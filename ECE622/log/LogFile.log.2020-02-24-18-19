2020-02-24 18:19:23,726 [main] WARN  (FlinkKafkaProducer.java:667) - Property [transaction.timeout.ms] not specified. Setting it to 3600000 ms
2020-02-24 18:19:24,092 [main] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.api.datastream.CoGroupedStreams$TaggedUnion does not contain a setter for field one
2020-02-24 18:19:24,098 [main] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.api.datastream.CoGroupedStreams$TaggedUnion cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-24 18:19:24,100 [main] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.api.datastream.CoGroupedStreams$TaggedUnion does not contain a setter for field one
2020-02-24 18:19:24,100 [main] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.api.datastream.CoGroupedStreams$TaggedUnion cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-24 18:19:24,327 [main] INFO  (LocalStreamEnvironment.java:108) - Running job on local embedded Flink mini cluster
2020-02-24 18:19:24,812 [main] INFO  (MiniCluster.java:253) - Starting Flink Mini Cluster
2020-02-24 18:19:24,816 [main] INFO  (MiniCluster.java:262) - Starting Metrics Registry
2020-02-24 18:19:24,883 [main] INFO  (MetricRegistryImpl.java:114) - No metrics reporter configured, no metrics will be exposed/reported.
2020-02-24 18:19:24,883 [main] INFO  (MiniCluster.java:266) - Starting RPC Service(s)
2020-02-24 18:19:25,595 [flink-akka.actor.default-dispatcher-3] INFO  (Slf4jLogger.scala:92) - Slf4jLogger started
2020-02-24 18:19:25,771 [main] INFO  (BootstrapTools.java:244) - Trying to start actor system at :0
2020-02-24 18:19:25,838 [flink-metrics-2] INFO  (Slf4jLogger.scala:92) - Slf4jLogger started
2020-02-24 18:19:25,856 [flink-metrics-2] INFO  (MarkerIgnoringBase.java:107) - Starting remoting
2020-02-24 18:19:25,980 [flink-metrics-2] INFO  (MarkerIgnoringBase.java:107) - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:40609]
2020-02-24 18:19:26,017 [main] INFO  (BootstrapTools.java:256) - Actor system started at akka.tcp://flink-metrics@127.0.1.1:40609
2020-02-24 18:19:26,026 [main] INFO  (AkkaRpcService.java:223) - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-02-24 18:19:26,038 [main] INFO  (MiniCluster.java:397) - Starting high-availability services
2020-02-24 18:19:26,051 [main] INFO  (BlobServer.java:141) - Created BLOB server storage directory /tmp/blobStore-00471661-a1bc-461b-9548-906597d6a174
2020-02-24 18:19:26,054 [main] INFO  (BlobServer.java:203) - Started BLOB server at 0.0.0.0:39551 - max concurrent requests: 50 - max backlog: 1000
2020-02-24 18:19:26,057 [main] INFO  (AbstractBlobCache.java:107) - Created BLOB cache storage directory /tmp/blobStore-27f01ed4-60e3-4216-98da-95941ef8f0c4
2020-02-24 18:19:26,060 [main] INFO  (AbstractBlobCache.java:107) - Created BLOB cache storage directory /tmp/blobStore-40fc6721-efd7-47f9-98f2-8c98b66a2fcc
2020-02-24 18:19:26,061 [main] INFO  (MiniCluster.java:479) - Starting 1 TaskManger(s)
2020-02-24 18:19:26,064 [main] INFO  (TaskManagerRunner.java:351) - Starting TaskManager with ResourceID: 889a278e-4eb0-476a-9588-68d7cb5e22b7
2020-02-24 18:19:26,189 [main] INFO  (TaskManagerServices.java:519) - Temporary file directory '/tmp': total 439 GB, usable 336 GB (76.54% usable)
2020-02-24 18:19:26,192 [main] INFO  (FileChannelManagerImpl.java:76) - FileChannelManager uses directory /tmp/flink-io-96999ebb-f3be-48ae-8837-6d35470d1b75 for spill files.
2020-02-24 18:19:26,198 [main] INFO  (FileChannelManagerImpl.java:76) - FileChannelManager uses directory /tmp/flink-netty-shuffle-3e3a4e0f-fbea-4d9a-83c2-d8a9a1c821d0 for spill files.
2020-02-24 18:19:26,295 [main] INFO  (NetworkBufferPool.java:140) - Allocated 191 MB for network buffer pool (number of memory segments: 6113, bytes per segment: 32768).
2020-02-24 18:19:26,301 [main] INFO  (NettyShuffleEnvironment.java:283) - Starting the network environment and its components.
2020-02-24 18:19:26,302 [main] INFO  (KvStateService.java:89) - Starting the kvState service and its components.
2020-02-24 18:19:26,302 [main] INFO  (TaskManagerServices.java:364) - Limiting managed memory to 0.7 of the currently free heap space (1195 MB), memory will be allocated lazily.
2020-02-24 18:19:26,311 [main] INFO  (TaskManagerConfiguration.java:197) - Messages have a max timeout of 10000 ms
2020-02-24 18:19:26,319 [main] INFO  (AkkaRpcService.java:223) - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-02-24 18:19:26,333 [flink-akka.actor.default-dispatcher-2] INFO  (JobLeaderService.java:125) - Start job leader service.
2020-02-24 18:19:26,335 [flink-akka.actor.default-dispatcher-2] INFO  (FileCache.java:107) - User file cache uses directory /tmp/flink-dist-cache-6eb8bc41-4491-4982-9a1e-03732580ce6d
2020-02-24 18:19:26,375 [main] INFO  (RestServerEndpoint.java:136) - Starting rest endpoint.
2020-02-24 18:19:26,580 [main] WARN  (WebMonitorUtils.java:87) - Log file environment variable 'log.file' is not set.
2020-02-24 18:19:26,581 [main] WARN  (WebMonitorUtils.java:93) - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-02-24 18:19:26,592 [main] INFO  (DispatcherRestEndpoint.java:113) - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-02-24 18:19:26,720 [main] INFO  (RestServerEndpoint.java:233) - Rest endpoint listening at localhost:38729
2020-02-24 18:19:26,721 [main] INFO  (EmbeddedLeaderService.java:300) - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@3e1624c7 @ http://localhost:38729
2020-02-24 18:19:26,723 [mini-cluster-io-thread-1] INFO  (WebMonitorEndpoint.java:712) - http://localhost:38729 was granted leadership with leaderSessionID=0146b0e6-d980-4470-acf1-3d80c9393c00
2020-02-24 18:19:26,723 [mini-cluster-io-thread-1] INFO  (EmbeddedLeaderService.java:250) - Received confirmation of leadership for leader http://localhost:38729 , session=0146b0e6-d980-4470-acf1-3d80c9393c00
2020-02-24 18:19:26,745 [main] INFO  (AkkaRpcService.java:223) - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-02-24 18:19:26,769 [main] INFO  (AkkaRpcService.java:223) - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-02-24 18:19:26,797 [flink-akka.actor.default-dispatcher-2] INFO  (EmbeddedLeaderService.java:300) - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@793a1e77 @ akka://flink/user/resourcemanager
2020-02-24 18:19:26,797 [flink-akka.actor.default-dispatcher-3] INFO  (EmbeddedLeaderService.java:300) - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@634b1ff4 @ akka://flink/user/dispatcher
2020-02-24 18:19:26,803 [flink-akka.actor.default-dispatcher-2] INFO  (ResourceManager.java:925) - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 9dbfd41d1af8ce9a470570a952db4f44
2020-02-24 18:19:26,808 [flink-akka.actor.default-dispatcher-2] INFO  (SlotManagerImpl.java:219) - Starting the SlotManager.
2020-02-24 18:19:26,813 [flink-akka.actor.default-dispatcher-3] INFO  (Dispatcher.java:884) - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token 9566972f-591f-4820-b8a5-9af8f2d931f2
2020-02-24 18:19:26,824 [flink-akka.actor.default-dispatcher-3] INFO  (Dispatcher.java:716) - Recovering all persisted jobs.
2020-02-24 18:19:26,825 [main] INFO  (MiniCluster.java:362) - Flink Mini Cluster started successfully
2020-02-24 18:19:26,829 [flink-akka.actor.default-dispatcher-4] INFO  (EmbeddedLeaderService.java:250) - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=9566972f-591f-4820-b8a5-9af8f2d931f2
2020-02-24 18:19:26,837 [flink-akka.actor.default-dispatcher-2] INFO  (EmbeddedLeaderService.java:250) - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=470570a9-52db-4f44-9dbf-d41d1af8ce9a
2020-02-24 18:19:26,839 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:991) - Connecting to ResourceManager akka://flink/user/resourcemanager(9dbfd41d1af8ce9a470570a952db4f44).
2020-02-24 18:19:26,850 [flink-akka.actor.default-dispatcher-2] INFO  (RetryingRegistration.java:155) - Resolved ResourceManager address, beginning registration
2020-02-24 18:19:26,850 [flink-akka.actor.default-dispatcher-2] INFO  (RetryingRegistration.java:204) - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-02-24 18:19:26,866 [flink-akka.actor.default-dispatcher-2] INFO  (ResourceManager.java:717) - Registering TaskManager with ResourceID 889a278e-4eb0-476a-9588-68d7cb5e22b7 (akka://flink/user/taskmanager_0) at ResourceManager
2020-02-24 18:19:26,870 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutorToResourceManagerConnection.java:100) - Successful registration at resource manager akka://flink/user/resourcemanager under registration id 3ceadd449f29c9af5abb1e1e3b1da256.
2020-02-24 18:19:26,871 [flink-akka.actor.default-dispatcher-4] INFO  (Dispatcher.java:264) - Received JobGraph submission d06e12c2bd2f9f17c3d1c764b5d9b097 (Job2).
2020-02-24 18:19:26,872 [flink-akka.actor.default-dispatcher-4] INFO  (Dispatcher.java:321) - Submitting job d06e12c2bd2f9f17c3d1c764b5d9b097 (Job2).
2020-02-24 18:19:26,898 [flink-akka.actor.default-dispatcher-3] INFO  (AkkaRpcService.java:223) - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-02-24 18:19:26,926 [flink-akka.actor.default-dispatcher-3] INFO  (JobMaster.java:242) - Initializing job Job2 (d06e12c2bd2f9f17c3d1c764b5d9b097).
2020-02-24 18:19:26,948 [flink-akka.actor.default-dispatcher-3] INFO  (LegacyScheduler.java:171) - Using restart strategy NoRestartStrategy for Job2 (d06e12c2bd2f9f17c3d1c764b5d9b097).
2020-02-24 18:19:26,971 [flink-akka.actor.default-dispatcher-3] INFO  (ExecutionGraph.java:519) - Job recovers via failover strategy: full graph restart
2020-02-24 18:19:26,993 [flink-akka.actor.default-dispatcher-3] INFO  (ExecutionGraphBuilder.java:204) - Running initialization on master for job Job2 (d06e12c2bd2f9f17c3d1c764b5d9b097).
2020-02-24 18:19:26,994 [flink-akka.actor.default-dispatcher-3] INFO  (ExecutionGraphBuilder.java:222) - Successfully ran initialization on master in 0 ms.
2020-02-24 18:19:27,048 [flink-akka.actor.default-dispatcher-3] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-24 18:19:27,061 [flink-akka.actor.default-dispatcher-3] INFO  (EmbeddedLeaderService.java:300) - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@e8e84cc @ akka://flink/user/jobmanager_1
2020-02-24 18:19:27,063 [mini-cluster-io-thread-3] INFO  (JobManagerRunner.java:313) - JobManager runner for job Job2 (d06e12c2bd2f9f17c3d1c764b5d9b097) was granted leadership with session id ee508c25-6164-42eb-aa7a-5beeff10fc12 at akka://flink/user/jobmanager_1.
2020-02-24 18:19:27,071 [flink-akka.actor.default-dispatcher-5] INFO  (JobMaster.java:712) - Starting execution of job Job2 (d06e12c2bd2f9f17c3d1c764b5d9b097) under job master id aa7a5beeff10fc12ee508c25616442eb.
2020-02-24 18:19:27,072 [flink-akka.actor.default-dispatcher-5] INFO  (ExecutionGraph.java:1325) - Job Job2 (d06e12c2bd2f9f17c3d1c764b5d9b097) switched from state CREATED to RUNNING.
2020-02-24 18:19:27,076 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (1/4) (18a6e10d6858b8fbc805d01a8af3e4b8) switched from CREATED to SCHEDULED.
2020-02-24 18:19:27,090 [flink-akka.actor.default-dispatcher-5] INFO  (SlotPoolImpl.java:369) - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{a8f7caa5c9e2032e71a887c7e5b2f05f}]
2020-02-24 18:19:27,097 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (2/4) (464d73f0ca20b3c5eb9f451e8fa34b2c) switched from CREATED to SCHEDULED.
2020-02-24 18:19:27,098 [flink-akka.actor.default-dispatcher-5] INFO  (SlotPoolImpl.java:369) - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{07f68cc1bc8d733faed5e15ca5ee2b53}]
2020-02-24 18:19:27,098 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (3/4) (494e6d3620ebdec47ca76467a574e915) switched from CREATED to SCHEDULED.
2020-02-24 18:19:27,099 [flink-akka.actor.default-dispatcher-5] INFO  (SlotPoolImpl.java:369) - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{fb0fa63e7bf36bbe3dc2d638d9b4456c}]
2020-02-24 18:19:27,099 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (4/4) (4b7dcee6ee60243f27a36e8f9d689275) switched from CREATED to SCHEDULED.
2020-02-24 18:19:27,099 [flink-akka.actor.default-dispatcher-5] INFO  (SlotPoolImpl.java:369) - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{a3dde11b9985c7ddd5cebafde8a4833e}]
2020-02-24 18:19:27,100 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (1/4) (435d95c25f64e51eebbf8006e27a2c93) switched from CREATED to SCHEDULED.
2020-02-24 18:19:27,100 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (2/4) (a096dbbb5eb5a97183d6b79102b1127b) switched from CREATED to SCHEDULED.
2020-02-24 18:19:27,100 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (3/4) (4084ca7717ea60ea10e9acc5f007897b) switched from CREATED to SCHEDULED.
2020-02-24 18:19:27,101 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (4/4) (cd3b5dd1ce17335d477d3691761c45a8) switched from CREATED to SCHEDULED.
2020-02-24 18:19:27,101 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (1/4) (ccb3f6596b65e147569b81b24ddffe57) switched from CREATED to SCHEDULED.
2020-02-24 18:19:27,102 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (2/4) (f109bbd0b94ab4451c71773c6cb112a4) switched from CREATED to SCHEDULED.
2020-02-24 18:19:27,102 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (3/4) (adefcfadc336ff9801c27316a8973dee) switched from CREATED to SCHEDULED.
2020-02-24 18:19:27,103 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (4/4) (b2cb4f9d7feb30a802ac4a7e8f915c59) switched from CREATED to SCHEDULED.
2020-02-24 18:19:27,103 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - KeyedProcess (1/4) (fa61ffef28c99b1a1e8593bddf6ce79f) switched from CREATED to SCHEDULED.
2020-02-24 18:19:27,103 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - KeyedProcess (2/4) (1db43c02bb150ed808bbaec20709cdb5) switched from CREATED to SCHEDULED.
2020-02-24 18:19:27,103 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - KeyedProcess (3/4) (e1c9fe40157dccfd19eaea735aea53c6) switched from CREATED to SCHEDULED.
2020-02-24 18:19:27,104 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - KeyedProcess (4/4) (c6b6a17f933f198236d67bda0b099aa4) switched from CREATED to SCHEDULED.
2020-02-24 18:19:27,104 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Print to Std. Out (1/4) (8c15cee09dba17c59259646b0fcb176f) switched from CREATED to SCHEDULED.
2020-02-24 18:19:27,104 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Print to Std. Out (2/4) (954d829e176a86b286f72b3077624418) switched from CREATED to SCHEDULED.
2020-02-24 18:19:27,104 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Print to Std. Out (3/4) (c66b59e4972258ec4ff4a85c56cb8256) switched from CREATED to SCHEDULED.
2020-02-24 18:19:27,104 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Print to Std. Out (4/4) (9c558071c1d84ddfac329bbf00f31955) switched from CREATED to SCHEDULED.
2020-02-24 18:19:27,105 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Unnamed (1/4) (11e845fecb76cc289aa6815c2594b0b9) switched from CREATED to SCHEDULED.
2020-02-24 18:19:27,105 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Unnamed (2/4) (6d5316f9ccd37e330ab39b37cd68f7e2) switched from CREATED to SCHEDULED.
2020-02-24 18:19:27,105 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Unnamed (3/4) (ce7fcc7784719525d92a447465effd71) switched from CREATED to SCHEDULED.
2020-02-24 18:19:27,105 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Unnamed (4/4) (248a8768b56ad5fdf080e19d070afb0b) switched from CREATED to SCHEDULED.
2020-02-24 18:19:27,107 [jobmanager-future-thread-1] INFO  (EmbeddedLeaderService.java:250) - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=ee508c25-6164-42eb-aa7a-5beeff10fc12
2020-02-24 18:19:27,107 [flink-akka.actor.default-dispatcher-5] INFO  (JobMaster.java:936) - Connecting to ResourceManager akka://flink/user/resourcemanager(9dbfd41d1af8ce9a470570a952db4f44)
2020-02-24 18:19:27,110 [flink-akka.actor.default-dispatcher-3] INFO  (RetryingRegistration.java:155) - Resolved ResourceManager address, beginning registration
2020-02-24 18:19:27,110 [flink-akka.actor.default-dispatcher-3] INFO  (RetryingRegistration.java:204) - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-02-24 18:19:27,112 [flink-akka.actor.default-dispatcher-2] INFO  (ResourceManager.java:306) - Registering job manager aa7a5beeff10fc12ee508c25616442eb@akka://flink/user/jobmanager_1 for job d06e12c2bd2f9f17c3d1c764b5d9b097.
2020-02-24 18:19:27,118 [flink-akka.actor.default-dispatcher-3] INFO  (ResourceManager.java:661) - Registered job manager aa7a5beeff10fc12ee508c25616442eb@akka://flink/user/jobmanager_1 for job d06e12c2bd2f9f17c3d1c764b5d9b097.
2020-02-24 18:19:27,120 [flink-akka.actor.default-dispatcher-4] INFO  (JobMaster.java:958) - JobManager successfully registered at ResourceManager, leader id: 9dbfd41d1af8ce9a470570a952db4f44.
2020-02-24 18:19:27,121 [flink-akka.actor.default-dispatcher-4] INFO  (SlotPoolImpl.java:319) - Requesting new slot [SlotRequestId{a8f7caa5c9e2032e71a887c7e5b2f05f}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-02-24 18:19:27,122 [flink-akka.actor.default-dispatcher-2] INFO  (ResourceManager.java:441) - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job d06e12c2bd2f9f17c3d1c764b5d9b097 with allocation id a81d14bb24d5705c615bf4622c7099c5.
2020-02-24 18:19:27,122 [flink-akka.actor.default-dispatcher-4] INFO  (SlotPoolImpl.java:319) - Requesting new slot [SlotRequestId{07f68cc1bc8d733faed5e15ca5ee2b53}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-02-24 18:19:27,123 [flink-akka.actor.default-dispatcher-4] INFO  (SlotPoolImpl.java:319) - Requesting new slot [SlotRequestId{fb0fa63e7bf36bbe3dc2d638d9b4456c}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-02-24 18:19:27,123 [flink-akka.actor.default-dispatcher-4] INFO  (SlotPoolImpl.java:319) - Requesting new slot [SlotRequestId{a3dde11b9985c7ddd5cebafde8a4833e}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-02-24 18:19:27,126 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:822) - Receive slot request a81d14bb24d5705c615bf4622c7099c5 for job d06e12c2bd2f9f17c3d1c764b5d9b097 from resource manager with leader id 9dbfd41d1af8ce9a470570a952db4f44.
2020-02-24 18:19:27,127 [flink-akka.actor.default-dispatcher-2] INFO  (ResourceManager.java:441) - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job d06e12c2bd2f9f17c3d1c764b5d9b097 with allocation id 9160dab80709e42663023c712c9ae4f6.
2020-02-24 18:19:27,128 [flink-akka.actor.default-dispatcher-2] INFO  (ResourceManager.java:441) - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job d06e12c2bd2f9f17c3d1c764b5d9b097 with allocation id 0ecb264b321b08bd2aace739fa63130a.
2020-02-24 18:19:27,129 [flink-akka.actor.default-dispatcher-2] INFO  (ResourceManager.java:441) - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job d06e12c2bd2f9f17c3d1c764b5d9b097 with allocation id d5efa02c0b783cdb8bc6cfe7bce7b95a.
2020-02-24 18:19:27,131 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:834) - Allocated slot for a81d14bb24d5705c615bf4622c7099c5.
2020-02-24 18:19:27,131 [flink-akka.actor.default-dispatcher-4] INFO  (JobLeaderService.java:193) - Add job d06e12c2bd2f9f17c3d1c764b5d9b097 for job leader monitoring.
2020-02-24 18:19:27,133 [mini-cluster-io-thread-1] INFO  (JobLeaderService.java:333) - Try to register at job manager akka://flink/user/jobmanager_1 with leader id ee508c25-6164-42eb-aa7a-5beeff10fc12.
2020-02-24 18:19:27,136 [flink-akka.actor.default-dispatcher-5] INFO  (RetryingRegistration.java:155) - Resolved JobManager address, beginning registration
2020-02-24 18:19:27,137 [flink-akka.actor.default-dispatcher-5] INFO  (RetryingRegistration.java:204) - Registration at JobManager attempt 1 (timeout=100ms)
2020-02-24 18:19:27,137 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:822) - Receive slot request 9160dab80709e42663023c712c9ae4f6 for job d06e12c2bd2f9f17c3d1c764b5d9b097 from resource manager with leader id 9dbfd41d1af8ce9a470570a952db4f44.
2020-02-24 18:19:27,138 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:834) - Allocated slot for 9160dab80709e42663023c712c9ae4f6.
2020-02-24 18:19:27,138 [flink-akka.actor.default-dispatcher-4] INFO  (JobLeaderService.java:193) - Add job d06e12c2bd2f9f17c3d1c764b5d9b097 for job leader monitoring.
2020-02-24 18:19:27,138 [mini-cluster-io-thread-3] INFO  (JobLeaderService.java:333) - Try to register at job manager akka://flink/user/jobmanager_1 with leader id ee508c25-6164-42eb-aa7a-5beeff10fc12.
2020-02-24 18:19:27,138 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:822) - Receive slot request 0ecb264b321b08bd2aace739fa63130a for job d06e12c2bd2f9f17c3d1c764b5d9b097 from resource manager with leader id 9dbfd41d1af8ce9a470570a952db4f44.
2020-02-24 18:19:27,139 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:834) - Allocated slot for 0ecb264b321b08bd2aace739fa63130a.
2020-02-24 18:19:27,139 [flink-akka.actor.default-dispatcher-4] INFO  (JobLeaderService.java:193) - Add job d06e12c2bd2f9f17c3d1c764b5d9b097 for job leader monitoring.
2020-02-24 18:19:27,140 [mini-cluster-io-thread-2] INFO  (JobLeaderService.java:333) - Try to register at job manager akka://flink/user/jobmanager_1 with leader id ee508c25-6164-42eb-aa7a-5beeff10fc12.
2020-02-24 18:19:27,140 [flink-akka.actor.default-dispatcher-3] INFO  (RetryingRegistration.java:155) - Resolved JobManager address, beginning registration
2020-02-24 18:19:27,141 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:822) - Receive slot request d5efa02c0b783cdb8bc6cfe7bce7b95a for job d06e12c2bd2f9f17c3d1c764b5d9b097 from resource manager with leader id 9dbfd41d1af8ce9a470570a952db4f44.
2020-02-24 18:19:27,141 [flink-akka.actor.default-dispatcher-5] INFO  (RetryingRegistration.java:155) - Resolved JobManager address, beginning registration
2020-02-24 18:19:27,141 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:834) - Allocated slot for d5efa02c0b783cdb8bc6cfe7bce7b95a.
2020-02-24 18:19:27,141 [flink-akka.actor.default-dispatcher-5] INFO  (RetryingRegistration.java:204) - Registration at JobManager attempt 1 (timeout=100ms)
2020-02-24 18:19:27,141 [flink-akka.actor.default-dispatcher-4] INFO  (JobLeaderService.java:193) - Add job d06e12c2bd2f9f17c3d1c764b5d9b097 for job leader monitoring.
2020-02-24 18:19:27,142 [mini-cluster-io-thread-4] INFO  (JobLeaderService.java:333) - Try to register at job manager akka://flink/user/jobmanager_1 with leader id ee508c25-6164-42eb-aa7a-5beeff10fc12.
2020-02-24 18:19:27,145 [flink-akka.actor.default-dispatcher-3] INFO  (RetryingRegistration.java:155) - Resolved JobManager address, beginning registration
2020-02-24 18:19:27,146 [flink-akka.actor.default-dispatcher-3] INFO  (RetryingRegistration.java:204) - Registration at JobManager attempt 1 (timeout=100ms)
2020-02-24 18:19:27,147 [flink-akka.actor.default-dispatcher-3] INFO  (JobLeaderService.java:382) - Successful registration at job manager akka://flink/user/jobmanager_1 for job d06e12c2bd2f9f17c3d1c764b5d9b097.
2020-02-24 18:19:27,148 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:1227) - Establish JobManager connection for job d06e12c2bd2f9f17c3d1c764b5d9b097.
2020-02-24 18:19:27,168 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:1128) - Offer reserved slots to the leader of job d06e12c2bd2f9f17c3d1c764b5d9b097.
2020-02-24 18:19:27,183 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (1/4) (18a6e10d6858b8fbc805d01a8af3e4b8) switched from SCHEDULED to DEPLOYING.
2020-02-24 18:19:27,183 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Map (1/4) (attempt #0) to 889a278e-4eb0-476a-9588-68d7cb5e22b7 @ localhost (dataPort=-1)
2020-02-24 18:19:27,189 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (2/4) (464d73f0ca20b3c5eb9f451e8fa34b2c) switched from SCHEDULED to DEPLOYING.
2020-02-24 18:19:27,190 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Map (2/4) (attempt #0) to 889a278e-4eb0-476a-9588-68d7cb5e22b7 @ localhost (dataPort=-1)
2020-02-24 18:19:27,191 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (3/4) (494e6d3620ebdec47ca76467a574e915) switched from SCHEDULED to DEPLOYING.
2020-02-24 18:19:27,191 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Map (3/4) (attempt #0) to 889a278e-4eb0-476a-9588-68d7cb5e22b7 @ localhost (dataPort=-1)
2020-02-24 18:19:27,192 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (4/4) (4b7dcee6ee60243f27a36e8f9d689275) switched from SCHEDULED to DEPLOYING.
2020-02-24 18:19:27,192 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Map (4/4) (attempt #0) to 889a278e-4eb0-476a-9588-68d7cb5e22b7 @ localhost (dataPort=-1)
2020-02-24 18:19:27,193 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (1/4) (435d95c25f64e51eebbf8006e27a2c93) switched from SCHEDULED to DEPLOYING.
2020-02-24 18:19:27,193 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Map (1/4) (attempt #0) to 889a278e-4eb0-476a-9588-68d7cb5e22b7 @ localhost (dataPort=-1)
2020-02-24 18:19:27,194 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (2/4) (a096dbbb5eb5a97183d6b79102b1127b) switched from SCHEDULED to DEPLOYING.
2020-02-24 18:19:27,195 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Map (2/4) (attempt #0) to 889a278e-4eb0-476a-9588-68d7cb5e22b7 @ localhost (dataPort=-1)
2020-02-24 18:19:27,196 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (3/4) (4084ca7717ea60ea10e9acc5f007897b) switched from SCHEDULED to DEPLOYING.
2020-02-24 18:19:27,196 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Map (3/4) (attempt #0) to 889a278e-4eb0-476a-9588-68d7cb5e22b7 @ localhost (dataPort=-1)
2020-02-24 18:19:27,197 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (4/4) (cd3b5dd1ce17335d477d3691761c45a8) switched from SCHEDULED to DEPLOYING.
2020-02-24 18:19:27,197 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Map (4/4) (attempt #0) to 889a278e-4eb0-476a-9588-68d7cb5e22b7 @ localhost (dataPort=-1)
2020-02-24 18:19:27,198 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (1/4) (ccb3f6596b65e147569b81b24ddffe57) switched from SCHEDULED to DEPLOYING.
2020-02-24 18:19:27,198 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (1/4) (attempt #0) to 889a278e-4eb0-476a-9588-68d7cb5e22b7 @ localhost (dataPort=-1)
2020-02-24 18:19:27,201 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (2/4) (f109bbd0b94ab4451c71773c6cb112a4) switched from SCHEDULED to DEPLOYING.
2020-02-24 18:19:27,202 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (2/4) (attempt #0) to 889a278e-4eb0-476a-9588-68d7cb5e22b7 @ localhost (dataPort=-1)
2020-02-24 18:19:27,202 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (3/4) (adefcfadc336ff9801c27316a8973dee) switched from SCHEDULED to DEPLOYING.
2020-02-24 18:19:27,203 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (3/4) (attempt #0) to 889a278e-4eb0-476a-9588-68d7cb5e22b7 @ localhost (dataPort=-1)
2020-02-24 18:19:27,203 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (4/4) (b2cb4f9d7feb30a802ac4a7e8f915c59) switched from SCHEDULED to DEPLOYING.
2020-02-24 18:19:27,204 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (4/4) (attempt #0) to 889a278e-4eb0-476a-9588-68d7cb5e22b7 @ localhost (dataPort=-1)
2020-02-24 18:19:27,205 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - KeyedProcess (1/4) (fa61ffef28c99b1a1e8593bddf6ce79f) switched from SCHEDULED to DEPLOYING.
2020-02-24 18:19:27,205 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying KeyedProcess (1/4) (attempt #0) to 889a278e-4eb0-476a-9588-68d7cb5e22b7 @ localhost (dataPort=-1)
2020-02-24 18:19:27,206 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - KeyedProcess (2/4) (1db43c02bb150ed808bbaec20709cdb5) switched from SCHEDULED to DEPLOYING.
2020-02-24 18:19:27,206 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying KeyedProcess (2/4) (attempt #0) to 889a278e-4eb0-476a-9588-68d7cb5e22b7 @ localhost (dataPort=-1)
2020-02-24 18:19:27,207 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - KeyedProcess (3/4) (e1c9fe40157dccfd19eaea735aea53c6) switched from SCHEDULED to DEPLOYING.
2020-02-24 18:19:27,207 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying KeyedProcess (3/4) (attempt #0) to 889a278e-4eb0-476a-9588-68d7cb5e22b7 @ localhost (dataPort=-1)
2020-02-24 18:19:27,208 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - KeyedProcess (4/4) (c6b6a17f933f198236d67bda0b099aa4) switched from SCHEDULED to DEPLOYING.
2020-02-24 18:19:27,208 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying KeyedProcess (4/4) (attempt #0) to 889a278e-4eb0-476a-9588-68d7cb5e22b7 @ localhost (dataPort=-1)
2020-02-24 18:19:27,209 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Sink: Print to Std. Out (1/4) (8c15cee09dba17c59259646b0fcb176f) switched from SCHEDULED to DEPLOYING.
2020-02-24 18:19:27,209 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Sink: Print to Std. Out (1/4) (attempt #0) to 889a278e-4eb0-476a-9588-68d7cb5e22b7 @ localhost (dataPort=-1)
2020-02-24 18:19:27,210 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Sink: Print to Std. Out (2/4) (954d829e176a86b286f72b3077624418) switched from SCHEDULED to DEPLOYING.
2020-02-24 18:19:27,210 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Sink: Print to Std. Out (2/4) (attempt #0) to 889a278e-4eb0-476a-9588-68d7cb5e22b7 @ localhost (dataPort=-1)
2020-02-24 18:19:27,211 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Sink: Print to Std. Out (3/4) (c66b59e4972258ec4ff4a85c56cb8256) switched from SCHEDULED to DEPLOYING.
2020-02-24 18:19:27,211 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Sink: Print to Std. Out (3/4) (attempt #0) to 889a278e-4eb0-476a-9588-68d7cb5e22b7 @ localhost (dataPort=-1)
2020-02-24 18:19:27,212 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Sink: Print to Std. Out (4/4) (9c558071c1d84ddfac329bbf00f31955) switched from SCHEDULED to DEPLOYING.
2020-02-24 18:19:27,212 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Sink: Print to Std. Out (4/4) (attempt #0) to 889a278e-4eb0-476a-9588-68d7cb5e22b7 @ localhost (dataPort=-1)
2020-02-24 18:19:27,213 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Sink: Unnamed (1/4) (11e845fecb76cc289aa6815c2594b0b9) switched from SCHEDULED to DEPLOYING.
2020-02-24 18:19:27,213 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Sink: Unnamed (1/4) (attempt #0) to 889a278e-4eb0-476a-9588-68d7cb5e22b7 @ localhost (dataPort=-1)
2020-02-24 18:19:27,214 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Sink: Unnamed (2/4) (6d5316f9ccd37e330ab39b37cd68f7e2) switched from SCHEDULED to DEPLOYING.
2020-02-24 18:19:27,215 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Sink: Unnamed (2/4) (attempt #0) to 889a278e-4eb0-476a-9588-68d7cb5e22b7 @ localhost (dataPort=-1)
2020-02-24 18:19:27,215 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Sink: Unnamed (3/4) (ce7fcc7784719525d92a447465effd71) switched from SCHEDULED to DEPLOYING.
2020-02-24 18:19:27,216 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Sink: Unnamed (3/4) (attempt #0) to 889a278e-4eb0-476a-9588-68d7cb5e22b7 @ localhost (dataPort=-1)
2020-02-24 18:19:27,216 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Sink: Unnamed (4/4) (248a8768b56ad5fdf080e19d070afb0b) switched from SCHEDULED to DEPLOYING.
2020-02-24 18:19:27,217 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Sink: Unnamed (4/4) (attempt #0) to 889a278e-4eb0-476a-9588-68d7cb5e22b7 @ localhost (dataPort=-1)
2020-02-24 18:19:27,230 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Map (1/4).
2020-02-24 18:19:27,234 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (1/4) (18a6e10d6858b8fbc805d01a8af3e4b8) switched from CREATED to DEPLOYING.
2020-02-24 18:19:27,234 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Map (1/4) (18a6e10d6858b8fbc805d01a8af3e4b8) [DEPLOYING]
2020-02-24 18:19:27,241 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Map (2/4).
2020-02-24 18:19:27,244 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (2/4) (464d73f0ca20b3c5eb9f451e8fa34b2c) switched from CREATED to DEPLOYING.
2020-02-24 18:19:27,245 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Map (2/4) (464d73f0ca20b3c5eb9f451e8fa34b2c) [DEPLOYING]
2020-02-24 18:19:27,247 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Map (3/4).
2020-02-24 18:19:27,248 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (3/4) (494e6d3620ebdec47ca76467a574e915) switched from CREATED to DEPLOYING.
2020-02-24 18:19:27,248 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Map (3/4) (494e6d3620ebdec47ca76467a574e915) [DEPLOYING]
2020-02-24 18:19:27,250 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Map (4/4).
2020-02-24 18:19:27,251 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (4/4) (4b7dcee6ee60243f27a36e8f9d689275) switched from CREATED to DEPLOYING.
2020-02-24 18:19:27,251 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Map (4/4) (4b7dcee6ee60243f27a36e8f9d689275) [DEPLOYING]
2020-02-24 18:19:27,252 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Map (1/4) (18a6e10d6858b8fbc805d01a8af3e4b8) [DEPLOYING].
2020-02-24 18:19:27,253 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Map (1/4).
2020-02-24 18:19:27,255 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Map (4/4) (4b7dcee6ee60243f27a36e8f9d689275) [DEPLOYING].
2020-02-24 18:19:27,257 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Map (3/4) (494e6d3620ebdec47ca76467a574e915) [DEPLOYING].
2020-02-24 18:19:27,258 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (1/4) (435d95c25f64e51eebbf8006e27a2c93) switched from CREATED to DEPLOYING.
2020-02-24 18:19:27,257 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Map (2/4) (464d73f0ca20b3c5eb9f451e8fa34b2c) [DEPLOYING].
2020-02-24 18:19:27,260 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Map (3/4) (494e6d3620ebdec47ca76467a574e915) [DEPLOYING].
2020-02-24 18:19:27,260 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Map (1/4) (435d95c25f64e51eebbf8006e27a2c93) [DEPLOYING]
2020-02-24 18:19:27,260 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Map (2/4) (464d73f0ca20b3c5eb9f451e8fa34b2c) [DEPLOYING].
2020-02-24 18:19:27,260 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Map (1/4) (435d95c25f64e51eebbf8006e27a2c93) [DEPLOYING].
2020-02-24 18:19:27,261 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Map (1/4) (435d95c25f64e51eebbf8006e27a2c93) [DEPLOYING].
2020-02-24 18:19:27,261 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Map (1/4) (18a6e10d6858b8fbc805d01a8af3e4b8) [DEPLOYING].
2020-02-24 18:19:27,264 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Map (2/4).
2020-02-24 18:19:27,263 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Map (4/4) (4b7dcee6ee60243f27a36e8f9d689275) [DEPLOYING].
2020-02-24 18:19:27,283 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Map (3/4).
2020-02-24 18:19:27,289 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (3/4) (4084ca7717ea60ea10e9acc5f007897b) switched from CREATED to DEPLOYING.
2020-02-24 18:19:27,292 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Map (4/4).
2020-02-24 18:19:27,293 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (4/4) (cd3b5dd1ce17335d477d3691761c45a8) switched from CREATED to DEPLOYING.
2020-02-24 18:19:27,293 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Map (4/4) (cd3b5dd1ce17335d477d3691761c45a8) [DEPLOYING]
2020-02-24 18:19:27,293 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Map (4/4) (cd3b5dd1ce17335d477d3691761c45a8) [DEPLOYING].
2020-02-24 18:19:27,293 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (2/4) (a096dbbb5eb5a97183d6b79102b1127b) switched from CREATED to DEPLOYING.
2020-02-24 18:19:27,294 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Map (2/4) (a096dbbb5eb5a97183d6b79102b1127b) [DEPLOYING]
2020-02-24 18:19:27,294 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Map (4/4) (cd3b5dd1ce17335d477d3691761c45a8) [DEPLOYING].
2020-02-24 18:19:27,297 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (2/4) (464d73f0ca20b3c5eb9f451e8fa34b2c) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,292 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Map (3/4) (4084ca7717ea60ea10e9acc5f007897b) [DEPLOYING]
2020-02-24 18:19:27,301 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (3/4) (494e6d3620ebdec47ca76467a574e915) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,302 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (2/4) (464d73f0ca20b3c5eb9f451e8fa34b2c) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,301 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (4/4) (4b7dcee6ee60243f27a36e8f9d689275) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,300 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (1/4) (435d95c25f64e51eebbf8006e27a2c93) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,300 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-24 18:19:27,305 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (3/4) (494e6d3620ebdec47ca76467a574e915) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,306 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (1/4) (435d95c25f64e51eebbf8006e27a2c93) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,306 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (4/4) (4b7dcee6ee60243f27a36e8f9d689275) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,294 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Map (2/4) (a096dbbb5eb5a97183d6b79102b1127b) [DEPLOYING].
2020-02-24 18:19:27,302 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (1/4) (18a6e10d6858b8fbc805d01a8af3e4b8) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,301 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Map (3/4) (4084ca7717ea60ea10e9acc5f007897b) [DEPLOYING].
2020-02-24 18:19:27,309 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (1/4) (18a6e10d6858b8fbc805d01a8af3e4b8) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,310 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Map (2/4) (a096dbbb5eb5a97183d6b79102b1127b) [DEPLOYING].
2020-02-24 18:19:27,310 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Map (3/4) (4084ca7717ea60ea10e9acc5f007897b) [DEPLOYING].
2020-02-24 18:19:27,302 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-24 18:19:27,309 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-24 18:19:27,313 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (4/4) (cd3b5dd1ce17335d477d3691761c45a8) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,303 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-24 18:19:27,313 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-24 18:19:27,314 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (4/4) (cd3b5dd1ce17335d477d3691761c45a8) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,303 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-24 18:19:27,315 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (2/4) (a096dbbb5eb5a97183d6b79102b1127b) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,316 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-24 18:19:27,316 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (2/4) (a096dbbb5eb5a97183d6b79102b1127b) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,320 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (1/4).
2020-02-24 18:19:27,320 [Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (1/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (1/4) (ccb3f6596b65e147569b81b24ddffe57) switched from CREATED to DEPLOYING.
2020-02-24 18:19:27,320 [Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (1/4) (ccb3f6596b65e147569b81b24ddffe57) [DEPLOYING]
2020-02-24 18:19:27,321 [Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (1/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (1/4) (ccb3f6596b65e147569b81b24ddffe57) [DEPLOYING].
2020-02-24 18:19:27,322 [Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (1/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (1/4) (ccb3f6596b65e147569b81b24ddffe57) [DEPLOYING].
2020-02-24 18:19:27,328 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (2/4).
2020-02-24 18:19:27,322 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (3/4) (4084ca7717ea60ea10e9acc5f007897b) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,341 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (3/4) (4084ca7717ea60ea10e9acc5f007897b) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,341 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-24 18:19:27,349 [Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (2/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (2/4) (f109bbd0b94ab4451c71773c6cb112a4) switched from CREATED to DEPLOYING.
2020-02-24 18:19:27,349 [Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (2/4) (f109bbd0b94ab4451c71773c6cb112a4) [DEPLOYING]
2020-02-24 18:19:27,349 [Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (2/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (2/4) (f109bbd0b94ab4451c71773c6cb112a4) [DEPLOYING].
2020-02-24 18:19:27,350 [Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (2/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (2/4) (f109bbd0b94ab4451c71773c6cb112a4) [DEPLOYING].
2020-02-24 18:19:27,350 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (3/4).
2020-02-24 18:19:27,354 [Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (3/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (3/4) (adefcfadc336ff9801c27316a8973dee) switched from CREATED to DEPLOYING.
2020-02-24 18:19:27,355 [Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (3/4) (adefcfadc336ff9801c27316a8973dee) [DEPLOYING]
2020-02-24 18:19:27,355 [Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (3/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (3/4) (adefcfadc336ff9801c27316a8973dee) [DEPLOYING].
2020-02-24 18:19:27,356 [Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (3/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (3/4) (adefcfadc336ff9801c27316a8973dee) [DEPLOYING].
2020-02-24 18:19:27,366 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (4/4).
2020-02-24 18:19:27,378 [Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (4/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (4/4) (b2cb4f9d7feb30a802ac4a7e8f915c59) switched from CREATED to DEPLOYING.
2020-02-24 18:19:27,381 [Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (4/4) (b2cb4f9d7feb30a802ac4a7e8f915c59) [DEPLOYING]
2020-02-24 18:19:27,381 [Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (4/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (4/4) (b2cb4f9d7feb30a802ac4a7e8f915c59) [DEPLOYING].
2020-02-24 18:19:27,382 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task KeyedProcess (1/4).
2020-02-24 18:19:27,384 [Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (4/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (4/4) (b2cb4f9d7feb30a802ac4a7e8f915c59) [DEPLOYING].
2020-02-24 18:19:27,385 [KeyedProcess (1/4)] INFO  (Task.java:958) - KeyedProcess (1/4) (fa61ffef28c99b1a1e8593bddf6ce79f) switched from CREATED to DEPLOYING.
2020-02-24 18:19:27,389 [KeyedProcess (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task KeyedProcess (1/4) (fa61ffef28c99b1a1e8593bddf6ce79f) [DEPLOYING]
2020-02-24 18:19:27,389 [KeyedProcess (1/4)] INFO  (Task.java:593) - Loading JAR files for task KeyedProcess (1/4) (fa61ffef28c99b1a1e8593bddf6ce79f) [DEPLOYING].
2020-02-24 18:19:27,390 [KeyedProcess (1/4)] INFO  (Task.java:619) - Registering task at network: KeyedProcess (1/4) (fa61ffef28c99b1a1e8593bddf6ce79f) [DEPLOYING].
2020-02-24 18:19:27,392 [Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (3/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (3/4) (adefcfadc336ff9801c27316a8973dee) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,397 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (3/4) (adefcfadc336ff9801c27316a8973dee) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,397 [Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-24 18:19:27,400 [Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (2/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (2/4) (f109bbd0b94ab4451c71773c6cb112a4) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,402 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (2/4) (f109bbd0b94ab4451c71773c6cb112a4) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,398 [Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (1/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (1/4) (ccb3f6596b65e147569b81b24ddffe57) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,403 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (1/4) (ccb3f6596b65e147569b81b24ddffe57) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,402 [Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-24 18:19:27,403 [Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-24 18:19:27,409 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task KeyedProcess (2/4).
2020-02-24 18:19:27,409 [KeyedProcess (1/4)] INFO  (Task.java:958) - KeyedProcess (1/4) (fa61ffef28c99b1a1e8593bddf6ce79f) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,410 [KeyedProcess (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-24 18:19:27,410 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - KeyedProcess (1/4) (fa61ffef28c99b1a1e8593bddf6ce79f) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,410 [KeyedProcess (2/4)] INFO  (Task.java:958) - KeyedProcess (2/4) (1db43c02bb150ed808bbaec20709cdb5) switched from CREATED to DEPLOYING.
2020-02-24 18:19:27,421 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-24 18:19:27,421 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-24 18:19:27,422 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-24 18:19:27,422 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-24 18:19:27,421 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-24 18:19:27,422 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-24 18:19:27,419 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-24 18:19:27,423 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-24 18:19:27,423 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-24 18:19:27,412 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task KeyedProcess (3/4).
2020-02-24 18:19:27,423 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-24 18:19:27,423 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-24 18:19:27,424 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-24 18:19:27,424 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-24 18:19:27,422 [KeyedProcess (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task KeyedProcess (2/4) (1db43c02bb150ed808bbaec20709cdb5) [DEPLOYING]
2020-02-24 18:19:27,424 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-24 18:19:27,424 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-24 18:19:27,424 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-24 18:19:27,424 [KeyedProcess (2/4)] INFO  (Task.java:593) - Loading JAR files for task KeyedProcess (2/4) (1db43c02bb150ed808bbaec20709cdb5) [DEPLOYING].
2020-02-24 18:19:27,425 [KeyedProcess (2/4)] INFO  (Task.java:619) - Registering task at network: KeyedProcess (2/4) (1db43c02bb150ed808bbaec20709cdb5) [DEPLOYING].
2020-02-24 18:19:27,434 [KeyedProcess (3/4)] INFO  (Task.java:958) - KeyedProcess (3/4) (e1c9fe40157dccfd19eaea735aea53c6) switched from CREATED to DEPLOYING.
2020-02-24 18:19:27,434 [KeyedProcess (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task KeyedProcess (3/4) (e1c9fe40157dccfd19eaea735aea53c6) [DEPLOYING]
2020-02-24 18:19:27,434 [KeyedProcess (3/4)] INFO  (Task.java:593) - Loading JAR files for task KeyedProcess (3/4) (e1c9fe40157dccfd19eaea735aea53c6) [DEPLOYING].
2020-02-24 18:19:27,435 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task KeyedProcess (4/4).
2020-02-24 18:19:27,435 [KeyedProcess (3/4)] INFO  (Task.java:619) - Registering task at network: KeyedProcess (3/4) (e1c9fe40157dccfd19eaea735aea53c6) [DEPLOYING].
2020-02-24 18:19:27,439 [KeyedProcess (4/4)] INFO  (Task.java:958) - KeyedProcess (4/4) (c6b6a17f933f198236d67bda0b099aa4) switched from CREATED to DEPLOYING.
2020-02-24 18:19:27,439 [KeyedProcess (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task KeyedProcess (4/4) (c6b6a17f933f198236d67bda0b099aa4) [DEPLOYING]
2020-02-24 18:19:27,439 [KeyedProcess (4/4)] INFO  (Task.java:593) - Loading JAR files for task KeyedProcess (4/4) (c6b6a17f933f198236d67bda0b099aa4) [DEPLOYING].
2020-02-24 18:19:27,440 [KeyedProcess (4/4)] INFO  (Task.java:619) - Registering task at network: KeyedProcess (4/4) (c6b6a17f933f198236d67bda0b099aa4) [DEPLOYING].
2020-02-24 18:19:27,441 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Sink: Print to Std. Out (1/4).
2020-02-24 18:19:27,450 [Sink: Print to Std. Out (1/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (1/4) (8c15cee09dba17c59259646b0fcb176f) switched from CREATED to DEPLOYING.
2020-02-24 18:19:27,450 [Sink: Print to Std. Out (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (1/4) (8c15cee09dba17c59259646b0fcb176f) [DEPLOYING]
2020-02-24 18:19:27,450 [Sink: Print to Std. Out (1/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Print to Std. Out (1/4) (8c15cee09dba17c59259646b0fcb176f) [DEPLOYING].
2020-02-24 18:19:27,451 [Sink: Print to Std. Out (1/4)] INFO  (Task.java:619) - Registering task at network: Sink: Print to Std. Out (1/4) (8c15cee09dba17c59259646b0fcb176f) [DEPLOYING].
2020-02-24 18:19:27,452 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Sink: Print to Std. Out (2/4).
2020-02-24 18:19:27,453 [Sink: Print to Std. Out (2/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (2/4) (954d829e176a86b286f72b3077624418) switched from CREATED to DEPLOYING.
2020-02-24 18:19:27,453 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 1 has no restore state.
2020-02-24 18:19:27,453 [Sink: Print to Std. Out (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (2/4) (954d829e176a86b286f72b3077624418) [DEPLOYING]
2020-02-24 18:19:27,454 [Sink: Print to Std. Out (2/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Print to Std. Out (2/4) (954d829e176a86b286f72b3077624418) [DEPLOYING].
2020-02-24 18:19:27,454 [Sink: Print to Std. Out (2/4)] INFO  (Task.java:619) - Registering task at network: Sink: Print to Std. Out (2/4) (954d829e176a86b286f72b3077624418) [DEPLOYING].
2020-02-24 18:19:27,454 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 2 has no restore state.
2020-02-24 18:19:27,454 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 1 has no restore state.
2020-02-24 18:19:27,454 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 0 has no restore state.
2020-02-24 18:19:27,454 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 3 has no restore state.
2020-02-24 18:19:27,457 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 3 has no restore state.
2020-02-24 18:19:27,454 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 0 has no restore state.
2020-02-24 18:19:27,454 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 2 has no restore state.
2020-02-24 18:19:27,455 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Sink: Print to Std. Out (3/4).
2020-02-24 18:19:27,458 [Sink: Print to Std. Out (3/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (3/4) (c66b59e4972258ec4ff4a85c56cb8256) switched from CREATED to DEPLOYING.
2020-02-24 18:19:27,458 [Sink: Print to Std. Out (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (3/4) (c66b59e4972258ec4ff4a85c56cb8256) [DEPLOYING]
2020-02-24 18:19:27,458 [Sink: Print to Std. Out (3/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Print to Std. Out (3/4) (c66b59e4972258ec4ff4a85c56cb8256) [DEPLOYING].
2020-02-24 18:19:27,459 [Sink: Print to Std. Out (3/4)] INFO  (Task.java:619) - Registering task at network: Sink: Print to Std. Out (3/4) (c66b59e4972258ec4ff4a85c56cb8256) [DEPLOYING].
2020-02-24 18:19:27,459 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Sink: Print to Std. Out (4/4).
2020-02-24 18:19:27,467 [KeyedProcess (2/4)] INFO  (Task.java:958) - KeyedProcess (2/4) (1db43c02bb150ed808bbaec20709cdb5) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,470 [KeyedProcess (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-24 18:19:27,469 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Sink: Unnamed (1/4).
2020-02-24 18:19:27,470 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - KeyedProcess (2/4) (1db43c02bb150ed808bbaec20709cdb5) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,474 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Sink: Unnamed (2/4).
2020-02-24 18:19:27,474 [Sink: Unnamed (1/4)] INFO  (Task.java:958) - Sink: Unnamed (1/4) (11e845fecb76cc289aa6815c2594b0b9) switched from CREATED to DEPLOYING.
2020-02-24 18:19:27,474 [Sink: Print to Std. Out (4/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (4/4) (9c558071c1d84ddfac329bbf00f31955) switched from CREATED to DEPLOYING.
2020-02-24 18:19:27,475 [Sink: Print to Std. Out (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (4/4) (9c558071c1d84ddfac329bbf00f31955) [DEPLOYING]
2020-02-24 18:19:27,475 [Sink: Print to Std. Out (4/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Print to Std. Out (4/4) (9c558071c1d84ddfac329bbf00f31955) [DEPLOYING].
2020-02-24 18:19:27,476 [Sink: Print to Std. Out (4/4)] INFO  (Task.java:619) - Registering task at network: Sink: Print to Std. Out (4/4) (9c558071c1d84ddfac329bbf00f31955) [DEPLOYING].
2020-02-24 18:19:27,476 [Sink: Unnamed (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Unnamed (1/4) (11e845fecb76cc289aa6815c2594b0b9) [DEPLOYING]
2020-02-24 18:19:27,476 [Sink: Unnamed (1/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Unnamed (1/4) (11e845fecb76cc289aa6815c2594b0b9) [DEPLOYING].
2020-02-24 18:19:27,477 [Sink: Unnamed (1/4)] INFO  (Task.java:619) - Registering task at network: Sink: Unnamed (1/4) (11e845fecb76cc289aa6815c2594b0b9) [DEPLOYING].
2020-02-24 18:19:27,481 [Sink: Unnamed (2/4)] INFO  (Task.java:958) - Sink: Unnamed (2/4) (6d5316f9ccd37e330ab39b37cd68f7e2) switched from CREATED to DEPLOYING.
2020-02-24 18:19:27,483 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Sink: Unnamed (3/4).
2020-02-24 18:19:27,488 [Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (4/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (4/4) (b2cb4f9d7feb30a802ac4a7e8f915c59) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,489 [Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-24 18:19:27,490 [Sink: Print to Std. Out (1/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (1/4) (8c15cee09dba17c59259646b0fcb176f) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,491 [Sink: Print to Std. Out (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-24 18:19:27,491 [KeyedProcess (2/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-24 18:19:27,492 [Sink: Print to Std. Out (3/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (3/4) (c66b59e4972258ec4ff4a85c56cb8256) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,492 [Sink: Print to Std. Out (2/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (2/4) (954d829e176a86b286f72b3077624418) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,492 [Sink: Unnamed (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Unnamed (2/4) (6d5316f9ccd37e330ab39b37cd68f7e2) [DEPLOYING]
2020-02-24 18:19:27,492 [Sink: Print to Std. Out (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-24 18:19:27,492 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (4/4) (b2cb4f9d7feb30a802ac4a7e8f915c59) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,493 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Sink: Print to Std. Out (1/4) (8c15cee09dba17c59259646b0fcb176f) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,492 [Sink: Print to Std. Out (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-24 18:19:27,493 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Sink: Print to Std. Out (3/4) (c66b59e4972258ec4ff4a85c56cb8256) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,494 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Sink: Print to Std. Out (2/4) (954d829e176a86b286f72b3077624418) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,495 [KeyedProcess (2/4)] INFO  (TypeExtractor.java:1815) - class java.util.Vector does not contain a getter for field elementData
2020-02-24 18:19:27,495 [KeyedProcess (2/4)] INFO  (TypeExtractor.java:1818) - class java.util.Vector does not contain a setter for field elementData
2020-02-24 18:19:27,496 [KeyedProcess (2/4)] INFO  (TypeExtractor.java:1857) - Class class java.util.Vector cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-24 18:19:27,492 [Sink: Unnamed (2/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Unnamed (2/4) (6d5316f9ccd37e330ab39b37cd68f7e2) [DEPLOYING].
2020-02-24 18:19:27,512 [Sink: Unnamed (2/4)] INFO  (Task.java:619) - Registering task at network: Sink: Unnamed (2/4) (6d5316f9ccd37e330ab39b37cd68f7e2) [DEPLOYING].
2020-02-24 18:19:27,513 [Sink: Unnamed (2/4)] INFO  (Task.java:958) - Sink: Unnamed (2/4) (6d5316f9ccd37e330ab39b37cd68f7e2) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,513 [Sink: Unnamed (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-24 18:19:27,515 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Sink: Unnamed (4/4).
2020-02-24 18:19:27,517 [Sink: Unnamed (2/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-24 18:19:27,517 [Sink: Unnamed (2/4)] WARN  (FlinkKafkaProducer.java:998) - Using EXACTLY_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-02-24 18:19:27,518 [Sink: Unnamed (2/4)] INFO  (TwoPhaseCommitSinkFunction.java:366) - FlinkKafkaProducer 1/4 - no state to restore
2020-02-24 18:19:27,512 [Sink: Unnamed (1/4)] INFO  (Task.java:958) - Sink: Unnamed (1/4) (11e845fecb76cc289aa6815c2594b0b9) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,511 [KeyedProcess (3/4)] INFO  (Task.java:958) - KeyedProcess (3/4) (e1c9fe40157dccfd19eaea735aea53c6) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,519 [KeyedProcess (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-24 18:19:27,502 [Sink: Unnamed (3/4)] INFO  (Task.java:958) - Sink: Unnamed (3/4) (ce7fcc7784719525d92a447465effd71) switched from CREATED to DEPLOYING.
2020-02-24 18:19:27,501 [Sink: Print to Std. Out (2/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-24 18:19:27,501 [Sink: Print to Std. Out (3/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-24 18:19:27,501 [Sink: Print to Std. Out (1/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-24 18:19:27,501 [Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (4/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-24 18:19:27,492 [Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (3/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-24 18:19:27,492 [KeyedProcess (1/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-24 18:19:27,522 [KeyedProcess (1/4)] INFO  (TypeExtractor.java:1815) - class java.util.Vector does not contain a getter for field elementData
2020-02-24 18:19:27,522 [KeyedProcess (1/4)] INFO  (TypeExtractor.java:1818) - class java.util.Vector does not contain a setter for field elementData
2020-02-24 18:19:27,522 [KeyedProcess (1/4)] INFO  (TypeExtractor.java:1857) - Class class java.util.Vector cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-24 18:19:27,492 [Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (2/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-24 18:19:27,491 [Window(TumblingEventTimeWindows(50000), EventTimeTrigger, CoGroupWindowFunction) (1/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-24 18:19:27,493 [Sink: Print to Std. Out (4/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (4/4) (9c558071c1d84ddfac329bbf00f31955) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,523 [Sink: Print to Std. Out (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-24 18:19:27,521 [Sink: Unnamed (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Unnamed (3/4) (ce7fcc7784719525d92a447465effd71) [DEPLOYING]
2020-02-24 18:19:27,519 [Sink: Unnamed (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-24 18:19:27,529 [KeyedProcess (4/4)] INFO  (Task.java:958) - KeyedProcess (4/4) (c6b6a17f933f198236d67bda0b099aa4) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,532 [KeyedProcess (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-24 18:19:27,529 [flink-akka.actor.default-dispatcher-2] INFO  (TaskSlotTable.java:242) - Activate slot 9160dab80709e42663023c712c9ae4f6.
2020-02-24 18:19:27,535 [flink-akka.actor.default-dispatcher-2] INFO  (TaskSlotTable.java:242) - Activate slot 0ecb264b321b08bd2aace739fa63130a.
2020-02-24 18:19:27,535 [flink-akka.actor.default-dispatcher-2] INFO  (TaskSlotTable.java:242) - Activate slot a81d14bb24d5705c615bf4622c7099c5.
2020-02-24 18:19:27,535 [flink-akka.actor.default-dispatcher-2] INFO  (TaskSlotTable.java:242) - Activate slot d5efa02c0b783cdb8bc6cfe7bce7b95a.
2020-02-24 18:19:27,528 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Sink: Unnamed (2/4) (6d5316f9ccd37e330ab39b37cd68f7e2) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,536 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Sink: Unnamed (1/4) (11e845fecb76cc289aa6815c2594b0b9) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,536 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - KeyedProcess (3/4) (e1c9fe40157dccfd19eaea735aea53c6) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,537 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Sink: Print to Std. Out (4/4) (9c558071c1d84ddfac329bbf00f31955) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,538 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - KeyedProcess (4/4) (c6b6a17f933f198236d67bda0b099aa4) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,527 [Sink: Print to Std. Out (4/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-24 18:19:27,527 [KeyedProcess (3/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-24 18:19:27,539 [Sink: Unnamed (1/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-24 18:19:27,539 [Sink: Unnamed (1/4)] WARN  (FlinkKafkaProducer.java:998) - Using EXACTLY_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-02-24 18:19:27,540 [KeyedProcess (3/4)] INFO  (TypeExtractor.java:1815) - class java.util.Vector does not contain a getter for field elementData
2020-02-24 18:19:27,540 [KeyedProcess (3/4)] INFO  (TypeExtractor.java:1818) - class java.util.Vector does not contain a setter for field elementData
2020-02-24 18:19:27,540 [KeyedProcess (3/4)] INFO  (TypeExtractor.java:1857) - Class class java.util.Vector cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-24 18:19:27,538 [Sink: Unnamed (3/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Unnamed (3/4) (ce7fcc7784719525d92a447465effd71) [DEPLOYING].
2020-02-24 18:19:27,540 [KeyedProcess (4/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-24 18:19:27,541 [Sink: Unnamed (3/4)] INFO  (Task.java:619) - Registering task at network: Sink: Unnamed (3/4) (ce7fcc7784719525d92a447465effd71) [DEPLOYING].
2020-02-24 18:19:27,541 [Sink: Unnamed (3/4)] INFO  (Task.java:958) - Sink: Unnamed (3/4) (ce7fcc7784719525d92a447465effd71) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,541 [Sink: Unnamed (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-24 18:19:27,541 [KeyedProcess (4/4)] INFO  (TypeExtractor.java:1815) - class java.util.Vector does not contain a getter for field elementData
2020-02-24 18:19:27,542 [KeyedProcess (4/4)] INFO  (TypeExtractor.java:1818) - class java.util.Vector does not contain a setter for field elementData
2020-02-24 18:19:27,542 [KeyedProcess (4/4)] INFO  (TypeExtractor.java:1857) - Class class java.util.Vector cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-24 18:19:27,537 [Sink: Unnamed (4/4)] INFO  (Task.java:958) - Sink: Unnamed (4/4) (248a8768b56ad5fdf080e19d070afb0b) switched from CREATED to DEPLOYING.
2020-02-24 18:19:27,540 [Sink: Unnamed (1/4)] INFO  (TwoPhaseCommitSinkFunction.java:366) - FlinkKafkaProducer 0/4 - no state to restore
2020-02-24 18:19:27,543 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Sink: Unnamed (3/4) (ce7fcc7784719525d92a447465effd71) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,543 [Sink: Unnamed (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Unnamed (4/4) (248a8768b56ad5fdf080e19d070afb0b) [DEPLOYING]
2020-02-24 18:19:27,543 [Sink: Unnamed (4/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Unnamed (4/4) (248a8768b56ad5fdf080e19d070afb0b) [DEPLOYING].
2020-02-24 18:19:27,547 [Sink: Unnamed (3/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-24 18:19:27,547 [Sink: Unnamed (3/4)] WARN  (FlinkKafkaProducer.java:998) - Using EXACTLY_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-02-24 18:19:27,547 [Sink: Unnamed (3/4)] INFO  (TwoPhaseCommitSinkFunction.java:366) - FlinkKafkaProducer 2/4 - no state to restore
2020-02-24 18:19:27,552 [Sink: Unnamed (4/4)] INFO  (Task.java:619) - Registering task at network: Sink: Unnamed (4/4) (248a8768b56ad5fdf080e19d070afb0b) [DEPLOYING].
2020-02-24 18:19:27,553 [Sink: Unnamed (4/4)] INFO  (Task.java:958) - Sink: Unnamed (4/4) (248a8768b56ad5fdf080e19d070afb0b) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,553 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-24 18:19:27,553 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-24 18:19:27,553 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-24 18:19:27,558 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-24 18:19:27,561 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-24 18:19:27,559 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-24 18:19:27,558 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-24 18:19:27,567 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Sink: Unnamed (4/4) (248a8768b56ad5fdf080e19d070afb0b) switched from DEPLOYING to RUNNING.
2020-02-24 18:19:27,569 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-24 18:19:27,567 [Sink: Unnamed (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-24 18:19:27,580 [Sink: Unnamed (1/4)] INFO  (AbstractConfig.java:347) - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-02-24 18:19:27,581 [Sink: Unnamed (4/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-24 18:19:27,586 [Sink: Unnamed (4/4)] WARN  (FlinkKafkaProducer.java:998) - Using EXACTLY_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-02-24 18:19:27,586 [Sink: Unnamed (4/4)] INFO  (TwoPhaseCommitSinkFunction.java:366) - FlinkKafkaProducer 3/4 - no state to restore
2020-02-24 18:19:27,587 [Sink: Unnamed (3/4)] INFO  (AbstractConfig.java:347) - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-02-24 18:19:27,588 [Sink: Unnamed (2/4)] INFO  (AbstractConfig.java:347) - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-02-24 18:19:27,596 [Sink: Unnamed (4/4)] INFO  (AbstractConfig.java:347) - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-02-24 18:19:27,739 [Sink: Unnamed (2/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-24 18:19:27,756 [Sink: Unnamed (2/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-24 18:19:27,756 [Sink: Unnamed (2/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582561167735
2020-02-24 18:19:27,768 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-24 18:19:27,769 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-24 18:19:27,769 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582561167768
2020-02-24 18:19:27,769 [Sink: Unnamed (2/4)] INFO  (FlinkKafkaProducer.java:1158) - Starting FlinkKafkaInternalProducer (2/4) to produce into default topic flinkfinal
2020-02-24 18:19:27,776 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-24 18:19:27,776 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-24 18:19:27,776 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582561167761
2020-02-24 18:19:27,777 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-24 18:19:27,788 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-24 18:19:27,789 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582561167761
2020-02-24 18:19:27,789 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-24 18:19:27,793 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-24 18:19:27,793 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582561167761
2020-02-24 18:19:27,793 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-24 18:19:27,794 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-24 18:19:27,794 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582561167759
2020-02-24 18:19:27,798 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-24 18:19:27,798 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-24 18:19:27,798 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582561167758
2020-02-24 18:19:27,799 [Sink: Unnamed (1/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-24 18:19:27,799 [Sink: Unnamed (1/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-24 18:19:27,799 [Sink: Unnamed (1/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582561167758
2020-02-24 18:19:27,800 [Sink: Unnamed (1/4)] INFO  (FlinkKafkaProducer.java:1158) - Starting FlinkKafkaInternalProducer (1/4) to produce into default topic flinkfinal
2020-02-24 18:19:27,800 [Sink: Unnamed (3/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-24 18:19:27,801 [Sink: Unnamed (3/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-24 18:19:27,801 [Sink: Unnamed (3/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582561167749
2020-02-24 18:19:27,801 [Sink: Unnamed (3/4)] INFO  (FlinkKafkaProducer.java:1158) - Starting FlinkKafkaInternalProducer (3/4) to produce into default topic flinkfinal
2020-02-24 18:19:27,801 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-24 18:19:27,802 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-24 18:19:27,802 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582561167749
2020-02-24 18:19:27,802 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-24 18:19:27,802 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-24 18:19:27,803 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582561167748
2020-02-24 18:19:27,803 [Sink: Unnamed (4/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-24 18:19:27,803 [Sink: Unnamed (4/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-24 18:19:27,803 [Sink: Unnamed (4/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582561167747
2020-02-24 18:19:27,803 [Sink: Unnamed (4/4)] INFO  (FlinkKafkaProducer.java:1158) - Starting FlinkKafkaInternalProducer (4/4) to produce into default topic flinkfinal
2020-02-24 18:19:28,234 [kafka-producer-network-thread | producer-1] INFO  (Metadata.java:261) - [Producer clientId=producer-1] Cluster ID: g54BmaOlTjihW0VeJBBMyQ
2020-02-24 18:19:28,234 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-8, groupId=KafkaCsvProducer] Cluster ID: g54BmaOlTjihW0VeJBBMyQ
2020-02-24 18:19:28,234 [kafka-producer-network-thread | producer-3] INFO  (Metadata.java:261) - [Producer clientId=producer-3] Cluster ID: g54BmaOlTjihW0VeJBBMyQ
2020-02-24 18:19:28,234 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-4, groupId=KafkaCsvProducer] Cluster ID: g54BmaOlTjihW0VeJBBMyQ
2020-02-24 18:19:28,235 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-2, groupId=KafkaCsvProducer] Cluster ID: g54BmaOlTjihW0VeJBBMyQ
2020-02-24 18:19:28,236 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-1, groupId=KafkaCsvProducer] Cluster ID: g54BmaOlTjihW0VeJBBMyQ
2020-02-24 18:19:28,236 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-6, groupId=KafkaCsvProducer] Cluster ID: g54BmaOlTjihW0VeJBBMyQ
2020-02-24 18:19:28,237 [kafka-producer-network-thread | producer-2] INFO  (Metadata.java:261) - [Producer clientId=producer-2] Cluster ID: g54BmaOlTjihW0VeJBBMyQ
2020-02-24 18:19:28,235 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-7, groupId=KafkaCsvProducer] Cluster ID: g54BmaOlTjihW0VeJBBMyQ
2020-02-24 18:19:28,237 [kafka-producer-network-thread | producer-4] INFO  (Metadata.java:261) - [Producer clientId=producer-4] Cluster ID: g54BmaOlTjihW0VeJBBMyQ
2020-02-24 18:19:28,236 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-5, groupId=KafkaCsvProducer] Cluster ID: g54BmaOlTjihW0VeJBBMyQ
2020-02-24 18:19:28,235 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-3, groupId=KafkaCsvProducer] Cluster ID: g54BmaOlTjihW0VeJBBMyQ
2020-02-24 18:19:28,239 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (FlinkKafkaConsumerBase.java:651) - Consumer subtask 3 initially has no partitions to read from.
2020-02-24 18:19:28,239 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (FlinkKafkaConsumerBase.java:651) - Consumer subtask 3 initially has no partitions to read from.
2020-02-24 18:19:28,239 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (FlinkKafkaConsumerBase.java:604) - Consumer subtask 0 will start reading the following 1 partitions from the earliest offsets: [KafkaTopicPartition{topic='flinkaggr1', partition=0}]
2020-02-24 18:19:28,239 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (FlinkKafkaConsumerBase.java:651) - Consumer subtask 2 initially has no partitions to read from.
2020-02-24 18:19:28,239 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (FlinkKafkaConsumerBase.java:651) - Consumer subtask 1 initially has no partitions to read from.
2020-02-24 18:19:28,239 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (FlinkKafkaConsumerBase.java:651) - Consumer subtask 0 initially has no partitions to read from.
2020-02-24 18:19:28,240 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (FlinkKafkaConsumerBase.java:651) - Consumer subtask 2 initially has no partitions to read from.
2020-02-24 18:19:28,240 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (FlinkKafkaConsumerBase.java:604) - Consumer subtask 1 will start reading the following 1 partitions from the earliest offsets: [KafkaTopicPartition{topic='flinkout1', partition=0}]
2020-02-24 18:19:28,274 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='flinkout1', partition=0}=-915623761775}.
2020-02-24 18:19:28,327 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 0 creating fetcher with offsets {KafkaTopicPartition{topic='flinkaggr1', partition=0}=-915623761775}.
2020-02-24 18:19:28,330 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 0 creating fetcher with offsets {}.
2020-02-24 18:19:28,330 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 2 creating fetcher with offsets {}.
2020-02-24 18:19:28,330 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 1 creating fetcher with offsets {}.
2020-02-24 18:19:28,330 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 2 creating fetcher with offsets {}.
2020-02-24 18:19:28,330 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 3 creating fetcher with offsets {}.
2020-02-24 18:19:28,332 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-24 18:19:28,333 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-24 18:19:28,339 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 3 creating fetcher with offsets {}.
2020-02-24 18:19:28,345 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-24 18:19:28,351 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-24 18:19:28,348 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-24 18:19:28,347 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-24 18:19:28,347 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-24 18:19:28,346 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-24 18:19:28,346 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-24 18:19:28,358 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-24 18:19:28,358 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582561168346
2020-02-24 18:19:28,368 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-24 18:19:28,369 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-24 18:19:28,369 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582561168366
2020-02-24 18:19:28,370 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-24 18:19:28,373 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-24 18:19:28,373 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582561168363
2020-02-24 18:19:28,377 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-24 18:19:28,378 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-24 18:19:28,378 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582561168347
2020-02-24 18:19:28,379 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-24 18:19:28,379 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-24 18:19:28,379 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582561168375
2020-02-24 18:19:28,379 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-24 18:19:28,380 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-24 18:19:28,380 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582561168379
2020-02-24 18:19:28,380 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-24 18:19:28,381 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-24 18:19:28,381 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582561168380
2020-02-24 18:19:28,382 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (KafkaConsumer.java:1123) - [Consumer clientId=consumer-KafkaCsvProducer-9, groupId=KafkaCsvProducer] Subscribed to partition(s): flinkout1-0
2020-02-24 18:19:28,382 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-24 18:19:28,383 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-24 18:19:28,383 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582561168382
2020-02-24 18:19:28,387 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-9, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition flinkout1-0
2020-02-24 18:19:28,389 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (KafkaConsumer.java:1123) - [Consumer clientId=consumer-KafkaCsvProducer-13, groupId=KafkaCsvProducer] Subscribed to partition(s): flinkaggr1-0
2020-02-24 18:19:28,390 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-13, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition flinkaggr1-0
2020-02-24 18:19:28,409 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-9, groupId=KafkaCsvProducer] Cluster ID: g54BmaOlTjihW0VeJBBMyQ
2020-02-24 18:19:28,414 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-13, groupId=KafkaCsvProducer] Cluster ID: g54BmaOlTjihW0VeJBBMyQ
2020-02-24 18:19:28,421 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-9, groupId=KafkaCsvProducer] Resetting offset for partition flinkout1-0 to offset 0.
2020-02-24 18:19:28,423 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-13, groupId=KafkaCsvProducer] Resetting offset for partition flinkaggr1-0 to offset 0.
2020-02-24 18:19:33,377 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AbstractCoordinator.java:756) - [Consumer clientId=consumer-KafkaCsvProducer-9, groupId=KafkaCsvProducer] Discovered group coordinator skl:9092 (id: 2147483647 rack: null)
2020-02-24 18:19:33,480 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AbstractCoordinator.java:756) - [Consumer clientId=consumer-KafkaCsvProducer-13, groupId=KafkaCsvProducer] Discovered group coordinator skl:9092 (id: 2147483647 rack: null)
