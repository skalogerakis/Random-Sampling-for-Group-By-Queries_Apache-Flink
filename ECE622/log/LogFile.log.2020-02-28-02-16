2020-02-28 02:16:17,182 [main] WARN  (FlinkKafkaProducer.java:667) - Property [transaction.timeout.ms] not specified. Setting it to 3600000 ms
2020-02-28 02:16:17,186 [main] WARN  (FlinkKafkaProducer.java:667) - Property [transaction.timeout.ms] not specified. Setting it to 3600000 ms
2020-02-28 02:16:17,385 [main] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.api.datastream.CoGroupedStreams$TaggedUnion does not contain a setter for field one
2020-02-28 02:16:17,386 [main] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.api.datastream.CoGroupedStreams$TaggedUnion cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-28 02:16:17,388 [main] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.api.datastream.CoGroupedStreams$TaggedUnion does not contain a setter for field one
2020-02-28 02:16:17,388 [main] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.api.datastream.CoGroupedStreams$TaggedUnion cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-28 02:16:17,769 [main] INFO  (LocalStreamEnvironment.java:108) - Running job on local embedded Flink mini cluster
2020-02-28 02:16:18,308 [main] INFO  (MiniCluster.java:253) - Starting Flink Mini Cluster
2020-02-28 02:16:18,312 [main] INFO  (MiniCluster.java:262) - Starting Metrics Registry
2020-02-28 02:16:18,389 [main] INFO  (MetricRegistryImpl.java:114) - No metrics reporter configured, no metrics will be exposed/reported.
2020-02-28 02:16:18,389 [main] INFO  (MiniCluster.java:266) - Starting RPC Service(s)
2020-02-28 02:16:19,106 [flink-akka.actor.default-dispatcher-2] INFO  (Slf4jLogger.scala:92) - Slf4jLogger started
2020-02-28 02:16:19,266 [main] INFO  (BootstrapTools.java:244) - Trying to start actor system at :0
2020-02-28 02:16:19,325 [flink-metrics-2] INFO  (Slf4jLogger.scala:92) - Slf4jLogger started
2020-02-28 02:16:19,348 [flink-metrics-2] INFO  (MarkerIgnoringBase.java:107) - Starting remoting
2020-02-28 02:16:19,482 [flink-metrics-2] INFO  (MarkerIgnoringBase.java:107) - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:46367]
2020-02-28 02:16:19,519 [main] INFO  (BootstrapTools.java:256) - Actor system started at akka.tcp://flink-metrics@127.0.1.1:46367
2020-02-28 02:16:19,525 [main] INFO  (AkkaRpcService.java:223) - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-02-28 02:16:19,540 [main] INFO  (MiniCluster.java:397) - Starting high-availability services
2020-02-28 02:16:19,554 [main] INFO  (BlobServer.java:141) - Created BLOB server storage directory /tmp/blobStore-20c11110-20fa-4a7c-86f4-14d4cd993795
2020-02-28 02:16:19,557 [main] INFO  (BlobServer.java:203) - Started BLOB server at 0.0.0.0:43649 - max concurrent requests: 50 - max backlog: 1000
2020-02-28 02:16:19,563 [main] INFO  (AbstractBlobCache.java:107) - Created BLOB cache storage directory /tmp/blobStore-7813f12a-dd9d-4a8b-8ad0-40caea3e4a93
2020-02-28 02:16:19,565 [main] INFO  (AbstractBlobCache.java:107) - Created BLOB cache storage directory /tmp/blobStore-e2a7e791-8dcb-452d-9687-e7dc974a0746
2020-02-28 02:16:19,569 [main] INFO  (MiniCluster.java:479) - Starting 1 TaskManger(s)
2020-02-28 02:16:19,572 [main] INFO  (TaskManagerRunner.java:351) - Starting TaskManager with ResourceID: 6c8c40a1-1cf4-4562-88db-fd4066c5353e
2020-02-28 02:16:19,715 [main] INFO  (TaskManagerServices.java:519) - Temporary file directory '/tmp': total 439 GB, usable 336 GB (76.54% usable)
2020-02-28 02:16:19,719 [main] INFO  (FileChannelManagerImpl.java:76) - FileChannelManager uses directory /tmp/flink-io-002298a5-7b12-4e87-8aed-30d5fc026c61 for spill files.
2020-02-28 02:16:19,729 [main] INFO  (FileChannelManagerImpl.java:76) - FileChannelManager uses directory /tmp/flink-netty-shuffle-eb73976d-c1f6-408b-bc65-2ee74b99d77f for spill files.
2020-02-28 02:16:19,832 [main] INFO  (NetworkBufferPool.java:140) - Allocated 191 MB for network buffer pool (number of memory segments: 6113, bytes per segment: 32768).
2020-02-28 02:16:19,838 [main] INFO  (NettyShuffleEnvironment.java:283) - Starting the network environment and its components.
2020-02-28 02:16:19,839 [main] INFO  (KvStateService.java:89) - Starting the kvState service and its components.
2020-02-28 02:16:19,839 [main] INFO  (TaskManagerServices.java:364) - Limiting managed memory to 0.7 of the currently free heap space (1193 MB), memory will be allocated lazily.
2020-02-28 02:16:19,847 [main] INFO  (TaskManagerConfiguration.java:197) - Messages have a max timeout of 10000 ms
2020-02-28 02:16:19,855 [main] INFO  (AkkaRpcService.java:223) - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-02-28 02:16:19,868 [flink-akka.actor.default-dispatcher-3] INFO  (JobLeaderService.java:125) - Start job leader service.
2020-02-28 02:16:19,869 [flink-akka.actor.default-dispatcher-3] INFO  (FileCache.java:107) - User file cache uses directory /tmp/flink-dist-cache-702e34e5-8a48-4e69-a3a4-feded6d44365
2020-02-28 02:16:19,902 [main] INFO  (RestServerEndpoint.java:136) - Starting rest endpoint.
2020-02-28 02:16:19,959 [main] WARN  (WebMonitorUtils.java:87) - Log file environment variable 'log.file' is not set.
2020-02-28 02:16:19,959 [main] WARN  (WebMonitorUtils.java:93) - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-02-28 02:16:19,968 [main] INFO  (DispatcherRestEndpoint.java:113) - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-02-28 02:16:20,100 [main] INFO  (RestServerEndpoint.java:233) - Rest endpoint listening at localhost:37659
2020-02-28 02:16:20,101 [main] INFO  (EmbeddedLeaderService.java:300) - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@5e8c34a0 @ http://localhost:37659
2020-02-28 02:16:20,108 [mini-cluster-io-thread-1] INFO  (WebMonitorEndpoint.java:712) - http://localhost:37659 was granted leadership with leaderSessionID=d36f2d36-3094-4d88-a497-614ae5eea3b0
2020-02-28 02:16:20,110 [mini-cluster-io-thread-1] INFO  (EmbeddedLeaderService.java:250) - Received confirmation of leadership for leader http://localhost:37659 , session=d36f2d36-3094-4d88-a497-614ae5eea3b0
2020-02-28 02:16:20,124 [main] INFO  (AkkaRpcService.java:223) - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-02-28 02:16:20,138 [main] INFO  (AkkaRpcService.java:223) - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-02-28 02:16:20,151 [flink-akka.actor.default-dispatcher-3] INFO  (EmbeddedLeaderService.java:300) - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@39315c0f @ akka://flink/user/resourcemanager
2020-02-28 02:16:20,151 [flink-akka.actor.default-dispatcher-2] INFO  (EmbeddedLeaderService.java:300) - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@7473d3ad @ akka://flink/user/dispatcher
2020-02-28 02:16:20,153 [flink-akka.actor.default-dispatcher-3] INFO  (ResourceManager.java:925) - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token ae76c439f1e2424e2dfcda5a4ff34ee4
2020-02-28 02:16:20,157 [flink-akka.actor.default-dispatcher-3] INFO  (SlotManagerImpl.java:219) - Starting the SlotManager.
2020-02-28 02:16:20,159 [flink-akka.actor.default-dispatcher-2] INFO  (Dispatcher.java:884) - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token ee6db5c6-454b-4477-8f49-62df427d121f
2020-02-28 02:16:20,162 [main] INFO  (MiniCluster.java:362) - Flink Mini Cluster started successfully
2020-02-28 02:16:20,166 [flink-akka.actor.default-dispatcher-3] INFO  (Dispatcher.java:716) - Recovering all persisted jobs.
2020-02-28 02:16:20,166 [flink-akka.actor.default-dispatcher-3] INFO  (EmbeddedLeaderService.java:250) - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=2dfcda5a-4ff3-4ee4-ae76-c439f1e2424e
2020-02-28 02:16:20,166 [flink-akka.actor.default-dispatcher-2] INFO  (EmbeddedLeaderService.java:250) - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=ee6db5c6-454b-4477-8f49-62df427d121f
2020-02-28 02:16:20,185 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:991) - Connecting to ResourceManager akka://flink/user/resourcemanager(ae76c439f1e2424e2dfcda5a4ff34ee4).
2020-02-28 02:16:20,191 [flink-akka.actor.default-dispatcher-3] INFO  (RetryingRegistration.java:155) - Resolved ResourceManager address, beginning registration
2020-02-28 02:16:20,191 [flink-akka.actor.default-dispatcher-3] INFO  (RetryingRegistration.java:204) - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-02-28 02:16:20,195 [flink-akka.actor.default-dispatcher-2] INFO  (Dispatcher.java:264) - Received JobGraph submission dd8b4cb5d0044ad3909492e463f3ebcc (Streaming FirstAlgorithmPass).
2020-02-28 02:16:20,196 [flink-akka.actor.default-dispatcher-2] INFO  (Dispatcher.java:321) - Submitting job dd8b4cb5d0044ad3909492e463f3ebcc (Streaming FirstAlgorithmPass).
2020-02-28 02:16:20,205 [flink-akka.actor.default-dispatcher-3] INFO  (ResourceManager.java:717) - Registering TaskManager with ResourceID 6c8c40a1-1cf4-4562-88db-fd4066c5353e (akka://flink/user/taskmanager_0) at ResourceManager
2020-02-28 02:16:20,208 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutorToResourceManagerConnection.java:100) - Successful registration at resource manager akka://flink/user/resourcemanager under registration id 2b2f4d9e89ec0e8083b907648abfc0a0.
2020-02-28 02:16:20,239 [flink-akka.actor.default-dispatcher-5] INFO  (AkkaRpcService.java:223) - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-02-28 02:16:20,251 [flink-akka.actor.default-dispatcher-5] INFO  (JobMaster.java:242) - Initializing job Streaming FirstAlgorithmPass (dd8b4cb5d0044ad3909492e463f3ebcc).
2020-02-28 02:16:20,272 [flink-akka.actor.default-dispatcher-5] INFO  (LegacyScheduler.java:171) - Using restart strategy NoRestartStrategy for Streaming FirstAlgorithmPass (dd8b4cb5d0044ad3909492e463f3ebcc).
2020-02-28 02:16:20,289 [flink-akka.actor.default-dispatcher-5] INFO  (ExecutionGraph.java:519) - Job recovers via failover strategy: full graph restart
2020-02-28 02:16:20,302 [flink-akka.actor.default-dispatcher-5] INFO  (ExecutionGraphBuilder.java:204) - Running initialization on master for job Streaming FirstAlgorithmPass (dd8b4cb5d0044ad3909492e463f3ebcc).
2020-02-28 02:16:20,303 [flink-akka.actor.default-dispatcher-5] INFO  (ExecutionGraphBuilder.java:222) - Successfully ran initialization on master in 0 ms.
2020-02-28 02:16:20,344 [flink-akka.actor.default-dispatcher-5] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:20,354 [flink-akka.actor.default-dispatcher-5] INFO  (EmbeddedLeaderService.java:300) - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@6755f91d @ akka://flink/user/jobmanager_1
2020-02-28 02:16:20,355 [mini-cluster-io-thread-3] INFO  (JobManagerRunner.java:313) - JobManager runner for job Streaming FirstAlgorithmPass (dd8b4cb5d0044ad3909492e463f3ebcc) was granted leadership with session id ffa730c3-d82f-4f4d-9908-c0981834fe78 at akka://flink/user/jobmanager_1.
2020-02-28 02:16:20,359 [flink-akka.actor.default-dispatcher-2] INFO  (JobMaster.java:712) - Starting execution of job Streaming FirstAlgorithmPass (dd8b4cb5d0044ad3909492e463f3ebcc) under job master id 9908c0981834fe78ffa730c3d82f4f4d.
2020-02-28 02:16:20,360 [flink-akka.actor.default-dispatcher-2] INFO  (ExecutionGraph.java:1325) - Job Streaming FirstAlgorithmPass (dd8b4cb5d0044ad3909492e463f3ebcc) switched from state CREATED to RUNNING.
2020-02-28 02:16:20,364 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source (1/4) (e3042c6488ffa19f3f8abf97064d18aa) switched from CREATED to SCHEDULED.
2020-02-28 02:16:20,376 [flink-akka.actor.default-dispatcher-2] INFO  (SlotPoolImpl.java:369) - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{3d4c42c35d2c3345b05fe4544bdb1698}]
2020-02-28 02:16:20,382 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source (2/4) (b4098daf51b253e782e08be0eb6c932b) switched from CREATED to SCHEDULED.
2020-02-28 02:16:20,383 [flink-akka.actor.default-dispatcher-2] INFO  (SlotPoolImpl.java:369) - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{c33d47449437d9dbfb2883b6848f47ed}]
2020-02-28 02:16:20,383 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source (3/4) (4fba671fcd5b7a18ea1d094bd1281a68) switched from CREATED to SCHEDULED.
2020-02-28 02:16:20,383 [flink-akka.actor.default-dispatcher-2] INFO  (SlotPoolImpl.java:369) - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{2432879fc37d605b062d9e8df03789f8}]
2020-02-28 02:16:20,383 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source (4/4) (f9a74775e968d243f85a2174ff7b4441) switched from CREATED to SCHEDULED.
2020-02-28 02:16:20,384 [flink-akka.actor.default-dispatcher-2] INFO  (SlotPoolImpl.java:369) - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{66479f7be1b6834e901d1f31ec64109a}]
2020-02-28 02:16:20,384 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4) (f8bcdc5fe640805c562ff80dffbe5915) switched from CREATED to SCHEDULED.
2020-02-28 02:16:20,384 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4) (3f455d03538a66bbb872995c2430a04a) switched from CREATED to SCHEDULED.
2020-02-28 02:16:20,384 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4) (d8bcc4786e1c0e9c2686f8b974cfbcc8) switched from CREATED to SCHEDULED.
2020-02-28 02:16:20,385 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4) (d701dc4adb4920a01de93f12d80e197e) switched from CREATED to SCHEDULED.
2020-02-28 02:16:20,385 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Sink: Print to Std. Out (1/4) (1317bb09b39a909a9da03d2d4edeb559) switched from CREATED to SCHEDULED.
2020-02-28 02:16:20,386 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Sink: Print to Std. Out (2/4) (5fae16fdb39a6d4a69be696ace3a65dc) switched from CREATED to SCHEDULED.
2020-02-28 02:16:20,386 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Sink: Print to Std. Out (3/4) (cec6435759317a83d4523a320dfd2739) switched from CREATED to SCHEDULED.
2020-02-28 02:16:20,387 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Sink: Print to Std. Out (4/4) (099e3a844d2d8583c68b37585eaa2258) switched from CREATED to SCHEDULED.
2020-02-28 02:16:20,387 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (1/4) (cf27a4208ea0a136e35c50264cf0bd8f) switched from CREATED to SCHEDULED.
2020-02-28 02:16:20,387 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (2/4) (42534cd96c1a15c82493d0bce6a80e1d) switched from CREATED to SCHEDULED.
2020-02-28 02:16:20,388 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (3/4) (e38ebfa08ef22b8cde6d49972638e73a) switched from CREATED to SCHEDULED.
2020-02-28 02:16:20,388 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (4/4) (00c42eabcbd7e11243cd647287bb5c61) switched from CREATED to SCHEDULED.
2020-02-28 02:16:20,388 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (1/4) (a70074e765076a11226762c45fc7718f) switched from CREATED to SCHEDULED.
2020-02-28 02:16:20,388 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (2/4) (d6d2c3703aeafb2bd3bab44cf0475149) switched from CREATED to SCHEDULED.
2020-02-28 02:16:20,389 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (3/4) (339acb37becc9a96a1ac51ff8ee19031) switched from CREATED to SCHEDULED.
2020-02-28 02:16:20,389 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (4/4) (41baeea2ca7a14e856aa85634a8909ec) switched from CREATED to SCHEDULED.
2020-02-28 02:16:20,389 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4) (f9fb52dbdbc2715b648c31b67571fe57) switched from CREATED to SCHEDULED.
2020-02-28 02:16:20,389 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4) (e4e97c0a5169e59f2946e70e34b53da3) switched from CREATED to SCHEDULED.
2020-02-28 02:16:20,390 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4) (d1fb0d0d867df6bdf5daca3c846e298f) switched from CREATED to SCHEDULED.
2020-02-28 02:16:20,390 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4) (107eb8393d64af9b08a1ad30b199ba83) switched from CREATED to SCHEDULED.
2020-02-28 02:16:20,390 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Flat Map (1/4) (17c67f01010578a1a0a037d0f9c359d1) switched from CREATED to SCHEDULED.
2020-02-28 02:16:20,390 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Flat Map (2/4) (fe89b8f10cb5459ff4804a0b6a2e9c3d) switched from CREATED to SCHEDULED.
2020-02-28 02:16:20,390 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Flat Map (3/4) (66ec15e1371d3dedab06eb2c9883a0bf) switched from CREATED to SCHEDULED.
2020-02-28 02:16:20,390 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Flat Map (4/4) (51b60f66c62142d3cd295a74431c1786) switched from CREATED to SCHEDULED.
2020-02-28 02:16:20,392 [jobmanager-future-thread-1] INFO  (EmbeddedLeaderService.java:250) - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=ffa730c3-d82f-4f4d-9908-c0981834fe78
2020-02-28 02:16:20,395 [flink-akka.actor.default-dispatcher-2] INFO  (JobMaster.java:936) - Connecting to ResourceManager akka://flink/user/resourcemanager(ae76c439f1e2424e2dfcda5a4ff34ee4)
2020-02-28 02:16:20,397 [flink-akka.actor.default-dispatcher-3] INFO  (RetryingRegistration.java:155) - Resolved ResourceManager address, beginning registration
2020-02-28 02:16:20,398 [flink-akka.actor.default-dispatcher-3] INFO  (RetryingRegistration.java:204) - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-02-28 02:16:20,399 [flink-akka.actor.default-dispatcher-4] INFO  (ResourceManager.java:306) - Registering job manager 9908c0981834fe78ffa730c3d82f4f4d@akka://flink/user/jobmanager_1 for job dd8b4cb5d0044ad3909492e463f3ebcc.
2020-02-28 02:16:20,404 [flink-akka.actor.default-dispatcher-3] INFO  (ResourceManager.java:661) - Registered job manager 9908c0981834fe78ffa730c3d82f4f4d@akka://flink/user/jobmanager_1 for job dd8b4cb5d0044ad3909492e463f3ebcc.
2020-02-28 02:16:20,406 [flink-akka.actor.default-dispatcher-2] INFO  (JobMaster.java:958) - JobManager successfully registered at ResourceManager, leader id: ae76c439f1e2424e2dfcda5a4ff34ee4.
2020-02-28 02:16:20,406 [flink-akka.actor.default-dispatcher-2] INFO  (SlotPoolImpl.java:319) - Requesting new slot [SlotRequestId{3d4c42c35d2c3345b05fe4544bdb1698}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-02-28 02:16:20,408 [flink-akka.actor.default-dispatcher-4] INFO  (ResourceManager.java:441) - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job dd8b4cb5d0044ad3909492e463f3ebcc with allocation id cbd9c41254f1dedba99d22fb8444527f.
2020-02-28 02:16:20,408 [flink-akka.actor.default-dispatcher-2] INFO  (SlotPoolImpl.java:319) - Requesting new slot [SlotRequestId{c33d47449437d9dbfb2883b6848f47ed}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-02-28 02:16:20,408 [flink-akka.actor.default-dispatcher-2] INFO  (SlotPoolImpl.java:319) - Requesting new slot [SlotRequestId{2432879fc37d605b062d9e8df03789f8}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-02-28 02:16:20,409 [flink-akka.actor.default-dispatcher-2] INFO  (SlotPoolImpl.java:319) - Requesting new slot [SlotRequestId{66479f7be1b6834e901d1f31ec64109a}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-02-28 02:16:20,411 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:822) - Receive slot request cbd9c41254f1dedba99d22fb8444527f for job dd8b4cb5d0044ad3909492e463f3ebcc from resource manager with leader id ae76c439f1e2424e2dfcda5a4ff34ee4.
2020-02-28 02:16:20,414 [flink-akka.actor.default-dispatcher-4] INFO  (ResourceManager.java:441) - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job dd8b4cb5d0044ad3909492e463f3ebcc with allocation id e117028350e01c5a2bfc9026b5b54986.
2020-02-28 02:16:20,415 [flink-akka.actor.default-dispatcher-4] INFO  (ResourceManager.java:441) - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job dd8b4cb5d0044ad3909492e463f3ebcc with allocation id 1d2d923aad85b037e9965526ca2f2a5d.
2020-02-28 02:16:20,415 [flink-akka.actor.default-dispatcher-4] INFO  (ResourceManager.java:441) - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job dd8b4cb5d0044ad3909492e463f3ebcc with allocation id fa4a718d1523e7c499497a5645156e20.
2020-02-28 02:16:20,416 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:834) - Allocated slot for cbd9c41254f1dedba99d22fb8444527f.
2020-02-28 02:16:20,417 [flink-akka.actor.default-dispatcher-2] INFO  (JobLeaderService.java:193) - Add job dd8b4cb5d0044ad3909492e463f3ebcc for job leader monitoring.
2020-02-28 02:16:20,418 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:822) - Receive slot request e117028350e01c5a2bfc9026b5b54986 for job dd8b4cb5d0044ad3909492e463f3ebcc from resource manager with leader id ae76c439f1e2424e2dfcda5a4ff34ee4.
2020-02-28 02:16:20,418 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:834) - Allocated slot for e117028350e01c5a2bfc9026b5b54986.
2020-02-28 02:16:20,419 [flink-akka.actor.default-dispatcher-2] INFO  (JobLeaderService.java:193) - Add job dd8b4cb5d0044ad3909492e463f3ebcc for job leader monitoring.
2020-02-28 02:16:20,418 [mini-cluster-io-thread-1] INFO  (JobLeaderService.java:333) - Try to register at job manager akka://flink/user/jobmanager_1 with leader id ffa730c3-d82f-4f4d-9908-c0981834fe78.
2020-02-28 02:16:20,420 [flink-akka.actor.default-dispatcher-5] INFO  (RetryingRegistration.java:155) - Resolved JobManager address, beginning registration
2020-02-28 02:16:20,420 [flink-akka.actor.default-dispatcher-5] INFO  (RetryingRegistration.java:204) - Registration at JobManager attempt 1 (timeout=100ms)
2020-02-28 02:16:20,422 [mini-cluster-io-thread-3] INFO  (JobLeaderService.java:333) - Try to register at job manager akka://flink/user/jobmanager_1 with leader id ffa730c3-d82f-4f4d-9908-c0981834fe78.
2020-02-28 02:16:20,422 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:822) - Receive slot request 1d2d923aad85b037e9965526ca2f2a5d for job dd8b4cb5d0044ad3909492e463f3ebcc from resource manager with leader id ae76c439f1e2424e2dfcda5a4ff34ee4.
2020-02-28 02:16:20,422 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:834) - Allocated slot for 1d2d923aad85b037e9965526ca2f2a5d.
2020-02-28 02:16:20,423 [flink-akka.actor.default-dispatcher-2] INFO  (JobLeaderService.java:193) - Add job dd8b4cb5d0044ad3909492e463f3ebcc for job leader monitoring.
2020-02-28 02:16:20,423 [mini-cluster-io-thread-2] INFO  (JobLeaderService.java:333) - Try to register at job manager akka://flink/user/jobmanager_1 with leader id ffa730c3-d82f-4f4d-9908-c0981834fe78.
2020-02-28 02:16:20,423 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:822) - Receive slot request fa4a718d1523e7c499497a5645156e20 for job dd8b4cb5d0044ad3909492e463f3ebcc from resource manager with leader id ae76c439f1e2424e2dfcda5a4ff34ee4.
2020-02-28 02:16:20,423 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:834) - Allocated slot for fa4a718d1523e7c499497a5645156e20.
2020-02-28 02:16:20,423 [flink-akka.actor.default-dispatcher-2] INFO  (JobLeaderService.java:193) - Add job dd8b4cb5d0044ad3909492e463f3ebcc for job leader monitoring.
2020-02-28 02:16:20,424 [mini-cluster-io-thread-4] INFO  (JobLeaderService.java:333) - Try to register at job manager akka://flink/user/jobmanager_1 with leader id ffa730c3-d82f-4f4d-9908-c0981834fe78.
2020-02-28 02:16:20,426 [flink-akka.actor.default-dispatcher-4] INFO  (RetryingRegistration.java:155) - Resolved JobManager address, beginning registration
2020-02-28 02:16:20,427 [flink-akka.actor.default-dispatcher-5] INFO  (RetryingRegistration.java:155) - Resolved JobManager address, beginning registration
2020-02-28 02:16:20,428 [flink-akka.actor.default-dispatcher-5] INFO  (RetryingRegistration.java:204) - Registration at JobManager attempt 1 (timeout=100ms)
2020-02-28 02:16:20,427 [flink-akka.actor.default-dispatcher-3] INFO  (RetryingRegistration.java:155) - Resolved JobManager address, beginning registration
2020-02-28 02:16:20,429 [flink-akka.actor.default-dispatcher-4] INFO  (JobLeaderService.java:382) - Successful registration at job manager akka://flink/user/jobmanager_1 for job dd8b4cb5d0044ad3909492e463f3ebcc.
2020-02-28 02:16:20,430 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:1227) - Establish JobManager connection for job dd8b4cb5d0044ad3909492e463f3ebcc.
2020-02-28 02:16:20,434 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:1128) - Offer reserved slots to the leader of job dd8b4cb5d0044ad3909492e463f3ebcc.
2020-02-28 02:16:20,450 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source (1/4) (e3042c6488ffa19f3f8abf97064d18aa) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:20,450 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:713) - Deploying Source: Custom Source (1/4) (attempt #0) to 6c8c40a1-1cf4-4562-88db-fd4066c5353e @ localhost (dataPort=-1)
2020-02-28 02:16:20,461 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source (2/4) (b4098daf51b253e782e08be0eb6c932b) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:20,461 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:713) - Deploying Source: Custom Source (2/4) (attempt #0) to 6c8c40a1-1cf4-4562-88db-fd4066c5353e @ localhost (dataPort=-1)
2020-02-28 02:16:20,468 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source (3/4) (4fba671fcd5b7a18ea1d094bd1281a68) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:20,469 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:713) - Deploying Source: Custom Source (3/4) (attempt #0) to 6c8c40a1-1cf4-4562-88db-fd4066c5353e @ localhost (dataPort=-1)
2020-02-28 02:16:20,469 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source (4/4) (f9a74775e968d243f85a2174ff7b4441) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:20,470 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:713) - Deploying Source: Custom Source (4/4) (attempt #0) to 6c8c40a1-1cf4-4562-88db-fd4066c5353e @ localhost (dataPort=-1)
2020-02-28 02:16:20,470 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4) (f8bcdc5fe640805c562ff80dffbe5915) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:20,471 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4) (attempt #0) to 6c8c40a1-1cf4-4562-88db-fd4066c5353e @ localhost (dataPort=-1)
2020-02-28 02:16:20,472 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4) (3f455d03538a66bbb872995c2430a04a) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:20,473 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4) (attempt #0) to 6c8c40a1-1cf4-4562-88db-fd4066c5353e @ localhost (dataPort=-1)
2020-02-28 02:16:20,474 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4) (d8bcc4786e1c0e9c2686f8b974cfbcc8) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:20,474 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4) (attempt #0) to 6c8c40a1-1cf4-4562-88db-fd4066c5353e @ localhost (dataPort=-1)
2020-02-28 02:16:20,475 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4) (d701dc4adb4920a01de93f12d80e197e) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:20,476 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4) (attempt #0) to 6c8c40a1-1cf4-4562-88db-fd4066c5353e @ localhost (dataPort=-1)
2020-02-28 02:16:20,476 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Sink: Print to Std. Out (1/4) (1317bb09b39a909a9da03d2d4edeb559) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:20,477 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:713) - Deploying Sink: Print to Std. Out (1/4) (attempt #0) to 6c8c40a1-1cf4-4562-88db-fd4066c5353e @ localhost (dataPort=-1)
2020-02-28 02:16:20,479 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Sink: Print to Std. Out (2/4) (5fae16fdb39a6d4a69be696ace3a65dc) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:20,479 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:713) - Deploying Sink: Print to Std. Out (2/4) (attempt #0) to 6c8c40a1-1cf4-4562-88db-fd4066c5353e @ localhost (dataPort=-1)
2020-02-28 02:16:20,480 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Sink: Print to Std. Out (3/4) (cec6435759317a83d4523a320dfd2739) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:20,481 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:713) - Deploying Sink: Print to Std. Out (3/4) (attempt #0) to 6c8c40a1-1cf4-4562-88db-fd4066c5353e @ localhost (dataPort=-1)
2020-02-28 02:16:20,481 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Sink: Print to Std. Out (4/4) (099e3a844d2d8583c68b37585eaa2258) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:20,482 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:713) - Deploying Sink: Print to Std. Out (4/4) (attempt #0) to 6c8c40a1-1cf4-4562-88db-fd4066c5353e @ localhost (dataPort=-1)
2020-02-28 02:16:20,483 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (1/4) (cf27a4208ea0a136e35c50264cf0bd8f) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:20,483 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (1/4) (attempt #0) to 6c8c40a1-1cf4-4562-88db-fd4066c5353e @ localhost (dataPort=-1)
2020-02-28 02:16:20,484 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (2/4) (42534cd96c1a15c82493d0bce6a80e1d) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:20,485 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (2/4) (attempt #0) to 6c8c40a1-1cf4-4562-88db-fd4066c5353e @ localhost (dataPort=-1)
2020-02-28 02:16:20,486 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (3/4) (e38ebfa08ef22b8cde6d49972638e73a) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:20,486 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (3/4) (attempt #0) to 6c8c40a1-1cf4-4562-88db-fd4066c5353e @ localhost (dataPort=-1)
2020-02-28 02:16:20,487 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (4/4) (00c42eabcbd7e11243cd647287bb5c61) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:20,488 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (4/4) (attempt #0) to 6c8c40a1-1cf4-4562-88db-fd4066c5353e @ localhost (dataPort=-1)
2020-02-28 02:16:20,489 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (1/4) (a70074e765076a11226762c45fc7718f) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:20,489 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (1/4) (attempt #0) to 6c8c40a1-1cf4-4562-88db-fd4066c5353e @ localhost (dataPort=-1)
2020-02-28 02:16:20,490 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (2/4) (d6d2c3703aeafb2bd3bab44cf0475149) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:20,491 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (2/4) (attempt #0) to 6c8c40a1-1cf4-4562-88db-fd4066c5353e @ localhost (dataPort=-1)
2020-02-28 02:16:20,492 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (3/4) (339acb37becc9a96a1ac51ff8ee19031) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:20,492 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (3/4) (attempt #0) to 6c8c40a1-1cf4-4562-88db-fd4066c5353e @ localhost (dataPort=-1)
2020-02-28 02:16:20,493 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (4/4) (41baeea2ca7a14e856aa85634a8909ec) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:20,494 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (4/4) (attempt #0) to 6c8c40a1-1cf4-4562-88db-fd4066c5353e @ localhost (dataPort=-1)
2020-02-28 02:16:20,498 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4) (f9fb52dbdbc2715b648c31b67571fe57) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:20,498 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4) (attempt #0) to 6c8c40a1-1cf4-4562-88db-fd4066c5353e @ localhost (dataPort=-1)
2020-02-28 02:16:20,500 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4) (e4e97c0a5169e59f2946e70e34b53da3) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:20,500 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4) (attempt #0) to 6c8c40a1-1cf4-4562-88db-fd4066c5353e @ localhost (dataPort=-1)
2020-02-28 02:16:20,501 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4) (d1fb0d0d867df6bdf5daca3c846e298f) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:20,502 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4) (attempt #0) to 6c8c40a1-1cf4-4562-88db-fd4066c5353e @ localhost (dataPort=-1)
2020-02-28 02:16:20,503 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4) (107eb8393d64af9b08a1ad30b199ba83) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:20,503 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4) (attempt #0) to 6c8c40a1-1cf4-4562-88db-fd4066c5353e @ localhost (dataPort=-1)
2020-02-28 02:16:20,504 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Flat Map (1/4) (17c67f01010578a1a0a037d0f9c359d1) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:20,505 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:713) - Deploying Flat Map (1/4) (attempt #0) to 6c8c40a1-1cf4-4562-88db-fd4066c5353e @ localhost (dataPort=-1)
2020-02-28 02:16:20,507 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Flat Map (2/4) (fe89b8f10cb5459ff4804a0b6a2e9c3d) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:20,507 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:713) - Deploying Flat Map (2/4) (attempt #0) to 6c8c40a1-1cf4-4562-88db-fd4066c5353e @ localhost (dataPort=-1)
2020-02-28 02:16:20,509 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Flat Map (3/4) (66ec15e1371d3dedab06eb2c9883a0bf) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:20,510 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:713) - Deploying Flat Map (3/4) (attempt #0) to 6c8c40a1-1cf4-4562-88db-fd4066c5353e @ localhost (dataPort=-1)
2020-02-28 02:16:20,511 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Flat Map (4/4) (51b60f66c62142d3cd295a74431c1786) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:20,511 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:713) - Deploying Flat Map (4/4) (attempt #0) to 6c8c40a1-1cf4-4562-88db-fd4066c5353e @ localhost (dataPort=-1)
2020-02-28 02:16:20,514 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source (1/4).
2020-02-28 02:16:20,517 [Source: Custom Source (1/4)] INFO  (Task.java:958) - Source: Custom Source (1/4) (e3042c6488ffa19f3f8abf97064d18aa) switched from CREATED to DEPLOYING.
2020-02-28 02:16:20,518 [Source: Custom Source (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source (1/4) (e3042c6488ffa19f3f8abf97064d18aa) [DEPLOYING]
2020-02-28 02:16:20,525 [Source: Custom Source (1/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source (1/4) (e3042c6488ffa19f3f8abf97064d18aa) [DEPLOYING].
2020-02-28 02:16:20,527 [Source: Custom Source (1/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source (1/4) (e3042c6488ffa19f3f8abf97064d18aa) [DEPLOYING].
2020-02-28 02:16:20,528 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source (2/4).
2020-02-28 02:16:20,538 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source (3/4).
2020-02-28 02:16:20,538 [Source: Custom Source (2/4)] INFO  (Task.java:958) - Source: Custom Source (2/4) (b4098daf51b253e782e08be0eb6c932b) switched from CREATED to DEPLOYING.
2020-02-28 02:16:20,538 [Source: Custom Source (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source (2/4) (b4098daf51b253e782e08be0eb6c932b) [DEPLOYING]
2020-02-28 02:16:20,539 [Source: Custom Source (2/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source (2/4) (b4098daf51b253e782e08be0eb6c932b) [DEPLOYING].
2020-02-28 02:16:20,540 [Source: Custom Source (2/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source (2/4) (b4098daf51b253e782e08be0eb6c932b) [DEPLOYING].
2020-02-28 02:16:20,546 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source (4/4).
2020-02-28 02:16:20,546 [Source: Custom Source (3/4)] INFO  (Task.java:958) - Source: Custom Source (3/4) (4fba671fcd5b7a18ea1d094bd1281a68) switched from CREATED to DEPLOYING.
2020-02-28 02:16:20,547 [Source: Custom Source (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source (3/4) (4fba671fcd5b7a18ea1d094bd1281a68) [DEPLOYING]
2020-02-28 02:16:20,547 [Source: Custom Source (3/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source (3/4) (4fba671fcd5b7a18ea1d094bd1281a68) [DEPLOYING].
2020-02-28 02:16:20,548 [Source: Custom Source (3/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source (3/4) (4fba671fcd5b7a18ea1d094bd1281a68) [DEPLOYING].
2020-02-28 02:16:20,551 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4).
2020-02-28 02:16:20,552 [Source: Custom Source (4/4)] INFO  (Task.java:958) - Source: Custom Source (4/4) (f9a74775e968d243f85a2174ff7b4441) switched from CREATED to DEPLOYING.
2020-02-28 02:16:20,553 [Source: Custom Source (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source (4/4) (f9a74775e968d243f85a2174ff7b4441) [DEPLOYING]
2020-02-28 02:16:20,553 [Source: Custom Source (4/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source (4/4) (f9a74775e968d243f85a2174ff7b4441) [DEPLOYING].
2020-02-28 02:16:20,554 [Source: Custom Source (4/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source (4/4) (f9a74775e968d243f85a2174ff7b4441) [DEPLOYING].
2020-02-28 02:16:20,557 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4).
2020-02-28 02:16:20,558 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4) (f8bcdc5fe640805c562ff80dffbe5915) switched from CREATED to DEPLOYING.
2020-02-28 02:16:20,559 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4) (f8bcdc5fe640805c562ff80dffbe5915) [DEPLOYING]
2020-02-28 02:16:20,559 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4) (f8bcdc5fe640805c562ff80dffbe5915) [DEPLOYING].
2020-02-28 02:16:20,560 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4) (f8bcdc5fe640805c562ff80dffbe5915) [DEPLOYING].
2020-02-28 02:16:20,569 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4).
2020-02-28 02:16:20,570 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4) (3f455d03538a66bbb872995c2430a04a) switched from CREATED to DEPLOYING.
2020-02-28 02:16:20,570 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4) (3f455d03538a66bbb872995c2430a04a) [DEPLOYING]
2020-02-28 02:16:20,570 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4) (3f455d03538a66bbb872995c2430a04a) [DEPLOYING].
2020-02-28 02:16:20,575 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4) (d8bcc4786e1c0e9c2686f8b974cfbcc8) switched from CREATED to DEPLOYING.
2020-02-28 02:16:20,575 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4) (d8bcc4786e1c0e9c2686f8b974cfbcc8) [DEPLOYING]
2020-02-28 02:16:20,575 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4) (d8bcc4786e1c0e9c2686f8b974cfbcc8) [DEPLOYING].
2020-02-28 02:16:20,576 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4).
2020-02-28 02:16:20,578 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4) (d8bcc4786e1c0e9c2686f8b974cfbcc8) [DEPLOYING].
2020-02-28 02:16:20,583 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4) (3f455d03538a66bbb872995c2430a04a) [DEPLOYING].
2020-02-28 02:16:20,591 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4) (d701dc4adb4920a01de93f12d80e197e) switched from CREATED to DEPLOYING.
2020-02-28 02:16:20,592 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4) (d701dc4adb4920a01de93f12d80e197e) [DEPLOYING]
2020-02-28 02:16:20,592 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4) (d701dc4adb4920a01de93f12d80e197e) [DEPLOYING].
2020-02-28 02:16:20,593 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4) (d701dc4adb4920a01de93f12d80e197e) [DEPLOYING].
2020-02-28 02:16:20,595 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4) (d8bcc4786e1c0e9c2686f8b974cfbcc8) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,596 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4) (d8bcc4786e1c0e9c2686f8b974cfbcc8) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,598 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:20,600 [Source: Custom Source (4/4)] INFO  (Task.java:958) - Source: Custom Source (4/4) (f9a74775e968d243f85a2174ff7b4441) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,601 [Source: Custom Source (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:20,601 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Source: Custom Source (4/4) (f9a74775e968d243f85a2174ff7b4441) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,606 [Source: Custom Source (3/4)] INFO  (Task.java:958) - Source: Custom Source (3/4) (4fba671fcd5b7a18ea1d094bd1281a68) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,607 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source (3/4) (4fba671fcd5b7a18ea1d094bd1281a68) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,607 [Source: Custom Source (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:20,612 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:592) - Received task Sink: Print to Std. Out (1/4).
2020-02-28 02:16:20,615 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4) (d701dc4adb4920a01de93f12d80e197e) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,615 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4) (f8bcdc5fe640805c562ff80dffbe5915) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,615 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4) (d701dc4adb4920a01de93f12d80e197e) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,615 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:20,616 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4) (f8bcdc5fe640805c562ff80dffbe5915) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,615 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:20,623 [Source: Custom Source (1/4)] INFO  (Task.java:958) - Source: Custom Source (1/4) (e3042c6488ffa19f3f8abf97064d18aa) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,623 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source (1/4) (e3042c6488ffa19f3f8abf97064d18aa) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,623 [Source: Custom Source (2/4)] INFO  (Task.java:958) - Source: Custom Source (2/4) (b4098daf51b253e782e08be0eb6c932b) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,623 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4) (3f455d03538a66bbb872995c2430a04a) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,624 [Source: Custom Source (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:20,623 [Source: Custom Source (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:20,625 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source (2/4) (b4098daf51b253e782e08be0eb6c932b) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,624 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:20,625 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4) (3f455d03538a66bbb872995c2430a04a) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,631 [Sink: Print to Std. Out (1/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (1/4) (1317bb09b39a909a9da03d2d4edeb559) switched from CREATED to DEPLOYING.
2020-02-28 02:16:20,631 [Sink: Print to Std. Out (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (1/4) (1317bb09b39a909a9da03d2d4edeb559) [DEPLOYING]
2020-02-28 02:16:20,632 [Sink: Print to Std. Out (1/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Print to Std. Out (1/4) (1317bb09b39a909a9da03d2d4edeb559) [DEPLOYING].
2020-02-28 02:16:20,633 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:592) - Received task Sink: Print to Std. Out (2/4).
2020-02-28 02:16:20,635 [Sink: Print to Std. Out (1/4)] INFO  (Task.java:619) - Registering task at network: Sink: Print to Std. Out (1/4) (1317bb09b39a909a9da03d2d4edeb559) [DEPLOYING].
2020-02-28 02:16:20,639 [Sink: Print to Std. Out (1/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (1/4) (1317bb09b39a909a9da03d2d4edeb559) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,642 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:592) - Received task Sink: Print to Std. Out (3/4).
2020-02-28 02:16:20,643 [Sink: Print to Std. Out (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:20,643 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Print to Std. Out (1/4) (1317bb09b39a909a9da03d2d4edeb559) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,643 [Sink: Print to Std. Out (2/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (2/4) (5fae16fdb39a6d4a69be696ace3a65dc) switched from CREATED to DEPLOYING.
2020-02-28 02:16:20,643 [Sink: Print to Std. Out (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (2/4) (5fae16fdb39a6d4a69be696ace3a65dc) [DEPLOYING]
2020-02-28 02:16:20,643 [Sink: Print to Std. Out (2/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Print to Std. Out (2/4) (5fae16fdb39a6d4a69be696ace3a65dc) [DEPLOYING].
2020-02-28 02:16:20,647 [Sink: Print to Std. Out (2/4)] INFO  (Task.java:619) - Registering task at network: Sink: Print to Std. Out (2/4) (5fae16fdb39a6d4a69be696ace3a65dc) [DEPLOYING].
2020-02-28 02:16:20,648 [Sink: Print to Std. Out (2/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (2/4) (5fae16fdb39a6d4a69be696ace3a65dc) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,648 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Sink: Print to Std. Out (2/4) (5fae16fdb39a6d4a69be696ace3a65dc) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,649 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] WARN  (FlinkKafkaProducer.java:998) - Using EXACTLY_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-02-28 02:16:20,650 [Sink: Print to Std. Out (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:20,651 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] WARN  (FlinkKafkaProducer.java:998) - Using EXACTLY_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-02-28 02:16:20,652 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:592) - Received task Sink: Print to Std. Out (4/4).
2020-02-28 02:16:20,653 [Sink: Print to Std. Out (3/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (3/4) (cec6435759317a83d4523a320dfd2739) switched from CREATED to DEPLOYING.
2020-02-28 02:16:20,653 [Sink: Print to Std. Out (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (3/4) (cec6435759317a83d4523a320dfd2739) [DEPLOYING]
2020-02-28 02:16:20,653 [Sink: Print to Std. Out (3/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Print to Std. Out (3/4) (cec6435759317a83d4523a320dfd2739) [DEPLOYING].
2020-02-28 02:16:20,654 [Sink: Print to Std. Out (3/4)] INFO  (Task.java:619) - Registering task at network: Sink: Print to Std. Out (3/4) (cec6435759317a83d4523a320dfd2739) [DEPLOYING].
2020-02-28 02:16:20,654 [Sink: Print to Std. Out (3/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (3/4) (cec6435759317a83d4523a320dfd2739) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,656 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Print to Std. Out (3/4) (cec6435759317a83d4523a320dfd2739) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,657 [Sink: Print to Std. Out (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:20,657 [Source: Custom Source (2/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-28 02:16:20,657 [Source: Custom Source (2/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-28 02:16:20,660 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] WARN  (FlinkKafkaProducer.java:998) - Using EXACTLY_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-02-28 02:16:20,661 [Source: Custom Source (1/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-28 02:16:20,661 [Source: Custom Source (1/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-28 02:16:20,661 [Source: Custom Source (3/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-28 02:16:20,661 [Source: Custom Source (3/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-28 02:16:20,662 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (1/4).
2020-02-28 02:16:20,656 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (TwoPhaseCommitSinkFunction.java:366) - FlinkKafkaProducer 3/4 - no state to restore
2020-02-28 02:16:20,661 [Source: Custom Source (4/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-28 02:16:20,663 [Source: Custom Source (4/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-28 02:16:20,664 [Sink: Print to Std. Out (4/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (4/4) (099e3a844d2d8583c68b37585eaa2258) switched from CREATED to DEPLOYING.
2020-02-28 02:16:20,664 [Sink: Print to Std. Out (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (4/4) (099e3a844d2d8583c68b37585eaa2258) [DEPLOYING]
2020-02-28 02:16:20,664 [Sink: Print to Std. Out (4/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Print to Std. Out (4/4) (099e3a844d2d8583c68b37585eaa2258) [DEPLOYING].
2020-02-28 02:16:20,661 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (TwoPhaseCommitSinkFunction.java:366) - FlinkKafkaProducer 0/4 - no state to restore
2020-02-28 02:16:20,660 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (TwoPhaseCommitSinkFunction.java:366) - FlinkKafkaProducer 1/4 - no state to restore
2020-02-28 02:16:20,668 [Sink: Print to Std. Out (4/4)] INFO  (Task.java:619) - Registering task at network: Sink: Print to Std. Out (4/4) (099e3a844d2d8583c68b37585eaa2258) [DEPLOYING].
2020-02-28 02:16:20,672 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] WARN  (FlinkKafkaProducer.java:998) - Using EXACTLY_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-02-28 02:16:20,672 [Sink: Print to Std. Out (4/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (4/4) (099e3a844d2d8583c68b37585eaa2258) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,677 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Sink: Print to Std. Out (4/4) (099e3a844d2d8583c68b37585eaa2258) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,677 [Sink: Print to Std. Out (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:20,677 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (1/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (1/4) (cf27a4208ea0a136e35c50264cf0bd8f) switched from CREATED to DEPLOYING.
2020-02-28 02:16:20,678 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (1/4) (cf27a4208ea0a136e35c50264cf0bd8f) [DEPLOYING]
2020-02-28 02:16:20,678 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (1/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (1/4) (cf27a4208ea0a136e35c50264cf0bd8f) [DEPLOYING].
2020-02-28 02:16:20,679 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (2/4).
2020-02-28 02:16:20,679 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (1/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (1/4) (cf27a4208ea0a136e35c50264cf0bd8f) [DEPLOYING].
2020-02-28 02:16:20,679 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (TwoPhaseCommitSinkFunction.java:366) - FlinkKafkaProducer 2/4 - no state to restore
2020-02-28 02:16:20,682 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (3/4).
2020-02-28 02:16:20,683 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (2/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (2/4) (42534cd96c1a15c82493d0bce6a80e1d) switched from CREATED to DEPLOYING.
2020-02-28 02:16:20,683 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (2/4) (42534cd96c1a15c82493d0bce6a80e1d) [DEPLOYING]
2020-02-28 02:16:20,684 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (2/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (2/4) (42534cd96c1a15c82493d0bce6a80e1d) [DEPLOYING].
2020-02-28 02:16:20,684 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (2/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (2/4) (42534cd96c1a15c82493d0bce6a80e1d) [DEPLOYING].
2020-02-28 02:16:20,687 [Source: Custom Source (2/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 1 has no restore state.
2020-02-28 02:16:20,687 [Source: Custom Source (1/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 0 has no restore state.
2020-02-28 02:16:20,687 [Source: Custom Source (3/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 2 has no restore state.
2020-02-28 02:16:20,687 [Source: Custom Source (4/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 3 has no restore state.
2020-02-28 02:16:20,700 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (1/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (1/4) (cf27a4208ea0a136e35c50264cf0bd8f) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,701 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (1/4) (cf27a4208ea0a136e35c50264cf0bd8f) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,701 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:20,711 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (3/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (3/4) (e38ebfa08ef22b8cde6d49972638e73a) switched from CREATED to DEPLOYING.
2020-02-28 02:16:20,712 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (3/4) (e38ebfa08ef22b8cde6d49972638e73a) [DEPLOYING]
2020-02-28 02:16:20,712 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (3/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (3/4) (e38ebfa08ef22b8cde6d49972638e73a) [DEPLOYING].
2020-02-28 02:16:20,713 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (3/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (3/4) (e38ebfa08ef22b8cde6d49972638e73a) [DEPLOYING].
2020-02-28 02:16:20,731 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (3/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (3/4) (e38ebfa08ef22b8cde6d49972638e73a) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,731 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (3/4) (e38ebfa08ef22b8cde6d49972638e73a) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,732 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:20,738 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (AbstractConfig.java:347) - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-02-28 02:16:20,739 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (AbstractConfig.java:347) - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-02-28 02:16:20,739 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (AbstractConfig.java:347) - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-02-28 02:16:20,738 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (AbstractConfig.java:347) - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-02-28 02:16:20,738 [Source: Custom Source (4/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:20,740 [Source: Custom Source (1/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:20,739 [Source: Custom Source (3/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:20,739 [Source: Custom Source (2/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:20,753 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (4/4).
2020-02-28 02:16:20,754 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (4/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (4/4) (00c42eabcbd7e11243cd647287bb5c61) switched from CREATED to DEPLOYING.
2020-02-28 02:16:20,755 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (1/4).
2020-02-28 02:16:20,769 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (2/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (2/4) (42534cd96c1a15c82493d0bce6a80e1d) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,769 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (4/4) (00c42eabcbd7e11243cd647287bb5c61) [DEPLOYING]
2020-02-28 02:16:20,766 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (3/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-28 02:16:20,769 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (4/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (4/4) (00c42eabcbd7e11243cd647287bb5c61) [DEPLOYING].
2020-02-28 02:16:20,766 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (1/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-28 02:16:20,778 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (2/4).
2020-02-28 02:16:20,777 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (4/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (4/4) (00c42eabcbd7e11243cd647287bb5c61) [DEPLOYING].
2020-02-28 02:16:20,773 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (1/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (1/4) (a70074e765076a11226762c45fc7718f) switched from CREATED to DEPLOYING.
2020-02-28 02:16:20,769 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:20,769 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (2/4) (42534cd96c1a15c82493d0bce6a80e1d) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,781 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (1/4) (a70074e765076a11226762c45fc7718f) [DEPLOYING]
2020-02-28 02:16:20,784 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (1/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (1/4) (a70074e765076a11226762c45fc7718f) [DEPLOYING].
2020-02-28 02:16:20,784 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (1/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (1/4) (a70074e765076a11226762c45fc7718f) [DEPLOYING].
2020-02-28 02:16:20,786 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (2/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-28 02:16:20,802 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (3/4).
2020-02-28 02:16:20,802 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (2/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (2/4) (d6d2c3703aeafb2bd3bab44cf0475149) switched from CREATED to DEPLOYING.
2020-02-28 02:16:20,803 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (2/4) (d6d2c3703aeafb2bd3bab44cf0475149) [DEPLOYING]
2020-02-28 02:16:20,803 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (2/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (2/4) (d6d2c3703aeafb2bd3bab44cf0475149) [DEPLOYING].
2020-02-28 02:16:20,804 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (2/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (2/4) (d6d2c3703aeafb2bd3bab44cf0475149) [DEPLOYING].
2020-02-28 02:16:20,809 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (4/4).
2020-02-28 02:16:20,810 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (3/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (3/4) (339acb37becc9a96a1ac51ff8ee19031) switched from CREATED to DEPLOYING.
2020-02-28 02:16:20,810 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (3/4) (339acb37becc9a96a1ac51ff8ee19031) [DEPLOYING]
2020-02-28 02:16:20,810 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (3/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (3/4) (339acb37becc9a96a1ac51ff8ee19031) [DEPLOYING].
2020-02-28 02:16:20,811 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (3/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (3/4) (339acb37becc9a96a1ac51ff8ee19031) [DEPLOYING].
2020-02-28 02:16:20,826 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (4/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (4/4) (00c42eabcbd7e11243cd647287bb5c61) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,827 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:20,828 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (4/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (4/4) (41baeea2ca7a14e856aa85634a8909ec) switched from CREATED to DEPLOYING.
2020-02-28 02:16:20,829 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (4/4) (00c42eabcbd7e11243cd647287bb5c61) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,829 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4).
2020-02-28 02:16:20,829 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (4/4) (41baeea2ca7a14e856aa85634a8909ec) [DEPLOYING]
2020-02-28 02:16:20,829 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (4/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (4/4) (41baeea2ca7a14e856aa85634a8909ec) [DEPLOYING].
2020-02-28 02:16:20,830 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (4/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (4/4) (41baeea2ca7a14e856aa85634a8909ec) [DEPLOYING].
2020-02-28 02:16:20,836 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4) (f9fb52dbdbc2715b648c31b67571fe57) switched from CREATED to DEPLOYING.
2020-02-28 02:16:20,837 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4) (f9fb52dbdbc2715b648c31b67571fe57) [DEPLOYING]
2020-02-28 02:16:20,837 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4) (f9fb52dbdbc2715b648c31b67571fe57) [DEPLOYING].
2020-02-28 02:16:20,838 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4) (f9fb52dbdbc2715b648c31b67571fe57) [DEPLOYING].
2020-02-28 02:16:20,839 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4).
2020-02-28 02:16:20,849 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (4/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-28 02:16:20,857 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4) (e4e97c0a5169e59f2946e70e34b53da3) switched from CREATED to DEPLOYING.
2020-02-28 02:16:20,857 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4) (e4e97c0a5169e59f2946e70e34b53da3) [DEPLOYING]
2020-02-28 02:16:20,857 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4) (e4e97c0a5169e59f2946e70e34b53da3) [DEPLOYING].
2020-02-28 02:16:20,857 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4) (e4e97c0a5169e59f2946e70e34b53da3) [DEPLOYING].
2020-02-28 02:16:20,868 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (1/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (1/4) (a70074e765076a11226762c45fc7718f) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,869 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:20,869 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (1/4) (a70074e765076a11226762c45fc7718f) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,872 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4).
2020-02-28 02:16:20,881 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4).
2020-02-28 02:16:20,884 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (4/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (4/4) (41baeea2ca7a14e856aa85634a8909ec) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,885 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (4/4) (41baeea2ca7a14e856aa85634a8909ec) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,885 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4) (d1fb0d0d867df6bdf5daca3c846e298f) switched from CREATED to DEPLOYING.
2020-02-28 02:16:20,885 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:20,888 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4) (d1fb0d0d867df6bdf5daca3c846e298f) [DEPLOYING]
2020-02-28 02:16:20,888 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4) (d1fb0d0d867df6bdf5daca3c846e298f) [DEPLOYING].
2020-02-28 02:16:20,900 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (4/4)] WARN  (TaskMetricGroup.java:143) - The operator name Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) exceeded the 80 characters length limit and was truncated.
2020-02-28 02:16:20,908 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (4/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-28 02:16:20,896 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (1/4)] WARN  (TaskMetricGroup.java:143) - The operator name Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) exceeded the 80 characters length limit and was truncated.
2020-02-28 02:16:20,896 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4) (107eb8393d64af9b08a1ad30b199ba83) switched from CREATED to DEPLOYING.
2020-02-28 02:16:20,909 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4) (107eb8393d64af9b08a1ad30b199ba83) [DEPLOYING]
2020-02-28 02:16:20,909 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4) (107eb8393d64af9b08a1ad30b199ba83) [DEPLOYING].
2020-02-28 02:16:20,909 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4) (107eb8393d64af9b08a1ad30b199ba83) [DEPLOYING].
2020-02-28 02:16:20,892 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Flat Map (1/4).
2020-02-28 02:16:20,910 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (1/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-28 02:16:20,914 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4) (d1fb0d0d867df6bdf5daca3c846e298f) [DEPLOYING].
2020-02-28 02:16:20,939 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Flat Map (2/4).
2020-02-28 02:16:20,939 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (2/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (2/4) (d6d2c3703aeafb2bd3bab44cf0475149) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,939 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:20,940 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Flat Map (3/4).
2020-02-28 02:16:20,940 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (2/4) (d6d2c3703aeafb2bd3bab44cf0475149) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,944 [Flat Map (1/4)] INFO  (Task.java:958) - Flat Map (1/4) (17c67f01010578a1a0a037d0f9c359d1) switched from CREATED to DEPLOYING.
2020-02-28 02:16:20,944 [Flat Map (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Flat Map (1/4) (17c67f01010578a1a0a037d0f9c359d1) [DEPLOYING]
2020-02-28 02:16:20,944 [Flat Map (1/4)] INFO  (Task.java:593) - Loading JAR files for task Flat Map (1/4) (17c67f01010578a1a0a037d0f9c359d1) [DEPLOYING].
2020-02-28 02:16:20,944 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (3/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (3/4) (339acb37becc9a96a1ac51ff8ee19031) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,945 [Flat Map (1/4)] INFO  (Task.java:619) - Registering task at network: Flat Map (1/4) (17c67f01010578a1a0a037d0f9c359d1) [DEPLOYING].
2020-02-28 02:16:20,944 [Flat Map (3/4)] INFO  (Task.java:958) - Flat Map (3/4) (66ec15e1371d3dedab06eb2c9883a0bf) switched from CREATED to DEPLOYING.
2020-02-28 02:16:20,944 [Flat Map (2/4)] INFO  (Task.java:958) - Flat Map (2/4) (fe89b8f10cb5459ff4804a0b6a2e9c3d) switched from CREATED to DEPLOYING.
2020-02-28 02:16:20,949 [Flat Map (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Flat Map (3/4) (66ec15e1371d3dedab06eb2c9883a0bf) [DEPLOYING]
2020-02-28 02:16:20,946 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4) (f9fb52dbdbc2715b648c31b67571fe57) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,945 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (2/4)] WARN  (TaskMetricGroup.java:143) - The operator name Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) exceeded the 80 characters length limit and was truncated.
2020-02-28 02:16:20,949 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:20,950 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:20,950 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:20,950 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582848980948
2020-02-28 02:16:20,945 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Flat Map (4/4).
2020-02-28 02:16:20,945 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:20,951 [Flat Map (3/4)] INFO  (Task.java:593) - Loading JAR files for task Flat Map (3/4) (66ec15e1371d3dedab06eb2c9883a0bf) [DEPLOYING].
2020-02-28 02:16:20,945 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (3/4) (339acb37becc9a96a1ac51ff8ee19031) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,953 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4) (f9fb52dbdbc2715b648c31b67571fe57) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,953 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (FlinkKafkaProducer.java:1158) - Starting FlinkKafkaInternalProducer (3/4) to produce into default topic _input1
2020-02-28 02:16:20,956 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-28 02:16:20,950 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (2/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-28 02:16:20,949 [Flat Map (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Flat Map (2/4) (fe89b8f10cb5459ff4804a0b6a2e9c3d) [DEPLOYING]
2020-02-28 02:16:20,961 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-28 02:16:20,962 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 2 has no restore state.
2020-02-28 02:16:20,963 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:20,961 [flink-akka.actor.default-dispatcher-3] INFO  (TaskSlotTable.java:242) - Activate slot fa4a718d1523e7c499497a5645156e20.
2020-02-28 02:16:20,964 [flink-akka.actor.default-dispatcher-3] INFO  (TaskSlotTable.java:242) - Activate slot cbd9c41254f1dedba99d22fb8444527f.
2020-02-28 02:16:20,964 [flink-akka.actor.default-dispatcher-3] INFO  (TaskSlotTable.java:242) - Activate slot e117028350e01c5a2bfc9026b5b54986.
2020-02-28 02:16:20,964 [flink-akka.actor.default-dispatcher-3] INFO  (TaskSlotTable.java:242) - Activate slot 1d2d923aad85b037e9965526ca2f2a5d.
2020-02-28 02:16:20,964 [Flat Map (2/4)] INFO  (Task.java:593) - Loading JAR files for task Flat Map (2/4) (fe89b8f10cb5459ff4804a0b6a2e9c3d) [DEPLOYING].
2020-02-28 02:16:20,961 [Flat Map (4/4)] INFO  (Task.java:958) - Flat Map (4/4) (51b60f66c62142d3cd295a74431c1786) switched from CREATED to DEPLOYING.
2020-02-28 02:16:20,953 [Flat Map (3/4)] INFO  (Task.java:619) - Registering task at network: Flat Map (3/4) (66ec15e1371d3dedab06eb2c9883a0bf) [DEPLOYING].
2020-02-28 02:16:20,978 [Flat Map (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Flat Map (4/4) (51b60f66c62142d3cd295a74431c1786) [DEPLOYING]
2020-02-28 02:16:20,961 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:20,979 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:20,975 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4)] WARN  (FlinkKafkaProducer.java:998) - Using EXACTLY_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-02-28 02:16:20,964 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (3/4)] WARN  (TaskMetricGroup.java:143) - The operator name Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) exceeded the 80 characters length limit and was truncated.
2020-02-28 02:16:20,980 [Flat Map (4/4)] INFO  (Task.java:593) - Loading JAR files for task Flat Map (4/4) (51b60f66c62142d3cd295a74431c1786) [DEPLOYING].
2020-02-28 02:16:20,979 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582848980961
2020-02-28 02:16:20,980 [Flat Map (1/4)] INFO  (Task.java:958) - Flat Map (1/4) (17c67f01010578a1a0a037d0f9c359d1) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,980 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4) (107eb8393d64af9b08a1ad30b199ba83) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,981 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4)] INFO  (TwoPhaseCommitSinkFunction.java:366) - FlinkKafkaProducer 0/4 - no state to restore
2020-02-28 02:16:20,982 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:20,982 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4)] INFO  (AbstractConfig.java:347) - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-02-28 02:16:20,980 [Flat Map (2/4)] INFO  (Task.java:619) - Registering task at network: Flat Map (2/4) (fe89b8f10cb5459ff4804a0b6a2e9c3d) [DEPLOYING].
2020-02-28 02:16:20,981 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (3/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-28 02:16:20,981 [Flat Map (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:20,980 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Flat Map (1/4) (17c67f01010578a1a0a037d0f9c359d1) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,998 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4) (107eb8393d64af9b08a1ad30b199ba83) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,993 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4)] WARN  (FlinkKafkaProducer.java:998) - Using EXACTLY_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-02-28 02:16:20,999 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4)] INFO  (TwoPhaseCommitSinkFunction.java:366) - FlinkKafkaProducer 3/4 - no state to restore
2020-02-28 02:16:20,999 [Flat Map (3/4)] INFO  (Task.java:958) - Flat Map (3/4) (66ec15e1371d3dedab06eb2c9883a0bf) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,999 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4)] INFO  (AbstractConfig.java:347) - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-02-28 02:16:21,000 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Flat Map (3/4) (66ec15e1371d3dedab06eb2c9883a0bf) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,989 [Flat Map (4/4)] INFO  (Task.java:619) - Registering task at network: Flat Map (4/4) (51b60f66c62142d3cd295a74431c1786) [DEPLOYING].
2020-02-28 02:16:21,001 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4) (d1fb0d0d867df6bdf5daca3c846e298f) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:21,007 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (FlinkKafkaProducer.java:1158) - Starting FlinkKafkaInternalProducer (1/4) to produce into default topic _input1
2020-02-28 02:16:21,007 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4) (d1fb0d0d867df6bdf5daca3c846e298f) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:20,999 [Flat Map (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:21,010 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-28 02:16:21,010 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-28 02:16:20,999 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4) (e4e97c0a5169e59f2946e70e34b53da3) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:21,010 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 0 has no restore state.
2020-02-28 02:16:21,011 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:21,011 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:21,012 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4) (e4e97c0a5169e59f2946e70e34b53da3) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:21,009 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:21,016 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:21,016 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582848980956
2020-02-28 02:16:21,007 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:21,007 [Flat Map (1/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-28 02:16:21,007 [Flat Map (2/4)] INFO  (Task.java:958) - Flat Map (2/4) (fe89b8f10cb5459ff4804a0b6a2e9c3d) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:21,017 [Flat Map (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:21,018 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Flat Map (2/4) (fe89b8f10cb5459ff4804a0b6a2e9c3d) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:21,016 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4)] WARN  (FlinkKafkaProducer.java:998) - Using EXACTLY_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-02-28 02:16:21,018 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4)] INFO  (TwoPhaseCommitSinkFunction.java:366) - FlinkKafkaProducer 1/4 - no state to restore
2020-02-28 02:16:21,025 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4)] INFO  (AbstractConfig.java:347) - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-02-28 02:16:21,015 [Flat Map (3/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-28 02:16:21,013 [Flat Map (4/4)] INFO  (Task.java:958) - Flat Map (4/4) (51b60f66c62142d3cd295a74431c1786) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:21,022 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4)] WARN  (FlinkKafkaProducer.java:998) - Using EXACTLY_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-02-28 02:16:21,026 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4)] INFO  (TwoPhaseCommitSinkFunction.java:366) - FlinkKafkaProducer 2/4 - no state to restore
2020-02-28 02:16:21,026 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4)] INFO  (AbstractConfig.java:347) - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-02-28 02:16:21,021 [Flat Map (2/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-28 02:16:21,027 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Flat Map (4/4) (51b60f66c62142d3cd295a74431c1786) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:21,027 [Flat Map (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:21,028 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (FlinkKafkaProducer.java:1158) - Starting FlinkKafkaInternalProducer (4/4) to produce into default topic _input1
2020-02-28 02:16:21,029 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-28 02:16:21,029 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-28 02:16:21,030 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 3 has no restore state.
2020-02-28 02:16:21,030 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:21,030 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:21,030 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:21,030 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582848980953
2020-02-28 02:16:21,037 [Flat Map (4/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-28 02:16:21,040 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (FlinkKafkaProducer.java:1158) - Starting FlinkKafkaInternalProducer (2/4) to produce into default topic _input1
2020-02-28 02:16:21,041 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-28 02:16:21,041 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-28 02:16:21,042 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 1 has no restore state.
2020-02-28 02:16:21,042 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:21,042 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:21,043 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:21,043 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582848981034
2020-02-28 02:16:21,043 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4)] INFO  (FlinkKafkaProducer.java:1158) - Starting FlinkKafkaInternalProducer (4/4) to produce into default topic output
2020-02-28 02:16:21,044 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-28 02:16:21,044 [Source: Custom Source (1/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:21,065 [Source: Custom Source (1/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:21,066 [Source: Custom Source (1/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582848981033
2020-02-28 02:16:21,066 [Source: Custom Source (2/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:21,066 [Source: Custom Source (2/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:21,066 [Source: Custom Source (2/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582848981032
2020-02-28 02:16:21,067 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:21,067 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:21,067 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582848981032
2020-02-28 02:16:21,068 [Source: Custom Source (4/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:21,068 [Source: Custom Source (4/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:21,068 [Source: Custom Source (4/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582848981031
2020-02-28 02:16:21,068 [Source: Custom Source (3/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:21,068 [Source: Custom Source (3/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:21,068 [Source: Custom Source (3/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582848981030
2020-02-28 02:16:21,069 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:21,069 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:21,069 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582848981030
2020-02-28 02:16:21,069 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4)] INFO  (FlinkKafkaProducer.java:1158) - Starting FlinkKafkaInternalProducer (1/4) to produce into default topic output
2020-02-28 02:16:21,069 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:21,070 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:21,070 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-28 02:16:21,070 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582848981028
2020-02-28 02:16:21,072 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:21,072 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:21,072 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582848981056
2020-02-28 02:16:21,072 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4)] INFO  (FlinkKafkaProducer.java:1158) - Starting FlinkKafkaInternalProducer (2/4) to produce into default topic output
2020-02-28 02:16:21,072 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:21,073 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:21,073 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582848981052
2020-02-28 02:16:21,073 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-28 02:16:21,073 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:21,073 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:21,073 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582848981051
2020-02-28 02:16:21,073 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4)] INFO  (FlinkKafkaProducer.java:1158) - Starting FlinkKafkaInternalProducer (3/4) to produce into default topic output
2020-02-28 02:16:21,074 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:21,074 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:21,074 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582848981048
2020-02-28 02:16:21,074 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-28 02:16:21,336 [kafka-producer-network-thread | producer-1] INFO  (Metadata.java:261) - [Producer clientId=producer-1] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:21,339 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-5, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:21,336 [kafka-producer-network-thread | producer-6] INFO  (Metadata.java:261) - [Producer clientId=producer-6] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:21,336 [kafka-producer-network-thread | producer-7] INFO  (Metadata.java:261) - [Producer clientId=producer-7] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:21,339 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-7, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:21,340 [Source: Custom Source (3/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-2, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:21,340 [Source: Custom Source (4/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-1, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:21,341 [kafka-producer-network-thread | producer-8] INFO  (Metadata.java:261) - [Producer clientId=producer-8] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:21,341 [Source: Custom Source (1/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-3, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:21,342 [kafka-producer-network-thread | producer-4] INFO  (Metadata.java:261) - [Producer clientId=producer-4] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:21,343 [kafka-producer-network-thread | producer-2] INFO  (Metadata.java:261) - [Producer clientId=producer-2] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:21,344 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-8, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:21,345 [Source: Custom Source (1/4)] INFO  (FlinkKafkaConsumerBase.java:604) - Consumer subtask 0 will start reading the following 2 partitions from the earliest offsets: [KafkaTopicPartition{topic='input1', partition=7}, KafkaTopicPartition{topic='input1', partition=3}]
2020-02-28 02:16:21,345 [Source: Custom Source (4/4)] INFO  (FlinkKafkaConsumerBase.java:604) - Consumer subtask 3 will start reading the following 2 partitions from the earliest offsets: [KafkaTopicPartition{topic='input1', partition=6}, KafkaTopicPartition{topic='input1', partition=2}]
2020-02-28 02:16:21,345 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (FlinkKafkaConsumerBase.java:604) - Consumer subtask 1 will start reading the following 2 partitions from the earliest offsets: [KafkaTopicPartition{topic='input1', partition=4}, KafkaTopicPartition{topic='input1', partition=0}]
2020-02-28 02:16:21,346 [Source: Custom Source (2/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-4, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:21,347 [kafka-producer-network-thread | producer-3] INFO  (Metadata.java:261) - [Producer clientId=producer-3] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:21,347 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-6, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:21,348 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (FlinkKafkaConsumerBase.java:604) - Consumer subtask 3 will start reading the following 2 partitions from the earliest offsets: [KafkaTopicPartition{topic='input1', partition=6}, KafkaTopicPartition{topic='input1', partition=2}]
2020-02-28 02:16:21,347 [kafka-producer-network-thread | producer-5] INFO  (Metadata.java:261) - [Producer clientId=producer-5] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:21,347 [Source: Custom Source (3/4)] INFO  (FlinkKafkaConsumerBase.java:604) - Consumer subtask 2 will start reading the following 2 partitions from the earliest offsets: [KafkaTopicPartition{topic='input1', partition=5}, KafkaTopicPartition{topic='input1', partition=1}]
2020-02-28 02:16:21,347 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (FlinkKafkaConsumerBase.java:604) - Consumer subtask 2 will start reading the following 2 partitions from the earliest offsets: [KafkaTopicPartition{topic='input1', partition=5}, KafkaTopicPartition{topic='input1', partition=1}]
2020-02-28 02:16:21,348 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (FlinkKafkaConsumerBase.java:604) - Consumer subtask 0 will start reading the following 2 partitions from the earliest offsets: [KafkaTopicPartition{topic='input1', partition=7}, KafkaTopicPartition{topic='input1', partition=3}]
2020-02-28 02:16:21,349 [Source: Custom Source (2/4)] INFO  (FlinkKafkaConsumerBase.java:604) - Consumer subtask 1 will start reading the following 2 partitions from the earliest offsets: [KafkaTopicPartition{topic='input1', partition=4}, KafkaTopicPartition{topic='input1', partition=0}]
2020-02-28 02:16:21,368 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 3 creating fetcher with offsets {KafkaTopicPartition{topic='input1', partition=6}=-915623761775, KafkaTopicPartition{topic='input1', partition=2}=-915623761775}.
2020-02-28 02:16:21,368 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='input1', partition=4}=-915623761775, KafkaTopicPartition{topic='input1', partition=0}=-915623761775}.
2020-02-28 02:16:21,369 [Legacy Source Thread - Source: Custom Source (3/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 2 creating fetcher with offsets {KafkaTopicPartition{topic='input1', partition=5}=-915623761775, KafkaTopicPartition{topic='input1', partition=1}=-915623761775}.
2020-02-28 02:16:21,378 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 2 creating fetcher with offsets {KafkaTopicPartition{topic='input1', partition=5}=-915623761775, KafkaTopicPartition{topic='input1', partition=1}=-915623761775}.
2020-02-28 02:16:21,384 [Legacy Source Thread - Source: Custom Source (1/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 0 creating fetcher with offsets {KafkaTopicPartition{topic='input1', partition=7}=-915623761775, KafkaTopicPartition{topic='input1', partition=3}=-915623761775}.
2020-02-28 02:16:21,388 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 0 creating fetcher with offsets {KafkaTopicPartition{topic='input1', partition=7}=-915623761775, KafkaTopicPartition{topic='input1', partition=3}=-915623761775}.
2020-02-28 02:16:21,390 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:21,394 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:21,394 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:21,394 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582848981394
2020-02-28 02:16:21,397 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:21,405 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (KafkaConsumer.java:1123) - [Consumer clientId=consumer-KafkaCsvProducer-9, groupId=KafkaCsvProducer] Subscribed to partition(s): input1-5, input1-1
2020-02-28 02:16:21,400 [Legacy Source Thread - Source: Custom Source (2/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='input1', partition=4}=-915623761775, KafkaTopicPartition{topic='input1', partition=0}=-915623761775}.
2020-02-28 02:16:21,420 [Legacy Source Thread - Source: Custom Source (4/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 3 creating fetcher with offsets {KafkaTopicPartition{topic='input1', partition=6}=-915623761775, KafkaTopicPartition{topic='input1', partition=2}=-915623761775}.
2020-02-28 02:16:21,417 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:21,416 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:21,421 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:21,421 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582848981416
2020-02-28 02:16:21,415 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:21,410 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-9, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition input1-5
2020-02-28 02:16:21,431 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:21,431 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (KafkaConsumer.java:1123) - [Consumer clientId=consumer-KafkaCsvProducer-10, groupId=KafkaCsvProducer] Subscribed to partition(s): input1-6, input1-2
2020-02-28 02:16:21,424 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:21,434 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-10, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition input1-6
2020-02-28 02:16:21,431 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:21,431 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:21,437 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:21,437 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:21,439 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582848981424
2020-02-28 02:16:21,445 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (KafkaConsumer.java:1123) - [Consumer clientId=consumer-KafkaCsvProducer-11, groupId=KafkaCsvProducer] Subscribed to partition(s): input1-4, input1-0
2020-02-28 02:16:21,445 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-11, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition input1-4
2020-02-28 02:16:21,446 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:21,446 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:21,446 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582848981433
2020-02-28 02:16:21,460 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-10, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:21,463 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (AbstractCoordinator.java:756) - [Consumer clientId=consumer-KafkaCsvProducer-10, groupId=KafkaCsvProducer] Discovered group coordinator skl:9092 (id: 2147483647 rack: null)
2020-02-28 02:16:21,466 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:21,466 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:21,466 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582848981456
2020-02-28 02:16:21,463 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-11, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:21,473 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (KafkaConsumer.java:1123) - [Consumer clientId=consumer-KafkaCsvProducer-12, groupId=KafkaCsvProducer] Subscribed to partition(s): input1-5, input1-1
2020-02-28 02:16:21,470 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-9, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:21,468 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (KafkaConsumer.java:1123) - [Consumer clientId=consumer-KafkaCsvProducer-14, groupId=KafkaCsvProducer] Subscribed to partition(s): input1-7, input1-3
2020-02-28 02:16:21,474 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-14, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition input1-7
2020-02-28 02:16:21,474 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (AbstractCoordinator.java:756) - [Consumer clientId=consumer-KafkaCsvProducer-9, groupId=KafkaCsvProducer] Discovered group coordinator skl:9092 (id: 2147483647 rack: null)
2020-02-28 02:16:21,468 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:21,475 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:21,475 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582848981464
2020-02-28 02:16:21,474 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-12, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition input1-5
2020-02-28 02:16:21,476 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:21,476 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:21,476 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582848981475
2020-02-28 02:16:21,477 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:21,477 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:21,477 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582848981472
2020-02-28 02:16:21,490 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (ConsumerCoordinator.java:762) - [Consumer clientId=consumer-KafkaCsvProducer-9, groupId=KafkaCsvProducer] Setting offset for partition input1-1 to the committed offset FetchPosition{offset=25, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=skl:9092 (id: 0 rack: null), epoch=0}}
2020-02-28 02:16:21,490 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (KafkaConsumer.java:1123) - [Consumer clientId=consumer-KafkaCsvProducer-13, groupId=KafkaCsvProducer] Subscribed to partition(s): input1-6, input1-2
2020-02-28 02:16:21,491 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-13, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition input1-6
2020-02-28 02:16:21,473 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (AbstractCoordinator.java:756) - [Consumer clientId=consumer-KafkaCsvProducer-11, groupId=KafkaCsvProducer] Discovered group coordinator skl:9092 (id: 2147483647 rack: null)
2020-02-28 02:16:21,493 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (KafkaConsumer.java:1123) - [Consumer clientId=consumer-KafkaCsvProducer-16, groupId=KafkaCsvProducer] Subscribed to partition(s): input1-4, input1-0
2020-02-28 02:16:21,493 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-16, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition input1-4
2020-02-28 02:16:21,498 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-13, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:21,498 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (AbstractCoordinator.java:756) - [Consumer clientId=consumer-KafkaCsvProducer-13, groupId=KafkaCsvProducer] Discovered group coordinator skl:9092 (id: 2147483647 rack: null)
2020-02-28 02:16:21,503 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-16, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:21,509 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (AbstractCoordinator.java:756) - [Consumer clientId=consumer-KafkaCsvProducer-16, groupId=KafkaCsvProducer] Discovered group coordinator skl:9092 (id: 2147483647 rack: null)
2020-02-28 02:16:21,510 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (KafkaConsumer.java:1123) - [Consumer clientId=consumer-KafkaCsvProducer-15, groupId=KafkaCsvProducer] Subscribed to partition(s): input1-7, input1-3
2020-02-28 02:16:21,509 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-14, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:21,511 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (AbstractCoordinator.java:756) - [Consumer clientId=consumer-KafkaCsvProducer-14, groupId=KafkaCsvProducer] Discovered group coordinator skl:9092 (id: 2147483647 rack: null)
2020-02-28 02:16:21,505 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (ConsumerCoordinator.java:762) - [Consumer clientId=consumer-KafkaCsvProducer-13, groupId=KafkaCsvProducer] Setting offset for partition input1-2 to the committed offset FetchPosition{offset=30, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=skl:9092 (id: 0 rack: null), epoch=0}}
2020-02-28 02:16:21,511 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-15, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition input1-7
2020-02-28 02:16:21,515 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-12, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:21,516 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (AbstractCoordinator.java:756) - [Consumer clientId=consumer-KafkaCsvProducer-12, groupId=KafkaCsvProducer] Discovered group coordinator skl:9092 (id: 2147483647 rack: null)
2020-02-28 02:16:21,518 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (ConsumerCoordinator.java:762) - [Consumer clientId=consumer-KafkaCsvProducer-14, groupId=KafkaCsvProducer] Setting offset for partition input1-3 to the committed offset FetchPosition{offset=26, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=skl:9092 (id: 0 rack: null), epoch=0}}
2020-02-28 02:16:21,519 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (ConsumerCoordinator.java:762) - [Consumer clientId=consumer-KafkaCsvProducer-10, groupId=KafkaCsvProducer] Setting offset for partition input1-2 to the committed offset FetchPosition{offset=30, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=skl:9092 (id: 0 rack: null), epoch=0}}
2020-02-28 02:16:21,524 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (ConsumerCoordinator.java:762) - [Consumer clientId=consumer-KafkaCsvProducer-16, groupId=KafkaCsvProducer] Setting offset for partition input1-0 to the committed offset FetchPosition{offset=25, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=skl:9092 (id: 0 rack: null), epoch=0}}
2020-02-28 02:16:21,527 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (ConsumerCoordinator.java:762) - [Consumer clientId=consumer-KafkaCsvProducer-12, groupId=KafkaCsvProducer] Setting offset for partition input1-1 to the committed offset FetchPosition{offset=25, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=skl:9092 (id: 0 rack: null), epoch=0}}
2020-02-28 02:16:21,529 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-15, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:21,535 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (ConsumerCoordinator.java:762) - [Consumer clientId=consumer-KafkaCsvProducer-11, groupId=KafkaCsvProducer] Setting offset for partition input1-0 to the committed offset FetchPosition{offset=25, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=skl:9092 (id: 0 rack: null), epoch=0}}
2020-02-28 02:16:21,539 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-13, groupId=KafkaCsvProducer] Resetting offset for partition input1-6 to offset 0.
2020-02-28 02:16:21,540 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-10, groupId=KafkaCsvProducer] Resetting offset for partition input1-6 to offset 0.
2020-02-28 02:16:21,541 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-10, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition input1-2
2020-02-28 02:16:21,542 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-13, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition input1-2
2020-02-28 02:16:21,544 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-14, groupId=KafkaCsvProducer] Resetting offset for partition input1-7 to offset 0.
2020-02-28 02:16:21,552 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-14, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition input1-3
2020-02-28 02:16:21,553 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-12, groupId=KafkaCsvProducer] Resetting offset for partition input1-5 to offset 0.
2020-02-28 02:16:21,553 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-12, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition input1-1
2020-02-28 02:16:21,551 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-16, groupId=KafkaCsvProducer] Resetting offset for partition input1-4 to offset 0.
2020-02-28 02:16:21,554 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-16, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition input1-0
2020-02-28 02:16:21,546 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (AbstractCoordinator.java:756) - [Consumer clientId=consumer-KafkaCsvProducer-15, groupId=KafkaCsvProducer] Discovered group coordinator skl:9092 (id: 2147483647 rack: null)
2020-02-28 02:16:21,559 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-12, groupId=KafkaCsvProducer] Resetting offset for partition input1-1 to offset 0.
2020-02-28 02:16:21,559 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-14, groupId=KafkaCsvProducer] Resetting offset for partition input1-3 to offset 0.
2020-02-28 02:16:21,561 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-13, groupId=KafkaCsvProducer] Resetting offset for partition input1-2 to offset 0.
2020-02-28 02:16:21,561 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-9, groupId=KafkaCsvProducer] Resetting offset for partition input1-5 to offset 0.
2020-02-28 02:16:21,562 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-9, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition input1-1
2020-02-28 02:16:21,569 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-11, groupId=KafkaCsvProducer] Resetting offset for partition input1-4 to offset 0.
2020-02-28 02:16:21,570 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-11, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition input1-0
2020-02-28 02:16:21,570 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-9, groupId=KafkaCsvProducer] Resetting offset for partition input1-1 to offset 0.
2020-02-28 02:16:21,573 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-16, groupId=KafkaCsvProducer] Resetting offset for partition input1-0 to offset 0.
2020-02-28 02:16:21,575 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (ConsumerCoordinator.java:762) - [Consumer clientId=consumer-KafkaCsvProducer-15, groupId=KafkaCsvProducer] Setting offset for partition input1-3 to the committed offset FetchPosition{offset=26, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=skl:9092 (id: 0 rack: null), epoch=0}}
2020-02-28 02:16:21,582 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-10, groupId=KafkaCsvProducer] Resetting offset for partition input1-2 to offset 0.
2020-02-28 02:16:21,586 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-15, groupId=KafkaCsvProducer] Resetting offset for partition input1-7 to offset 0.
2020-02-28 02:16:21,586 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-15, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition input1-3
2020-02-28 02:16:21,588 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-15, groupId=KafkaCsvProducer] Resetting offset for partition input1-3 to offset 0.
2020-02-28 02:16:21,589 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-11, groupId=KafkaCsvProducer] Resetting offset for partition input1-0 to offset 0.
2020-02-28 02:16:42,792 [TransientBlobCache shutdown hook] INFO  (AbstractBlobCache.java:247) - Shutting down BLOB cache
2020-02-28 02:16:42,793 [PermanentBlobCache shutdown hook] INFO  (AbstractBlobCache.java:247) - Shutting down BLOB cache
2020-02-28 02:16:42,792 [TaskExecutorLocalStateStoresManager shutdown hook] INFO  (TaskExecutorLocalStateStoresManager.java:213) - Shutting down TaskExecutorLocalStateStoresManager.
2020-02-28 02:16:42,799 [FileCache shutdown hook] INFO  (FileCache.java:153) - removed file cache directory /tmp/flink-dist-cache-702e34e5-8a48-4e69-a3a4-feded6d44365
2020-02-28 02:16:42,799 [IOManagerAsync shutdown hook] INFO  (FileChannelManagerImpl.java:112) - FileChannelManager removed spill file directory /tmp/flink-io-002298a5-7b12-4e87-8aed-30d5fc026c61
2020-02-28 02:16:42,800 [BlobServer shutdown hook] INFO  (BlobServer.java:340) - Stopped BLOB server at 0.0.0.0:43649
2020-02-28 02:16:52,370 [main] WARN  (FlinkKafkaProducer.java:667) - Property [transaction.timeout.ms] not specified. Setting it to 3600000 ms
2020-02-28 02:16:52,543 [main] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.api.datastream.CoGroupedStreams$TaggedUnion does not contain a setter for field one
2020-02-28 02:16:52,544 [main] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.api.datastream.CoGroupedStreams$TaggedUnion cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-28 02:16:52,546 [main] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.api.datastream.CoGroupedStreams$TaggedUnion does not contain a setter for field one
2020-02-28 02:16:52,546 [main] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.api.datastream.CoGroupedStreams$TaggedUnion cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-28 02:16:53,050 [main] INFO  (LocalStreamEnvironment.java:108) - Running job on local embedded Flink mini cluster
2020-02-28 02:16:53,477 [main] INFO  (MiniCluster.java:253) - Starting Flink Mini Cluster
2020-02-28 02:16:53,480 [main] INFO  (MiniCluster.java:262) - Starting Metrics Registry
2020-02-28 02:16:53,557 [main] INFO  (MetricRegistryImpl.java:114) - No metrics reporter configured, no metrics will be exposed/reported.
2020-02-28 02:16:53,557 [main] INFO  (MiniCluster.java:266) - Starting RPC Service(s)
2020-02-28 02:16:54,260 [flink-akka.actor.default-dispatcher-2] INFO  (Slf4jLogger.scala:92) - Slf4jLogger started
2020-02-28 02:16:54,460 [main] INFO  (BootstrapTools.java:244) - Trying to start actor system at :0
2020-02-28 02:16:54,528 [flink-metrics-2] INFO  (Slf4jLogger.scala:92) - Slf4jLogger started
2020-02-28 02:16:54,549 [flink-metrics-2] INFO  (MarkerIgnoringBase.java:107) - Starting remoting
2020-02-28 02:16:54,700 [flink-metrics-2] INFO  (MarkerIgnoringBase.java:107) - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:43915]
2020-02-28 02:16:54,736 [main] INFO  (BootstrapTools.java:256) - Actor system started at akka.tcp://flink-metrics@127.0.1.1:43915
2020-02-28 02:16:54,744 [main] INFO  (AkkaRpcService.java:223) - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-02-28 02:16:54,756 [main] INFO  (MiniCluster.java:397) - Starting high-availability services
2020-02-28 02:16:54,768 [main] INFO  (BlobServer.java:141) - Created BLOB server storage directory /tmp/blobStore-c7134b20-d1a5-4ff8-b92f-2596db010bc8
2020-02-28 02:16:54,771 [main] INFO  (BlobServer.java:203) - Started BLOB server at 0.0.0.0:34685 - max concurrent requests: 50 - max backlog: 1000
2020-02-28 02:16:54,773 [main] INFO  (AbstractBlobCache.java:107) - Created BLOB cache storage directory /tmp/blobStore-bbd9611a-b004-46ae-92fe-ba3ef1cabbbc
2020-02-28 02:16:54,774 [main] INFO  (AbstractBlobCache.java:107) - Created BLOB cache storage directory /tmp/blobStore-b21529b1-34ae-4557-996c-22fbcb9317fe
2020-02-28 02:16:54,775 [main] INFO  (MiniCluster.java:479) - Starting 1 TaskManger(s)
2020-02-28 02:16:54,777 [main] INFO  (TaskManagerRunner.java:351) - Starting TaskManager with ResourceID: c1a9bd0d-ecc7-4769-9567-0bfee122b6ad
2020-02-28 02:16:54,905 [main] INFO  (TaskManagerServices.java:519) - Temporary file directory '/tmp': total 439 GB, usable 336 GB (76.54% usable)
2020-02-28 02:16:54,910 [main] INFO  (FileChannelManagerImpl.java:76) - FileChannelManager uses directory /tmp/flink-io-464532d4-5864-4bed-833d-0aebd4733e7d for spill files.
2020-02-28 02:16:54,922 [main] INFO  (FileChannelManagerImpl.java:76) - FileChannelManager uses directory /tmp/flink-netty-shuffle-5b1ef18a-523b-42d6-ae40-69fcf6fea5e9 for spill files.
2020-02-28 02:16:55,056 [main] INFO  (NetworkBufferPool.java:140) - Allocated 191 MB for network buffer pool (number of memory segments: 6113, bytes per segment: 32768).
2020-02-28 02:16:55,065 [main] INFO  (NettyShuffleEnvironment.java:283) - Starting the network environment and its components.
2020-02-28 02:16:55,066 [main] INFO  (KvStateService.java:89) - Starting the kvState service and its components.
2020-02-28 02:16:55,067 [main] INFO  (TaskManagerServices.java:364) - Limiting managed memory to 0.7 of the currently free heap space (1197 MB), memory will be allocated lazily.
2020-02-28 02:16:55,079 [main] INFO  (TaskManagerConfiguration.java:197) - Messages have a max timeout of 10000 ms
2020-02-28 02:16:55,089 [main] INFO  (AkkaRpcService.java:223) - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-02-28 02:16:55,104 [flink-akka.actor.default-dispatcher-2] INFO  (JobLeaderService.java:125) - Start job leader service.
2020-02-28 02:16:55,106 [flink-akka.actor.default-dispatcher-2] INFO  (FileCache.java:107) - User file cache uses directory /tmp/flink-dist-cache-6b2a5d6d-c843-438c-b7ef-2a794f76abd5
2020-02-28 02:16:55,167 [main] INFO  (RestServerEndpoint.java:136) - Starting rest endpoint.
2020-02-28 02:16:55,254 [main] WARN  (WebMonitorUtils.java:87) - Log file environment variable 'log.file' is not set.
2020-02-28 02:16:55,255 [main] WARN  (WebMonitorUtils.java:93) - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-02-28 02:16:55,267 [main] INFO  (DispatcherRestEndpoint.java:113) - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-02-28 02:16:55,429 [main] INFO  (RestServerEndpoint.java:233) - Rest endpoint listening at localhost:37187
2020-02-28 02:16:55,430 [main] INFO  (EmbeddedLeaderService.java:300) - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@25c53f74 @ http://localhost:37187
2020-02-28 02:16:55,432 [mini-cluster-io-thread-1] INFO  (WebMonitorEndpoint.java:712) - http://localhost:37187 was granted leadership with leaderSessionID=5af9c5d5-650c-476b-941f-300b188463d1
2020-02-28 02:16:55,432 [mini-cluster-io-thread-1] INFO  (EmbeddedLeaderService.java:250) - Received confirmation of leadership for leader http://localhost:37187 , session=5af9c5d5-650c-476b-941f-300b188463d1
2020-02-28 02:16:55,443 [main] INFO  (AkkaRpcService.java:223) - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-02-28 02:16:55,459 [main] INFO  (AkkaRpcService.java:223) - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-02-28 02:16:55,469 [flink-akka.actor.default-dispatcher-3] INFO  (EmbeddedLeaderService.java:300) - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@7b37566e @ akka://flink/user/dispatcher
2020-02-28 02:16:55,470 [flink-akka.actor.default-dispatcher-2] INFO  (EmbeddedLeaderService.java:300) - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@7b4515f9 @ akka://flink/user/resourcemanager
2020-02-28 02:16:55,472 [flink-akka.actor.default-dispatcher-3] INFO  (Dispatcher.java:884) - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token 9d47b188-4074-4f33-a43c-901d0015b9ca
2020-02-28 02:16:55,477 [flink-akka.actor.default-dispatcher-2] INFO  (Dispatcher.java:716) - Recovering all persisted jobs.
2020-02-28 02:16:55,479 [flink-akka.actor.default-dispatcher-2] INFO  (ResourceManager.java:925) - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 851b09f41332e8adb5495f77e69d429c
2020-02-28 02:16:55,482 [flink-akka.actor.default-dispatcher-2] INFO  (SlotManagerImpl.java:219) - Starting the SlotManager.
2020-02-28 02:16:55,490 [flink-akka.actor.default-dispatcher-3] INFO  (EmbeddedLeaderService.java:250) - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=9d47b188-4074-4f33-a43c-901d0015b9ca
2020-02-28 02:16:55,490 [flink-akka.actor.default-dispatcher-2] INFO  (EmbeddedLeaderService.java:250) - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=b5495f77-e69d-429c-851b-09f41332e8ad
2020-02-28 02:16:55,501 [main] INFO  (MiniCluster.java:362) - Flink Mini Cluster started successfully
2020-02-28 02:16:55,505 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:991) - Connecting to ResourceManager akka://flink/user/resourcemanager(851b09f41332e8adb5495f77e69d429c).
2020-02-28 02:16:55,516 [flink-akka.actor.default-dispatcher-2] INFO  (RetryingRegistration.java:155) - Resolved ResourceManager address, beginning registration
2020-02-28 02:16:55,516 [flink-akka.actor.default-dispatcher-2] INFO  (RetryingRegistration.java:204) - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-02-28 02:16:55,528 [flink-akka.actor.default-dispatcher-2] INFO  (Dispatcher.java:264) - Received JobGraph submission eb3b31bdcc6d247420f3ea17fe5af4db (SecondAlgorithmPass).
2020-02-28 02:16:55,530 [flink-akka.actor.default-dispatcher-2] INFO  (Dispatcher.java:321) - Submitting job eb3b31bdcc6d247420f3ea17fe5af4db (SecondAlgorithmPass).
2020-02-28 02:16:55,530 [flink-akka.actor.default-dispatcher-5] INFO  (ResourceManager.java:717) - Registering TaskManager with ResourceID c1a9bd0d-ecc7-4769-9567-0bfee122b6ad (akka://flink/user/taskmanager_0) at ResourceManager
2020-02-28 02:16:55,532 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutorToResourceManagerConnection.java:100) - Successful registration at resource manager akka://flink/user/resourcemanager under registration id efc9c70a4b9d1b9b8ee236e341a8a951.
2020-02-28 02:16:55,550 [flink-akka.actor.default-dispatcher-5] INFO  (AkkaRpcService.java:223) - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-02-28 02:16:55,559 [flink-akka.actor.default-dispatcher-5] INFO  (JobMaster.java:242) - Initializing job SecondAlgorithmPass (eb3b31bdcc6d247420f3ea17fe5af4db).
2020-02-28 02:16:55,580 [flink-akka.actor.default-dispatcher-5] INFO  (LegacyScheduler.java:171) - Using restart strategy NoRestartStrategy for SecondAlgorithmPass (eb3b31bdcc6d247420f3ea17fe5af4db).
2020-02-28 02:16:55,596 [flink-akka.actor.default-dispatcher-5] INFO  (ExecutionGraph.java:519) - Job recovers via failover strategy: full graph restart
2020-02-28 02:16:55,608 [flink-akka.actor.default-dispatcher-5] INFO  (ExecutionGraphBuilder.java:204) - Running initialization on master for job SecondAlgorithmPass (eb3b31bdcc6d247420f3ea17fe5af4db).
2020-02-28 02:16:55,608 [flink-akka.actor.default-dispatcher-5] INFO  (ExecutionGraphBuilder.java:222) - Successfully ran initialization on master in 0 ms.
2020-02-28 02:16:55,648 [flink-akka.actor.default-dispatcher-5] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:55,657 [flink-akka.actor.default-dispatcher-5] INFO  (EmbeddedLeaderService.java:300) - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@65d34092 @ akka://flink/user/jobmanager_1
2020-02-28 02:16:55,658 [mini-cluster-io-thread-2] INFO  (JobManagerRunner.java:313) - JobManager runner for job SecondAlgorithmPass (eb3b31bdcc6d247420f3ea17fe5af4db) was granted leadership with session id 786af19a-de4c-44ed-a16b-acddf5d80c2b at akka://flink/user/jobmanager_1.
2020-02-28 02:16:55,661 [flink-akka.actor.default-dispatcher-5] INFO  (JobMaster.java:712) - Starting execution of job SecondAlgorithmPass (eb3b31bdcc6d247420f3ea17fe5af4db) under job master id a16bacddf5d80c2b786af19ade4c44ed.
2020-02-28 02:16:55,662 [flink-akka.actor.default-dispatcher-5] INFO  (ExecutionGraph.java:1325) - Job SecondAlgorithmPass (eb3b31bdcc6d247420f3ea17fe5af4db) switched from state CREATED to RUNNING.
2020-02-28 02:16:55,666 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source (1/4) (94ef5892b18db2d7dc283570df7b222b) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,680 [flink-akka.actor.default-dispatcher-5] INFO  (SlotPoolImpl.java:369) - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{43ab9f615dd2709d2e6e4412072b6fd4}]
2020-02-28 02:16:55,688 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source (2/4) (09b8a4066c9083f2601045b3c852f38e) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,688 [flink-akka.actor.default-dispatcher-5] INFO  (SlotPoolImpl.java:369) - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{be70075cfc8773bf3f0eb19634d5c025}]
2020-02-28 02:16:55,688 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source (3/4) (e448ec2139b6b577f76ce0680972578c) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,689 [flink-akka.actor.default-dispatcher-5] INFO  (SlotPoolImpl.java:369) - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{f64bcc5293e98ac0f46a5d911fad625f}]
2020-02-28 02:16:55,689 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source (4/4) (35dbc00df37e7b8409ef6d7cd9e1cc23) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,689 [flink-akka.actor.default-dispatcher-5] INFO  (SlotPoolImpl.java:369) - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{907919b77a91b26779601f2e5b9856fb}]
2020-02-28 02:16:55,689 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (1/4) (2b68656e2c7621f89475fdaa271c1bc3) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,690 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (2/4) (0b3adb70c418e53cfb1cd1be64e5db95) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,690 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (3/4) (bbd9aba2d790bbf56452585a4aae1a19) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,690 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (4/4) (75497dca693c043a328597ad72a4d495) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,690 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source (1/4) (39659281680d7028202a317b6dbe46aa) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,691 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source (2/4) (e60507f2bb706dd2ca7d2b3c315ab616) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,691 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source (3/4) (dce10faecf772de9ba8f6fe339930189) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,692 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source (4/4) (cb3092089b9eca91b2a588c879f8504a) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,692 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (1/4) (5436c29940ef81e2e47f86276b1510b2) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,692 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (2/4) (925fc4b864f9c06ab48577a02e9f46af) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,693 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (3/4) (cc9d60061a79fbaa6bda74b851362a42) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,693 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (4/4) (01f5c4e6b7ad5c94b9983556f1c51601) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,694 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Print to Std. Out (1/4) (a8d5c6e99b63bdaaf7b65a104960d1f2) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,695 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Print to Std. Out (2/4) (7976610031a13a14e9b53a493fe5c596) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,695 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Print to Std. Out (3/4) (009e306ed5e40696b5b18441884abf6e) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,696 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Print to Std. Out (4/4) (58fcc3bf73076384465785bd53dbe43d) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,696 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (1/4) (618792d0ac593b352e95e3c95c03eb4a) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,696 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (2/4) (54018ea9ca53a0ed0be9c2e2fccf50a1) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,696 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (3/4) (2db8a7001715ac6475d39c6889a8053c) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,697 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (4/4) (5ff31f4f896c37c68173ed1b6e5543a9) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,697 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - KeyedProcess (1/4) (6254c3586d143a34711abd9ab9bbae89) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,697 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - KeyedProcess (2/4) (84062b9addfdf242b60fbaf43c12bf13) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,697 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - KeyedProcess (3/4) (abd011e107dae07a7d14df1013e9838e) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,698 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - KeyedProcess (4/4) (cb9cb5b43a8091d8cc65a940d694adda) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,698 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Unnamed (1/4) (7480cdb93c0688ae4269c805bbf9b49c) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,698 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Unnamed (2/4) (281150e2aaea3a4d9034e6b8b9dff1e8) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,698 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Unnamed (3/4) (83e569c47365334307d2aa3070e30fb2) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,698 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Unnamed (4/4) (39319c0227e31f3dd0eb0b11461cb43d) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,698 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Flat Map (1/4) (23e6d95a9dcf53b94cd41c744e5d6df3) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,699 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Flat Map (2/4) (d53f62e920a3d200b4a718c620e80874) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,699 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Flat Map (3/4) (6261faa62991f4539b9ed8f045e49ef0) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,699 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Flat Map (4/4) (8b4829311aec3a64dbc419b77241ffb9) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,699 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Print to Std. Out (1/4) (dd9c9bd104fbe907a44e33650f113513) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,699 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Print to Std. Out (2/4) (8f12deba1d6471291e6527a93ed0474e) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,700 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Print to Std. Out (3/4) (2b09f78eade1d200c05c29ba9cd68c16) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,700 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Print to Std. Out (4/4) (5c5fa427a24e6a84af4a04c2d3661709) switched from CREATED to SCHEDULED.
2020-02-28 02:16:55,702 [jobmanager-future-thread-1] INFO  (EmbeddedLeaderService.java:250) - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=786af19a-de4c-44ed-a16b-acddf5d80c2b
2020-02-28 02:16:55,705 [flink-akka.actor.default-dispatcher-5] INFO  (JobMaster.java:936) - Connecting to ResourceManager akka://flink/user/resourcemanager(851b09f41332e8adb5495f77e69d429c)
2020-02-28 02:16:55,707 [flink-akka.actor.default-dispatcher-2] INFO  (RetryingRegistration.java:155) - Resolved ResourceManager address, beginning registration
2020-02-28 02:16:55,707 [flink-akka.actor.default-dispatcher-2] INFO  (RetryingRegistration.java:204) - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-02-28 02:16:55,709 [flink-akka.actor.default-dispatcher-5] INFO  (ResourceManager.java:306) - Registering job manager a16bacddf5d80c2b786af19ade4c44ed@akka://flink/user/jobmanager_1 for job eb3b31bdcc6d247420f3ea17fe5af4db.
2020-02-28 02:16:55,714 [flink-akka.actor.default-dispatcher-5] INFO  (ResourceManager.java:661) - Registered job manager a16bacddf5d80c2b786af19ade4c44ed@akka://flink/user/jobmanager_1 for job eb3b31bdcc6d247420f3ea17fe5af4db.
2020-02-28 02:16:55,715 [flink-akka.actor.default-dispatcher-2] INFO  (JobMaster.java:958) - JobManager successfully registered at ResourceManager, leader id: 851b09f41332e8adb5495f77e69d429c.
2020-02-28 02:16:55,716 [flink-akka.actor.default-dispatcher-2] INFO  (SlotPoolImpl.java:319) - Requesting new slot [SlotRequestId{43ab9f615dd2709d2e6e4412072b6fd4}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-02-28 02:16:55,717 [flink-akka.actor.default-dispatcher-3] INFO  (ResourceManager.java:441) - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job eb3b31bdcc6d247420f3ea17fe5af4db with allocation id 17a900a552b47b5e090a5983e8fdf3e2.
2020-02-28 02:16:55,717 [flink-akka.actor.default-dispatcher-2] INFO  (SlotPoolImpl.java:319) - Requesting new slot [SlotRequestId{be70075cfc8773bf3f0eb19634d5c025}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-02-28 02:16:55,718 [flink-akka.actor.default-dispatcher-2] INFO  (SlotPoolImpl.java:319) - Requesting new slot [SlotRequestId{f64bcc5293e98ac0f46a5d911fad625f}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-02-28 02:16:55,718 [flink-akka.actor.default-dispatcher-2] INFO  (SlotPoolImpl.java:319) - Requesting new slot [SlotRequestId{907919b77a91b26779601f2e5b9856fb}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-02-28 02:16:55,721 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:822) - Receive slot request 17a900a552b47b5e090a5983e8fdf3e2 for job eb3b31bdcc6d247420f3ea17fe5af4db from resource manager with leader id 851b09f41332e8adb5495f77e69d429c.
2020-02-28 02:16:55,724 [flink-akka.actor.default-dispatcher-3] INFO  (ResourceManager.java:441) - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job eb3b31bdcc6d247420f3ea17fe5af4db with allocation id a6ab05b5bc84b46884af96df39a94a6f.
2020-02-28 02:16:55,725 [flink-akka.actor.default-dispatcher-3] INFO  (ResourceManager.java:441) - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job eb3b31bdcc6d247420f3ea17fe5af4db with allocation id 2b3c2a283f89efd14031a69878878334.
2020-02-28 02:16:55,726 [flink-akka.actor.default-dispatcher-3] INFO  (ResourceManager.java:441) - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job eb3b31bdcc6d247420f3ea17fe5af4db with allocation id aa980e8fc9b0182d9e24a08700212c05.
2020-02-28 02:16:55,729 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:834) - Allocated slot for 17a900a552b47b5e090a5983e8fdf3e2.
2020-02-28 02:16:55,729 [flink-akka.actor.default-dispatcher-2] INFO  (JobLeaderService.java:193) - Add job eb3b31bdcc6d247420f3ea17fe5af4db for job leader monitoring.
2020-02-28 02:16:55,731 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:822) - Receive slot request a6ab05b5bc84b46884af96df39a94a6f for job eb3b31bdcc6d247420f3ea17fe5af4db from resource manager with leader id 851b09f41332e8adb5495f77e69d429c.
2020-02-28 02:16:55,731 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:834) - Allocated slot for a6ab05b5bc84b46884af96df39a94a6f.
2020-02-28 02:16:55,731 [flink-akka.actor.default-dispatcher-2] INFO  (JobLeaderService.java:193) - Add job eb3b31bdcc6d247420f3ea17fe5af4db for job leader monitoring.
2020-02-28 02:16:55,731 [mini-cluster-io-thread-4] INFO  (JobLeaderService.java:333) - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 786af19a-de4c-44ed-a16b-acddf5d80c2b.
2020-02-28 02:16:55,732 [mini-cluster-io-thread-2] INFO  (JobLeaderService.java:333) - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 786af19a-de4c-44ed-a16b-acddf5d80c2b.
2020-02-28 02:16:55,732 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:822) - Receive slot request 2b3c2a283f89efd14031a69878878334 for job eb3b31bdcc6d247420f3ea17fe5af4db from resource manager with leader id 851b09f41332e8adb5495f77e69d429c.
2020-02-28 02:16:55,732 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:834) - Allocated slot for 2b3c2a283f89efd14031a69878878334.
2020-02-28 02:16:55,732 [flink-akka.actor.default-dispatcher-2] INFO  (JobLeaderService.java:193) - Add job eb3b31bdcc6d247420f3ea17fe5af4db for job leader monitoring.
2020-02-28 02:16:55,732 [mini-cluster-io-thread-4] WARN  (EmbeddedLeaderService.java:516) - Error notifying leader listener about new leader
java.lang.IllegalStateException: The RPC connection is already closed
	at org.apache.flink.util.Preconditions.checkState(Preconditions.java:195)
	at org.apache.flink.runtime.registration.RegisteredRpcConnection.start(RegisteredRpcConnection.java:90)
	at org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener.notifyLeaderAddress(JobLeaderService.java:334)
	at org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService$NotifyOfLeaderCall.run(EmbeddedLeaderService.java:513)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1626)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-02-28 02:16:55,735 [flink-akka.actor.default-dispatcher-4] INFO  (RetryingRegistration.java:155) - Resolved JobManager address, beginning registration
2020-02-28 02:16:55,733 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:822) - Receive slot request aa980e8fc9b0182d9e24a08700212c05 for job eb3b31bdcc6d247420f3ea17fe5af4db from resource manager with leader id 851b09f41332e8adb5495f77e69d429c.
2020-02-28 02:16:55,733 [mini-cluster-io-thread-3] INFO  (JobLeaderService.java:333) - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 786af19a-de4c-44ed-a16b-acddf5d80c2b.
2020-02-28 02:16:55,735 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:834) - Allocated slot for aa980e8fc9b0182d9e24a08700212c05.
2020-02-28 02:16:55,736 [flink-akka.actor.default-dispatcher-2] INFO  (JobLeaderService.java:193) - Add job eb3b31bdcc6d247420f3ea17fe5af4db for job leader monitoring.
2020-02-28 02:16:55,737 [flink-akka.actor.default-dispatcher-3] INFO  (RetryingRegistration.java:155) - Resolved JobManager address, beginning registration
2020-02-28 02:16:55,737 [mini-cluster-io-thread-1] INFO  (JobLeaderService.java:333) - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 786af19a-de4c-44ed-a16b-acddf5d80c2b.
2020-02-28 02:16:55,738 [flink-akka.actor.default-dispatcher-2] INFO  (RetryingRegistration.java:155) - Resolved JobManager address, beginning registration
2020-02-28 02:16:55,738 [flink-akka.actor.default-dispatcher-2] INFO  (RetryingRegistration.java:204) - Registration at JobManager attempt 1 (timeout=100ms)
2020-02-28 02:16:55,741 [flink-akka.actor.default-dispatcher-4] INFO  (JobLeaderService.java:382) - Successful registration at job manager akka://flink/user/jobmanager_1 for job eb3b31bdcc6d247420f3ea17fe5af4db.
2020-02-28 02:16:55,742 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:1227) - Establish JobManager connection for job eb3b31bdcc6d247420f3ea17fe5af4db.
2020-02-28 02:16:55,746 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:1128) - Offer reserved slots to the leader of job eb3b31bdcc6d247420f3ea17fe5af4db.
2020-02-28 02:16:55,762 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source (1/4) (94ef5892b18db2d7dc283570df7b222b) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,762 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying Source: Custom Source (1/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,776 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source (2/4) (09b8a4066c9083f2601045b3c852f38e) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,777 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying Source: Custom Source (2/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,777 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source (3/4) (e448ec2139b6b577f76ce0680972578c) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,778 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying Source: Custom Source (3/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,778 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source (4/4) (35dbc00df37e7b8409ef6d7cd9e1cc23) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,779 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying Source: Custom Source (4/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,779 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (1/4) (2b68656e2c7621f89475fdaa271c1bc3) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,779 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Map (1/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,780 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (2/4) (0b3adb70c418e53cfb1cd1be64e5db95) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,781 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Map (2/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,781 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (3/4) (bbd9aba2d790bbf56452585a4aae1a19) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,781 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Map (3/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,782 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (4/4) (75497dca693c043a328597ad72a4d495) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,782 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Map (4/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,783 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source (1/4) (39659281680d7028202a317b6dbe46aa) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,783 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying Source: Custom Source (1/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,784 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source (2/4) (e60507f2bb706dd2ca7d2b3c315ab616) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,784 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying Source: Custom Source (2/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,785 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source (3/4) (dce10faecf772de9ba8f6fe339930189) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,785 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying Source: Custom Source (3/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,786 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source (4/4) (cb3092089b9eca91b2a588c879f8504a) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,786 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying Source: Custom Source (4/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,787 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (1/4) (5436c29940ef81e2e47f86276b1510b2) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,787 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Map (1/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,788 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (2/4) (925fc4b864f9c06ab48577a02e9f46af) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,788 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Map (2/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,789 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (3/4) (cc9d60061a79fbaa6bda74b851362a42) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,789 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Map (3/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,789 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (4/4) (01f5c4e6b7ad5c94b9983556f1c51601) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,790 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Map (4/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,790 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Print to Std. Out (1/4) (a8d5c6e99b63bdaaf7b65a104960d1f2) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,790 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying Sink: Print to Std. Out (1/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,791 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Print to Std. Out (2/4) (7976610031a13a14e9b53a493fe5c596) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,792 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying Sink: Print to Std. Out (2/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,792 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Print to Std. Out (3/4) (009e306ed5e40696b5b18441884abf6e) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,793 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying Sink: Print to Std. Out (3/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,793 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Print to Std. Out (4/4) (58fcc3bf73076384465785bd53dbe43d) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,793 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying Sink: Print to Std. Out (4/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,794 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (1/4) (618792d0ac593b352e95e3c95c03eb4a) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,794 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (1/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,794 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (2/4) (54018ea9ca53a0ed0be9c2e2fccf50a1) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,795 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (2/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,795 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (3/4) (2db8a7001715ac6475d39c6889a8053c) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,795 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (3/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,796 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (4/4) (5ff31f4f896c37c68173ed1b6e5543a9) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,796 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (4/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,797 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - KeyedProcess (1/4) (6254c3586d143a34711abd9ab9bbae89) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,797 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying KeyedProcess (1/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,798 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - KeyedProcess (2/4) (84062b9addfdf242b60fbaf43c12bf13) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,798 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying KeyedProcess (2/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,798 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - KeyedProcess (3/4) (abd011e107dae07a7d14df1013e9838e) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,799 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying KeyedProcess (3/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,799 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - KeyedProcess (4/4) (cb9cb5b43a8091d8cc65a940d694adda) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,799 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying KeyedProcess (4/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,800 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Unnamed (1/4) (7480cdb93c0688ae4269c805bbf9b49c) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,800 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying Sink: Unnamed (1/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,801 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Unnamed (2/4) (281150e2aaea3a4d9034e6b8b9dff1e8) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,801 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying Sink: Unnamed (2/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,802 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Unnamed (3/4) (83e569c47365334307d2aa3070e30fb2) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,802 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying Sink: Unnamed (3/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,803 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Unnamed (4/4) (39319c0227e31f3dd0eb0b11461cb43d) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,803 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying Sink: Unnamed (4/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,804 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Flat Map (1/4) (23e6d95a9dcf53b94cd41c744e5d6df3) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,804 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying Flat Map (1/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,805 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Flat Map (2/4) (d53f62e920a3d200b4a718c620e80874) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,805 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying Flat Map (2/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,806 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Flat Map (3/4) (6261faa62991f4539b9ed8f045e49ef0) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,806 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying Flat Map (3/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,806 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Flat Map (4/4) (8b4829311aec3a64dbc419b77241ffb9) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,807 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying Flat Map (4/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,807 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Print to Std. Out (1/4) (dd9c9bd104fbe907a44e33650f113513) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,807 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying Sink: Print to Std. Out (1/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,808 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Print to Std. Out (2/4) (8f12deba1d6471291e6527a93ed0474e) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,808 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying Sink: Print to Std. Out (2/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,809 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Print to Std. Out (3/4) (2b09f78eade1d200c05c29ba9cd68c16) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,809 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying Sink: Print to Std. Out (3/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,810 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Print to Std. Out (4/4) (5c5fa427a24e6a84af4a04c2d3661709) switched from SCHEDULED to DEPLOYING.
2020-02-28 02:16:55,810 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:713) - Deploying Sink: Print to Std. Out (4/4) (attempt #0) to c1a9bd0d-ecc7-4769-9567-0bfee122b6ad @ localhost (dataPort=-1)
2020-02-28 02:16:55,812 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source (1/4).
2020-02-28 02:16:55,813 [Source: Custom Source (1/4)] INFO  (Task.java:958) - Source: Custom Source (1/4) (94ef5892b18db2d7dc283570df7b222b) switched from CREATED to DEPLOYING.
2020-02-28 02:16:55,814 [Source: Custom Source (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source (1/4) (94ef5892b18db2d7dc283570df7b222b) [DEPLOYING]
2020-02-28 02:16:55,819 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source (2/4).
2020-02-28 02:16:55,820 [Source: Custom Source (1/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source (1/4) (94ef5892b18db2d7dc283570df7b222b) [DEPLOYING].
2020-02-28 02:16:55,821 [Source: Custom Source (1/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source (1/4) (94ef5892b18db2d7dc283570df7b222b) [DEPLOYING].
2020-02-28 02:16:55,822 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source (3/4).
2020-02-28 02:16:55,823 [Source: Custom Source (2/4)] INFO  (Task.java:958) - Source: Custom Source (2/4) (09b8a4066c9083f2601045b3c852f38e) switched from CREATED to DEPLOYING.
2020-02-28 02:16:55,823 [Source: Custom Source (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source (2/4) (09b8a4066c9083f2601045b3c852f38e) [DEPLOYING]
2020-02-28 02:16:55,824 [Source: Custom Source (2/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source (2/4) (09b8a4066c9083f2601045b3c852f38e) [DEPLOYING].
2020-02-28 02:16:55,825 [Source: Custom Source (2/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source (2/4) (09b8a4066c9083f2601045b3c852f38e) [DEPLOYING].
2020-02-28 02:16:55,828 [Source: Custom Source (3/4)] INFO  (Task.java:958) - Source: Custom Source (3/4) (e448ec2139b6b577f76ce0680972578c) switched from CREATED to DEPLOYING.
2020-02-28 02:16:55,828 [Source: Custom Source (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source (3/4) (e448ec2139b6b577f76ce0680972578c) [DEPLOYING]
2020-02-28 02:16:55,829 [Source: Custom Source (3/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source (3/4) (e448ec2139b6b577f76ce0680972578c) [DEPLOYING].
2020-02-28 02:16:55,829 [Source: Custom Source (3/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source (3/4) (e448ec2139b6b577f76ce0680972578c) [DEPLOYING].
2020-02-28 02:16:55,831 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Map (1/4).
2020-02-28 02:16:55,841 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Map (2/4).
2020-02-28 02:16:55,841 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (1/4) (2b68656e2c7621f89475fdaa271c1bc3) switched from CREATED to DEPLOYING.
2020-02-28 02:16:55,841 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Map (1/4) (2b68656e2c7621f89475fdaa271c1bc3) [DEPLOYING]
2020-02-28 02:16:55,842 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Map (1/4) (2b68656e2c7621f89475fdaa271c1bc3) [DEPLOYING].
2020-02-28 02:16:55,843 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Map (1/4) (2b68656e2c7621f89475fdaa271c1bc3) [DEPLOYING].
2020-02-28 02:16:55,848 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (2/4) (0b3adb70c418e53cfb1cd1be64e5db95) switched from CREATED to DEPLOYING.
2020-02-28 02:16:55,848 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Map (2/4) (0b3adb70c418e53cfb1cd1be64e5db95) [DEPLOYING]
2020-02-28 02:16:55,849 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Map (2/4) (0b3adb70c418e53cfb1cd1be64e5db95) [DEPLOYING].
2020-02-28 02:16:55,849 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Map (2/4) (0b3adb70c418e53cfb1cd1be64e5db95) [DEPLOYING].
2020-02-28 02:16:55,850 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Map (3/4).
2020-02-28 02:16:55,858 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (3/4) (bbd9aba2d790bbf56452585a4aae1a19) switched from CREATED to DEPLOYING.
2020-02-28 02:16:55,858 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Map (3/4) (bbd9aba2d790bbf56452585a4aae1a19) [DEPLOYING]
2020-02-28 02:16:55,858 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Map (3/4) (bbd9aba2d790bbf56452585a4aae1a19) [DEPLOYING].
2020-02-28 02:16:55,867 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Map (3/4) (bbd9aba2d790bbf56452585a4aae1a19) [DEPLOYING].
2020-02-28 02:16:55,873 [Source: Custom Source (3/4)] INFO  (Task.java:958) - Source: Custom Source (3/4) (e448ec2139b6b577f76ce0680972578c) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:55,874 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Source: Custom Source (3/4) (e448ec2139b6b577f76ce0680972578c) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:55,875 [Source: Custom Source (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:55,880 [Source: Custom Source (1/4)] INFO  (Task.java:958) - Source: Custom Source (1/4) (94ef5892b18db2d7dc283570df7b222b) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:55,881 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source (1/4) (94ef5892b18db2d7dc283570df7b222b) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:55,881 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Map (4/4).
2020-02-28 02:16:55,881 [Source: Custom Source (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:55,897 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (1/4) (2b68656e2c7621f89475fdaa271c1bc3) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:55,898 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:55,898 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (1/4) (2b68656e2c7621f89475fdaa271c1bc3) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:55,907 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source (1/4).
2020-02-28 02:16:55,907 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (2/4) (0b3adb70c418e53cfb1cd1be64e5db95) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:55,907 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (3/4) (bbd9aba2d790bbf56452585a4aae1a19) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:55,907 [Source: Custom Source (2/4)] INFO  (Task.java:958) - Source: Custom Source (2/4) (09b8a4066c9083f2601045b3c852f38e) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:55,907 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:55,907 [Source: Custom Source (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:55,909 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (2/4) (0b3adb70c418e53cfb1cd1be64e5db95) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:55,909 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (3/4) (bbd9aba2d790bbf56452585a4aae1a19) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:55,910 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source (2/4) (09b8a4066c9083f2601045b3c852f38e) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:55,907 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (4/4) (75497dca693c043a328597ad72a4d495) switched from CREATED to DEPLOYING.
2020-02-28 02:16:55,907 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:55,915 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Map (4/4) (75497dca693c043a328597ad72a4d495) [DEPLOYING]
2020-02-28 02:16:55,915 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Map (4/4) (75497dca693c043a328597ad72a4d495) [DEPLOYING].
2020-02-28 02:16:55,934 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source (2/4).
2020-02-28 02:16:55,939 [Source: Custom Source (1/4)] INFO  (Task.java:958) - Source: Custom Source (1/4) (39659281680d7028202a317b6dbe46aa) switched from CREATED to DEPLOYING.
2020-02-28 02:16:55,939 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Map (4/4) (75497dca693c043a328597ad72a4d495) [DEPLOYING].
2020-02-28 02:16:55,939 [Source: Custom Source (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source (1/4) (39659281680d7028202a317b6dbe46aa) [DEPLOYING]
2020-02-28 02:16:55,939 [Source: Custom Source (1/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source (1/4) (39659281680d7028202a317b6dbe46aa) [DEPLOYING].
2020-02-28 02:16:55,940 [Source: Custom Source (1/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source (1/4) (39659281680d7028202a317b6dbe46aa) [DEPLOYING].
2020-02-28 02:16:55,941 [Source: Custom Source (2/4)] INFO  (Task.java:958) - Source: Custom Source (2/4) (e60507f2bb706dd2ca7d2b3c315ab616) switched from CREATED to DEPLOYING.
2020-02-28 02:16:55,941 [Source: Custom Source (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source (2/4) (e60507f2bb706dd2ca7d2b3c315ab616) [DEPLOYING]
2020-02-28 02:16:55,941 [Source: Custom Source (2/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source (2/4) (e60507f2bb706dd2ca7d2b3c315ab616) [DEPLOYING].
2020-02-28 02:16:55,941 [Source: Custom Source (2/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source (2/4) (e60507f2bb706dd2ca7d2b3c315ab616) [DEPLOYING].
2020-02-28 02:16:55,946 [Source: Custom Source (3/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-28 02:16:55,946 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-28 02:16:55,946 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-28 02:16:55,946 [Source: Custom Source (2/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-28 02:16:55,946 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-28 02:16:55,946 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-28 02:16:55,946 [Source: Custom Source (1/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-28 02:16:55,946 [Source: Custom Source (3/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-28 02:16:55,947 [Source: Custom Source (1/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-28 02:16:55,946 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-28 02:16:55,946 [Source: Custom Source (2/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-28 02:16:55,947 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-28 02:16:55,949 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source (3/4).
2020-02-28 02:16:55,949 [Source: Custom Source (1/4)] INFO  (Task.java:958) - Source: Custom Source (1/4) (39659281680d7028202a317b6dbe46aa) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:55,950 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Source: Custom Source (1/4) (39659281680d7028202a317b6dbe46aa) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:55,950 [Source: Custom Source (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:55,952 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source (4/4).
2020-02-28 02:16:55,952 [Source: Custom Source (3/4)] INFO  (Task.java:958) - Source: Custom Source (3/4) (dce10faecf772de9ba8f6fe339930189) switched from CREATED to DEPLOYING.
2020-02-28 02:16:55,952 [Source: Custom Source (1/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-28 02:16:55,952 [Source: Custom Source (1/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-28 02:16:55,954 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source (4/4).
2020-02-28 02:16:55,952 [Source: Custom Source (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source (3/4) (dce10faecf772de9ba8f6fe339930189) [DEPLOYING]
2020-02-28 02:16:55,955 [Source: Custom Source (3/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source (3/4) (dce10faecf772de9ba8f6fe339930189) [DEPLOYING].
2020-02-28 02:16:55,956 [Source: Custom Source (3/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source (3/4) (dce10faecf772de9ba8f6fe339930189) [DEPLOYING].
2020-02-28 02:16:55,957 [Source: Custom Source (4/4)] INFO  (Task.java:958) - Source: Custom Source (4/4) (35dbc00df37e7b8409ef6d7cd9e1cc23) switched from CREATED to DEPLOYING.
2020-02-28 02:16:55,957 [Source: Custom Source (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source (4/4) (35dbc00df37e7b8409ef6d7cd9e1cc23) [DEPLOYING]
2020-02-28 02:16:55,957 [Source: Custom Source (4/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source (4/4) (35dbc00df37e7b8409ef6d7cd9e1cc23) [DEPLOYING].
2020-02-28 02:16:55,957 [Source: Custom Source (4/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source (4/4) (35dbc00df37e7b8409ef6d7cd9e1cc23) [DEPLOYING].
2020-02-28 02:16:55,963 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Map (1/4).
2020-02-28 02:16:55,963 [Source: Custom Source (4/4)] INFO  (Task.java:958) - Source: Custom Source (4/4) (cb3092089b9eca91b2a588c879f8504a) switched from CREATED to DEPLOYING.
2020-02-28 02:16:55,964 [Source: Custom Source (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source (4/4) (cb3092089b9eca91b2a588c879f8504a) [DEPLOYING]
2020-02-28 02:16:55,964 [Source: Custom Source (4/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source (4/4) (cb3092089b9eca91b2a588c879f8504a) [DEPLOYING].
2020-02-28 02:16:55,964 [Source: Custom Source (4/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source (4/4) (cb3092089b9eca91b2a588c879f8504a) [DEPLOYING].
2020-02-28 02:16:55,965 [Source: Custom Source (1/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 0 has no restore state.
2020-02-28 02:16:55,965 [Source: Custom Source (2/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 1 has no restore state.
2020-02-28 02:16:55,966 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 2 has no restore state.
2020-02-28 02:16:55,966 [Source: Custom Source (1/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 0 has no restore state.
2020-02-28 02:16:55,965 [Source: Custom Source (3/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 2 has no restore state.
2020-02-28 02:16:55,966 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 0 has no restore state.
2020-02-28 02:16:55,970 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 1 has no restore state.
2020-02-28 02:16:55,973 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (1/4) (5436c29940ef81e2e47f86276b1510b2) switched from CREATED to DEPLOYING.
2020-02-28 02:16:55,975 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Map (1/4) (5436c29940ef81e2e47f86276b1510b2) [DEPLOYING]
2020-02-28 02:16:55,975 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Map (1/4) (5436c29940ef81e2e47f86276b1510b2) [DEPLOYING].
2020-02-28 02:16:55,975 [Source: Custom Source (2/4)] INFO  (Task.java:958) - Source: Custom Source (2/4) (e60507f2bb706dd2ca7d2b3c315ab616) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:55,975 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Map (1/4) (5436c29940ef81e2e47f86276b1510b2) [DEPLOYING].
2020-02-28 02:16:55,976 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source (2/4) (e60507f2bb706dd2ca7d2b3c315ab616) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:55,976 [Source: Custom Source (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:55,978 [Source: Custom Source (2/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-28 02:16:55,978 [Source: Custom Source (2/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-28 02:16:55,978 [Source: Custom Source (2/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 1 has no restore state.
2020-02-28 02:16:55,984 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Map (2/4).
2020-02-28 02:16:55,984 [Source: Custom Source (3/4)] INFO  (Task.java:958) - Source: Custom Source (3/4) (dce10faecf772de9ba8f6fe339930189) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:55,985 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Source: Custom Source (3/4) (dce10faecf772de9ba8f6fe339930189) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:55,986 [Source: Custom Source (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:55,987 [Source: Custom Source (3/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-28 02:16:55,987 [Source: Custom Source (3/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-28 02:16:55,988 [Source: Custom Source (3/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 2 has no restore state.
2020-02-28 02:16:55,988 [Source: Custom Source (4/4)] INFO  (Task.java:958) - Source: Custom Source (4/4) (cb3092089b9eca91b2a588c879f8504a) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:55,988 [Source: Custom Source (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:55,989 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Source: Custom Source (4/4) (cb3092089b9eca91b2a588c879f8504a) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:55,988 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (2/4) (925fc4b864f9c06ab48577a02e9f46af) switched from CREATED to DEPLOYING.
2020-02-28 02:16:55,990 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (1/4) (5436c29940ef81e2e47f86276b1510b2) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:55,990 [Source: Custom Source (4/4)] INFO  (Task.java:958) - Source: Custom Source (4/4) (35dbc00df37e7b8409ef6d7cd9e1cc23) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:55,990 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (1/4) (5436c29940ef81e2e47f86276b1510b2) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:55,990 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Map (2/4) (925fc4b864f9c06ab48577a02e9f46af) [DEPLOYING]
2020-02-28 02:16:55,990 [Source: Custom Source (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:55,990 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:55,990 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Source: Custom Source (4/4) (35dbc00df37e7b8409ef6d7cd9e1cc23) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:55,990 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Map (2/4) (925fc4b864f9c06ab48577a02e9f46af) [DEPLOYING].
2020-02-28 02:16:55,992 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (4/4) (75497dca693c043a328597ad72a4d495) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:55,993 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (4/4) (75497dca693c043a328597ad72a4d495) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:55,993 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Map (2/4) (925fc4b864f9c06ab48577a02e9f46af) [DEPLOYING].
2020-02-28 02:16:55,993 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:56,006 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (2/4) (925fc4b864f9c06ab48577a02e9f46af) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,006 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:56,006 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (2/4) (925fc4b864f9c06ab48577a02e9f46af) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,007 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Map (3/4).
2020-02-28 02:16:56,007 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:56,008 [Source: Custom Source (4/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-28 02:16:56,008 [Source: Custom Source (4/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-28 02:16:56,009 [Source: Custom Source (4/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 3 has no restore state.
2020-02-28 02:16:56,009 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-28 02:16:56,009 [Source: Custom Source (4/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:56,013 [Source: Custom Source (1/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:56,008 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:56,013 [Source: Custom Source (3/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:56,013 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:56,011 [Source: Custom Source (1/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:56,011 [Source: Custom Source (3/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:56,008 [Source: Custom Source (2/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:56,007 [Source: Custom Source (2/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:56,010 [Source: Custom Source (4/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-28 02:16:56,010 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-28 02:16:56,023 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-28 02:16:56,023 [Source: Custom Source (4/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-28 02:16:56,024 [Source: Custom Source (4/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 3 has no restore state.
2020-02-28 02:16:56,017 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-28 02:16:56,015 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Map (4/4).
2020-02-28 02:16:56,013 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (3/4) (cc9d60061a79fbaa6bda74b851362a42) switched from CREATED to DEPLOYING.
2020-02-28 02:16:56,013 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-28 02:16:56,027 [Source: Custom Source (4/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:56,027 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 3 has no restore state.
2020-02-28 02:16:56,024 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 0 has no restore state.
2020-02-28 02:16:56,030 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-28 02:16:56,030 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:56,030 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (4/4) (01f5c4e6b7ad5c94b9983556f1c51601) switched from CREATED to DEPLOYING.
2020-02-28 02:16:56,030 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Map (3/4) (cc9d60061a79fbaa6bda74b851362a42) [DEPLOYING]
2020-02-28 02:16:56,033 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Map (3/4) (cc9d60061a79fbaa6bda74b851362a42) [DEPLOYING].
2020-02-28 02:16:56,033 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Map (3/4) (cc9d60061a79fbaa6bda74b851362a42) [DEPLOYING].
2020-02-28 02:16:56,030 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 1 has no restore state.
2020-02-28 02:16:56,030 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:56,034 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Map (4/4) (01f5c4e6b7ad5c94b9983556f1c51601) [DEPLOYING]
2020-02-28 02:16:56,035 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:56,035 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Map (4/4) (01f5c4e6b7ad5c94b9983556f1c51601) [DEPLOYING].
2020-02-28 02:16:56,042 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Map (4/4) (01f5c4e6b7ad5c94b9983556f1c51601) [DEPLOYING].
2020-02-28 02:16:56,045 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Sink: Print to Std. Out (1/4).
2020-02-28 02:16:56,047 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (3/4) (cc9d60061a79fbaa6bda74b851362a42) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,047 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:56,047 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (3/4) (cc9d60061a79fbaa6bda74b851362a42) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,057 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (4/4) (01f5c4e6b7ad5c94b9983556f1c51601) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,057 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:56,058 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (4/4) (01f5c4e6b7ad5c94b9983556f1c51601) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,060 [Sink: Print to Std. Out (1/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (1/4) (a8d5c6e99b63bdaaf7b65a104960d1f2) switched from CREATED to DEPLOYING.
2020-02-28 02:16:56,060 [Sink: Print to Std. Out (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (1/4) (a8d5c6e99b63bdaaf7b65a104960d1f2) [DEPLOYING]
2020-02-28 02:16:56,060 [Sink: Print to Std. Out (1/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Print to Std. Out (1/4) (a8d5c6e99b63bdaaf7b65a104960d1f2) [DEPLOYING].
2020-02-28 02:16:56,060 [Sink: Print to Std. Out (1/4)] INFO  (Task.java:619) - Registering task at network: Sink: Print to Std. Out (1/4) (a8d5c6e99b63bdaaf7b65a104960d1f2) [DEPLOYING].
2020-02-28 02:16:56,062 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Sink: Print to Std. Out (2/4).
2020-02-28 02:16:56,064 [Sink: Print to Std. Out (2/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (2/4) (7976610031a13a14e9b53a493fe5c596) switched from CREATED to DEPLOYING.
2020-02-28 02:16:56,064 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-28 02:16:56,066 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-28 02:16:56,067 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 2 has no restore state.
2020-02-28 02:16:56,067 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:56,068 [Sink: Print to Std. Out (1/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (1/4) (a8d5c6e99b63bdaaf7b65a104960d1f2) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,068 [Sink: Print to Std. Out (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:56,064 [Sink: Print to Std. Out (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (2/4) (7976610031a13a14e9b53a493fe5c596) [DEPLOYING]
2020-02-28 02:16:56,072 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Sink: Print to Std. Out (3/4).
2020-02-28 02:16:56,071 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-28 02:16:56,068 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Sink: Print to Std. Out (1/4) (a8d5c6e99b63bdaaf7b65a104960d1f2) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,076 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-28 02:16:56,077 [Sink: Print to Std. Out (3/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (3/4) (009e306ed5e40696b5b18441884abf6e) switched from CREATED to DEPLOYING.
2020-02-28 02:16:56,077 [Sink: Print to Std. Out (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (3/4) (009e306ed5e40696b5b18441884abf6e) [DEPLOYING]
2020-02-28 02:16:56,078 [Sink: Print to Std. Out (3/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Print to Std. Out (3/4) (009e306ed5e40696b5b18441884abf6e) [DEPLOYING].
2020-02-28 02:16:56,076 [Sink: Print to Std. Out (2/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Print to Std. Out (2/4) (7976610031a13a14e9b53a493fe5c596) [DEPLOYING].
2020-02-28 02:16:56,079 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Sink: Print to Std. Out (4/4).
2020-02-28 02:16:56,077 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 3 has no restore state.
2020-02-28 02:16:56,081 [Sink: Print to Std. Out (4/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (4/4) (58fcc3bf73076384465785bd53dbe43d) switched from CREATED to DEPLOYING.
2020-02-28 02:16:56,081 [Sink: Print to Std. Out (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (4/4) (58fcc3bf73076384465785bd53dbe43d) [DEPLOYING]
2020-02-28 02:16:56,081 [Sink: Print to Std. Out (4/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Print to Std. Out (4/4) (58fcc3bf73076384465785bd53dbe43d) [DEPLOYING].
2020-02-28 02:16:56,081 [Sink: Print to Std. Out (4/4)] INFO  (Task.java:619) - Registering task at network: Sink: Print to Std. Out (4/4) (58fcc3bf73076384465785bd53dbe43d) [DEPLOYING].
2020-02-28 02:16:56,079 [Sink: Print to Std. Out (2/4)] INFO  (Task.java:619) - Registering task at network: Sink: Print to Std. Out (2/4) (7976610031a13a14e9b53a493fe5c596) [DEPLOYING].
2020-02-28 02:16:56,079 [Sink: Print to Std. Out (3/4)] INFO  (Task.java:619) - Registering task at network: Sink: Print to Std. Out (3/4) (009e306ed5e40696b5b18441884abf6e) [DEPLOYING].
2020-02-28 02:16:56,089 [Sink: Print to Std. Out (2/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (2/4) (7976610031a13a14e9b53a493fe5c596) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,094 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Sink: Print to Std. Out (2/4) (7976610031a13a14e9b53a493fe5c596) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,084 [Sink: Print to Std. Out (4/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (4/4) (58fcc3bf73076384465785bd53dbe43d) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,082 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (1/4).
2020-02-28 02:16:56,081 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:56,095 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Sink: Print to Std. Out (4/4) (58fcc3bf73076384465785bd53dbe43d) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,094 [Sink: Print to Std. Out (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:56,099 [Sink: Print to Std. Out (3/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (3/4) (009e306ed5e40696b5b18441884abf6e) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,096 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (2/4).
2020-02-28 02:16:56,095 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (1/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (1/4) (618792d0ac593b352e95e3c95c03eb4a) switched from CREATED to DEPLOYING.
2020-02-28 02:16:56,095 [Sink: Print to Std. Out (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:56,109 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (2/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (2/4) (54018ea9ca53a0ed0be9c2e2fccf50a1) switched from CREATED to DEPLOYING.
2020-02-28 02:16:56,108 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (3/4).
2020-02-28 02:16:56,119 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (2/4) (54018ea9ca53a0ed0be9c2e2fccf50a1) [DEPLOYING]
2020-02-28 02:16:56,119 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (2/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (2/4) (54018ea9ca53a0ed0be9c2e2fccf50a1) [DEPLOYING].
2020-02-28 02:16:56,120 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (2/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (2/4) (54018ea9ca53a0ed0be9c2e2fccf50a1) [DEPLOYING].
2020-02-28 02:16:56,107 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (1/4) (618792d0ac593b352e95e3c95c03eb4a) [DEPLOYING]
2020-02-28 02:16:56,124 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (1/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (1/4) (618792d0ac593b352e95e3c95c03eb4a) [DEPLOYING].
2020-02-28 02:16:56,124 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (3/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (3/4) (2db8a7001715ac6475d39c6889a8053c) switched from CREATED to DEPLOYING.
2020-02-28 02:16:56,125 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (3/4) (2db8a7001715ac6475d39c6889a8053c) [DEPLOYING]
2020-02-28 02:16:56,125 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (1/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (1/4) (618792d0ac593b352e95e3c95c03eb4a) [DEPLOYING].
2020-02-28 02:16:56,108 [Sink: Print to Std. Out (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:56,108 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Sink: Print to Std. Out (3/4) (009e306ed5e40696b5b18441884abf6e) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,132 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (2/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (2/4) (54018ea9ca53a0ed0be9c2e2fccf50a1) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,125 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (3/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (3/4) (2db8a7001715ac6475d39c6889a8053c) [DEPLOYING].
2020-02-28 02:16:56,134 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:56,135 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (3/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (3/4) (2db8a7001715ac6475d39c6889a8053c) [DEPLOYING].
2020-02-28 02:16:56,125 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (4/4).
2020-02-28 02:16:56,134 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (2/4) (54018ea9ca53a0ed0be9c2e2fccf50a1) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,137 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (4/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (4/4) (5ff31f4f896c37c68173ed1b6e5543a9) switched from CREATED to DEPLOYING.
2020-02-28 02:16:56,137 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (4/4) (5ff31f4f896c37c68173ed1b6e5543a9) [DEPLOYING]
2020-02-28 02:16:56,137 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (4/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (4/4) (5ff31f4f896c37c68173ed1b6e5543a9) [DEPLOYING].
2020-02-28 02:16:56,141 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task KeyedProcess (1/4).
2020-02-28 02:16:56,147 [KeyedProcess (1/4)] INFO  (Task.java:958) - KeyedProcess (1/4) (6254c3586d143a34711abd9ab9bbae89) switched from CREATED to DEPLOYING.
2020-02-28 02:16:56,147 [KeyedProcess (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task KeyedProcess (1/4) (6254c3586d143a34711abd9ab9bbae89) [DEPLOYING]
2020-02-28 02:16:56,147 [KeyedProcess (1/4)] INFO  (Task.java:593) - Loading JAR files for task KeyedProcess (1/4) (6254c3586d143a34711abd9ab9bbae89) [DEPLOYING].
2020-02-28 02:16:56,147 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task KeyedProcess (2/4).
2020-02-28 02:16:56,159 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task KeyedProcess (4/4).
2020-02-28 02:16:56,160 [KeyedProcess (2/4)] INFO  (Task.java:958) - KeyedProcess (2/4) (84062b9addfdf242b60fbaf43c12bf13) switched from CREATED to DEPLOYING.
2020-02-28 02:16:56,160 [KeyedProcess (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task KeyedProcess (2/4) (84062b9addfdf242b60fbaf43c12bf13) [DEPLOYING]
2020-02-28 02:16:56,160 [KeyedProcess (2/4)] INFO  (Task.java:593) - Loading JAR files for task KeyedProcess (2/4) (84062b9addfdf242b60fbaf43c12bf13) [DEPLOYING].
2020-02-28 02:16:56,165 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (4/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (4/4) (5ff31f4f896c37c68173ed1b6e5543a9) [DEPLOYING].
2020-02-28 02:16:56,166 [KeyedProcess (1/4)] INFO  (Task.java:619) - Registering task at network: KeyedProcess (1/4) (6254c3586d143a34711abd9ab9bbae89) [DEPLOYING].
2020-02-28 02:16:56,166 [KeyedProcess (2/4)] INFO  (Task.java:619) - Registering task at network: KeyedProcess (2/4) (84062b9addfdf242b60fbaf43c12bf13) [DEPLOYING].
2020-02-28 02:16:56,165 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Sink: Unnamed (1/4).
2020-02-28 02:16:56,170 [KeyedProcess (4/4)] INFO  (Task.java:958) - KeyedProcess (4/4) (cb9cb5b43a8091d8cc65a940d694adda) switched from CREATED to DEPLOYING.
2020-02-28 02:16:56,171 [KeyedProcess (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task KeyedProcess (4/4) (cb9cb5b43a8091d8cc65a940d694adda) [DEPLOYING]
2020-02-28 02:16:56,171 [KeyedProcess (4/4)] INFO  (Task.java:593) - Loading JAR files for task KeyedProcess (4/4) (cb9cb5b43a8091d8cc65a940d694adda) [DEPLOYING].
2020-02-28 02:16:56,171 [KeyedProcess (4/4)] INFO  (Task.java:619) - Registering task at network: KeyedProcess (4/4) (cb9cb5b43a8091d8cc65a940d694adda) [DEPLOYING].
2020-02-28 02:16:56,172 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Sink: Unnamed (2/4).
2020-02-28 02:16:56,174 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task KeyedProcess (3/4).
2020-02-28 02:16:56,180 [KeyedProcess (3/4)] INFO  (Task.java:958) - KeyedProcess (3/4) (abd011e107dae07a7d14df1013e9838e) switched from CREATED to DEPLOYING.
2020-02-28 02:16:56,180 [KeyedProcess (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task KeyedProcess (3/4) (abd011e107dae07a7d14df1013e9838e) [DEPLOYING]
2020-02-28 02:16:56,181 [KeyedProcess (3/4)] INFO  (Task.java:593) - Loading JAR files for task KeyedProcess (3/4) (abd011e107dae07a7d14df1013e9838e) [DEPLOYING].
2020-02-28 02:16:56,181 [KeyedProcess (3/4)] INFO  (Task.java:619) - Registering task at network: KeyedProcess (3/4) (abd011e107dae07a7d14df1013e9838e) [DEPLOYING].
2020-02-28 02:16:56,176 [Sink: Unnamed (1/4)] INFO  (Task.java:958) - Sink: Unnamed (1/4) (7480cdb93c0688ae4269c805bbf9b49c) switched from CREATED to DEPLOYING.
2020-02-28 02:16:56,188 [Sink: Unnamed (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Unnamed (1/4) (7480cdb93c0688ae4269c805bbf9b49c) [DEPLOYING]
2020-02-28 02:16:56,189 [Sink: Unnamed (1/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Unnamed (1/4) (7480cdb93c0688ae4269c805bbf9b49c) [DEPLOYING].
2020-02-28 02:16:56,174 [Sink: Unnamed (2/4)] INFO  (Task.java:958) - Sink: Unnamed (2/4) (281150e2aaea3a4d9034e6b8b9dff1e8) switched from CREATED to DEPLOYING.
2020-02-28 02:16:56,192 [Sink: Unnamed (1/4)] INFO  (Task.java:619) - Registering task at network: Sink: Unnamed (1/4) (7480cdb93c0688ae4269c805bbf9b49c) [DEPLOYING].
2020-02-28 02:16:56,192 [KeyedProcess (1/4)] INFO  (Task.java:958) - KeyedProcess (1/4) (6254c3586d143a34711abd9ab9bbae89) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,193 [KeyedProcess (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:56,189 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (1/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (1/4) (618792d0ac593b352e95e3c95c03eb4a) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,192 [Sink: Unnamed (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Unnamed (2/4) (281150e2aaea3a4d9034e6b8b9dff1e8) [DEPLOYING]
2020-02-28 02:16:56,194 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:56,194 [Sink: Unnamed (2/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Unnamed (2/4) (281150e2aaea3a4d9034e6b8b9dff1e8) [DEPLOYING].
2020-02-28 02:16:56,201 [Sink: Unnamed (2/4)] INFO  (Task.java:619) - Registering task at network: Sink: Unnamed (2/4) (281150e2aaea3a4d9034e6b8b9dff1e8) [DEPLOYING].
2020-02-28 02:16:56,194 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - KeyedProcess (1/4) (6254c3586d143a34711abd9ab9bbae89) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,200 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (4/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (4/4) (5ff31f4f896c37c68173ed1b6e5543a9) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,197 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Sink: Unnamed (3/4).
2020-02-28 02:16:56,203 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (1/4) (618792d0ac593b352e95e3c95c03eb4a) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,203 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (4/4) (5ff31f4f896c37c68173ed1b6e5543a9) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,202 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:56,212 [Sink: Unnamed (3/4)] INFO  (Task.java:958) - Sink: Unnamed (3/4) (83e569c47365334307d2aa3070e30fb2) switched from CREATED to DEPLOYING.
2020-02-28 02:16:56,213 [Sink: Unnamed (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Unnamed (3/4) (83e569c47365334307d2aa3070e30fb2) [DEPLOYING]
2020-02-28 02:16:56,213 [Sink: Unnamed (3/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Unnamed (3/4) (83e569c47365334307d2aa3070e30fb2) [DEPLOYING].
2020-02-28 02:16:56,213 [Sink: Unnamed (3/4)] INFO  (Task.java:619) - Registering task at network: Sink: Unnamed (3/4) (83e569c47365334307d2aa3070e30fb2) [DEPLOYING].
2020-02-28 02:16:56,213 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Sink: Unnamed (4/4).
2020-02-28 02:16:56,228 [Sink: Unnamed (4/4)] INFO  (Task.java:958) - Sink: Unnamed (4/4) (39319c0227e31f3dd0eb0b11461cb43d) switched from CREATED to DEPLOYING.
2020-02-28 02:16:56,228 [Sink: Unnamed (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Unnamed (4/4) (39319c0227e31f3dd0eb0b11461cb43d) [DEPLOYING]
2020-02-28 02:16:56,228 [Sink: Unnamed (4/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Unnamed (4/4) (39319c0227e31f3dd0eb0b11461cb43d) [DEPLOYING].
2020-02-28 02:16:56,229 [Sink: Unnamed (4/4)] INFO  (Task.java:619) - Registering task at network: Sink: Unnamed (4/4) (39319c0227e31f3dd0eb0b11461cb43d) [DEPLOYING].
2020-02-28 02:16:56,229 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Flat Map (1/4).
2020-02-28 02:16:56,238 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Flat Map (2/4).
2020-02-28 02:16:56,238 [Flat Map (1/4)] INFO  (Task.java:958) - Flat Map (1/4) (23e6d95a9dcf53b94cd41c744e5d6df3) switched from CREATED to DEPLOYING.
2020-02-28 02:16:56,238 [Flat Map (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Flat Map (1/4) (23e6d95a9dcf53b94cd41c744e5d6df3) [DEPLOYING]
2020-02-28 02:16:56,238 [Flat Map (1/4)] INFO  (Task.java:593) - Loading JAR files for task Flat Map (1/4) (23e6d95a9dcf53b94cd41c744e5d6df3) [DEPLOYING].
2020-02-28 02:16:56,239 [Flat Map (1/4)] INFO  (Task.java:619) - Registering task at network: Flat Map (1/4) (23e6d95a9dcf53b94cd41c744e5d6df3) [DEPLOYING].
2020-02-28 02:16:56,244 [Flat Map (2/4)] INFO  (Task.java:958) - Flat Map (2/4) (d53f62e920a3d200b4a718c620e80874) switched from CREATED to DEPLOYING.
2020-02-28 02:16:56,245 [Flat Map (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Flat Map (2/4) (d53f62e920a3d200b4a718c620e80874) [DEPLOYING]
2020-02-28 02:16:56,249 [Flat Map (2/4)] INFO  (Task.java:593) - Loading JAR files for task Flat Map (2/4) (d53f62e920a3d200b4a718c620e80874) [DEPLOYING].
2020-02-28 02:16:56,249 [Flat Map (2/4)] INFO  (Task.java:619) - Registering task at network: Flat Map (2/4) (d53f62e920a3d200b4a718c620e80874) [DEPLOYING].
2020-02-28 02:16:56,248 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:56,249 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Flat Map (3/4).
2020-02-28 02:16:56,250 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:56,250 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582849016219
2020-02-28 02:16:56,252 [Flat Map (3/4)] INFO  (Task.java:958) - Flat Map (3/4) (6261faa62991f4539b9ed8f045e49ef0) switched from CREATED to DEPLOYING.
2020-02-28 02:16:56,252 [Flat Map (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Flat Map (3/4) (6261faa62991f4539b9ed8f045e49ef0) [DEPLOYING]
2020-02-28 02:16:56,253 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Flat Map (4/4).
2020-02-28 02:16:56,253 [Flat Map (3/4)] INFO  (Task.java:593) - Loading JAR files for task Flat Map (3/4) (6261faa62991f4539b9ed8f045e49ef0) [DEPLOYING].
2020-02-28 02:16:56,253 [Flat Map (3/4)] INFO  (Task.java:619) - Registering task at network: Flat Map (3/4) (6261faa62991f4539b9ed8f045e49ef0) [DEPLOYING].
2020-02-28 02:16:56,257 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Sink: Print to Std. Out (1/4).
2020-02-28 02:16:56,258 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (3/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (3/4) (2db8a7001715ac6475d39c6889a8053c) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,259 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (3/4) (2db8a7001715ac6475d39c6889a8053c) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,259 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:56,263 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (4/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-28 02:16:56,264 [Flat Map (4/4)] INFO  (Task.java:958) - Flat Map (4/4) (8b4829311aec3a64dbc419b77241ffb9) switched from CREATED to DEPLOYING.
2020-02-28 02:16:56,265 [Flat Map (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Flat Map (4/4) (8b4829311aec3a64dbc419b77241ffb9) [DEPLOYING]
2020-02-28 02:16:56,265 [Flat Map (4/4)] INFO  (Task.java:593) - Loading JAR files for task Flat Map (4/4) (8b4829311aec3a64dbc419b77241ffb9) [DEPLOYING].
2020-02-28 02:16:56,265 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Sink: Print to Std. Out (2/4).
2020-02-28 02:16:56,265 [Sink: Print to Std. Out (1/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (1/4) (dd9c9bd104fbe907a44e33650f113513) switched from CREATED to DEPLOYING.
2020-02-28 02:16:56,266 [Sink: Print to Std. Out (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (1/4) (dd9c9bd104fbe907a44e33650f113513) [DEPLOYING]
2020-02-28 02:16:56,266 [Sink: Print to Std. Out (1/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Print to Std. Out (1/4) (dd9c9bd104fbe907a44e33650f113513) [DEPLOYING].
2020-02-28 02:16:56,266 [Sink: Print to Std. Out (1/4)] INFO  (Task.java:619) - Registering task at network: Sink: Print to Std. Out (1/4) (dd9c9bd104fbe907a44e33650f113513) [DEPLOYING].
2020-02-28 02:16:56,267 [Flat Map (4/4)] INFO  (Task.java:619) - Registering task at network: Flat Map (4/4) (8b4829311aec3a64dbc419b77241ffb9) [DEPLOYING].
2020-02-28 02:16:56,273 [Sink: Print to Std. Out (2/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (2/4) (8f12deba1d6471291e6527a93ed0474e) switched from CREATED to DEPLOYING.
2020-02-28 02:16:56,273 [Sink: Print to Std. Out (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (2/4) (8f12deba1d6471291e6527a93ed0474e) [DEPLOYING]
2020-02-28 02:16:56,274 [Sink: Print to Std. Out (2/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Print to Std. Out (2/4) (8f12deba1d6471291e6527a93ed0474e) [DEPLOYING].
2020-02-28 02:16:56,274 [Sink: Print to Std. Out (2/4)] INFO  (Task.java:619) - Registering task at network: Sink: Print to Std. Out (2/4) (8f12deba1d6471291e6527a93ed0474e) [DEPLOYING].
2020-02-28 02:16:56,279 [Flat Map (1/4)] INFO  (Task.java:958) - Flat Map (1/4) (23e6d95a9dcf53b94cd41c744e5d6df3) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,280 [Flat Map (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:56,280 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (3/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-28 02:16:56,280 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Flat Map (1/4) (23e6d95a9dcf53b94cd41c744e5d6df3) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,281 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Sink: Print to Std. Out (3/4).
2020-02-28 02:16:56,263 [KeyedProcess (1/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-28 02:16:56,266 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (1/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-28 02:16:56,266 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (2/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-28 02:16:56,285 [KeyedProcess (1/4)] INFO  (TypeExtractor.java:1815) - class java.util.Vector does not contain a getter for field elementData
2020-02-28 02:16:56,285 [KeyedProcess (1/4)] INFO  (TypeExtractor.java:1818) - class java.util.Vector does not contain a setter for field elementData
2020-02-28 02:16:56,285 [KeyedProcess (1/4)] INFO  (TypeExtractor.java:1857) - Class class java.util.Vector cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-28 02:16:56,288 [Sink: Print to Std. Out (3/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (3/4) (2b09f78eade1d200c05c29ba9cd68c16) switched from CREATED to DEPLOYING.
2020-02-28 02:16:56,285 [Source: Custom Source (3/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:56,297 [Source: Custom Source (3/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:56,297 [Source: Custom Source (3/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582849016280
2020-02-28 02:16:56,297 [Sink: Print to Std. Out (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (3/4) (2b09f78eade1d200c05c29ba9cd68c16) [DEPLOYING]
2020-02-28 02:16:56,295 [Flat Map (1/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-28 02:16:56,294 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:592) - Received task Sink: Print to Std. Out (4/4).
2020-02-28 02:16:56,293 [Sink: Unnamed (4/4)] INFO  (Task.java:958) - Sink: Unnamed (4/4) (39319c0227e31f3dd0eb0b11461cb43d) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,298 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Unnamed (4/4) (39319c0227e31f3dd0eb0b11461cb43d) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,298 [Sink: Print to Std. Out (3/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Print to Std. Out (3/4) (2b09f78eade1d200c05c29ba9cd68c16) [DEPLOYING].
2020-02-28 02:16:56,299 [Sink: Unnamed (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:56,301 [Sink: Print to Std. Out (3/4)] INFO  (Task.java:619) - Registering task at network: Sink: Print to Std. Out (3/4) (2b09f78eade1d200c05c29ba9cd68c16) [DEPLOYING].
2020-02-28 02:16:56,305 [Sink: Unnamed (3/4)] INFO  (Task.java:958) - Sink: Unnamed (3/4) (83e569c47365334307d2aa3070e30fb2) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,305 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:56,305 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:56,305 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582849016258
2020-02-28 02:16:56,306 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Unnamed (3/4) (83e569c47365334307d2aa3070e30fb2) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,305 [Sink: Unnamed (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:56,306 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:56,306 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:56,306 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582849016222
2020-02-28 02:16:56,307 [Sink: Unnamed (4/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-28 02:16:56,307 [Sink: Unnamed (4/4)] WARN  (FlinkKafkaProducer.java:998) - Using EXACTLY_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-02-28 02:16:56,306 [Sink: Print to Std. Out (4/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (4/4) (5c5fa427a24e6a84af4a04c2d3661709) switched from CREATED to DEPLOYING.
2020-02-28 02:16:56,306 [flink-akka.actor.default-dispatcher-2] INFO  (TaskSlotTable.java:242) - Activate slot 17a900a552b47b5e090a5983e8fdf3e2.
2020-02-28 02:16:56,308 [flink-akka.actor.default-dispatcher-2] INFO  (TaskSlotTable.java:242) - Activate slot a6ab05b5bc84b46884af96df39a94a6f.
2020-02-28 02:16:56,308 [flink-akka.actor.default-dispatcher-2] INFO  (TaskSlotTable.java:242) - Activate slot aa980e8fc9b0182d9e24a08700212c05.
2020-02-28 02:16:56,308 [flink-akka.actor.default-dispatcher-2] INFO  (TaskSlotTable.java:242) - Activate slot 2b3c2a283f89efd14031a69878878334.
2020-02-28 02:16:56,308 [Sink: Unnamed (3/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-28 02:16:56,309 [Sink: Unnamed (3/4)] WARN  (FlinkKafkaProducer.java:998) - Using EXACTLY_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-02-28 02:16:56,309 [Sink: Print to Std. Out (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (4/4) (5c5fa427a24e6a84af4a04c2d3661709) [DEPLOYING]
2020-02-28 02:16:56,309 [Sink: Print to Std. Out (4/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Print to Std. Out (4/4) (5c5fa427a24e6a84af4a04c2d3661709) [DEPLOYING].
2020-02-28 02:16:56,309 [Sink: Print to Std. Out (4/4)] INFO  (Task.java:619) - Registering task at network: Sink: Print to Std. Out (4/4) (5c5fa427a24e6a84af4a04c2d3661709) [DEPLOYING].
2020-02-28 02:16:56,309 [Sink: Unnamed (3/4)] INFO  (TwoPhaseCommitSinkFunction.java:366) - FlinkKafkaProducer 2/4 - no state to restore
2020-02-28 02:16:56,311 [Sink: Unnamed (4/4)] INFO  (TwoPhaseCommitSinkFunction.java:366) - FlinkKafkaProducer 3/4 - no state to restore
2020-02-28 02:16:56,311 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:56,312 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:56,313 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582849016223
2020-02-28 02:16:56,314 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:56,314 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:56,314 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582849016227
2020-02-28 02:16:56,314 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:56,314 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:56,314 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582849016233
2020-02-28 02:16:56,315 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:56,315 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:56,315 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582849016233
2020-02-28 02:16:56,315 [Source: Custom Source (4/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:56,316 [Source: Custom Source (4/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:56,316 [Source: Custom Source (4/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582849016233
2020-02-28 02:16:56,316 [Source: Custom Source (3/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:56,316 [Source: Custom Source (3/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:56,316 [Source: Custom Source (3/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582849016239
2020-02-28 02:16:56,317 [Source: Custom Source (2/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:56,317 [Source: Custom Source (2/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:56,317 [Source: Custom Source (2/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582849016241
2020-02-28 02:16:56,317 [Source: Custom Source (1/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:56,317 [Source: Custom Source (1/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:56,317 [Source: Custom Source (1/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582849016240
2020-02-28 02:16:56,318 [Source: Custom Source (4/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:56,318 [Source: Custom Source (4/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:56,318 [Sink: Unnamed (1/4)] INFO  (Task.java:958) - Sink: Unnamed (1/4) (7480cdb93c0688ae4269c805bbf9b49c) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,318 [Source: Custom Source (4/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582849016243
2020-02-28 02:16:56,319 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Sink: Unnamed (1/4) (7480cdb93c0688ae4269c805bbf9b49c) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,319 [Sink: Unnamed (2/4)] INFO  (Task.java:958) - Sink: Unnamed (2/4) (281150e2aaea3a4d9034e6b8b9dff1e8) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,319 [Sink: Print to Std. Out (4/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (4/4) (5c5fa427a24e6a84af4a04c2d3661709) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,319 [Source: Custom Source (1/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:56,320 [Source: Custom Source (1/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:56,320 [Source: Custom Source (1/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582849016247
2020-02-28 02:16:56,321 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:56,321 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:56,321 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582849016248
2020-02-28 02:16:56,321 [Source: Custom Source (2/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:56,322 [Source: Custom Source (2/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:56,322 [Source: Custom Source (2/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582849016295
2020-02-28 02:16:56,323 [Sink: Print to Std. Out (2/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (2/4) (8f12deba1d6471291e6527a93ed0474e) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,319 [Sink: Unnamed (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:56,320 [Sink: Print to Std. Out (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:56,324 [Flat Map (4/4)] INFO  (Task.java:958) - Flat Map (4/4) (8b4829311aec3a64dbc419b77241ffb9) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,320 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Sink: Unnamed (2/4) (281150e2aaea3a4d9034e6b8b9dff1e8) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,325 [Sink: Print to Std. Out (1/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (1/4) (dd9c9bd104fbe907a44e33650f113513) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,320 [Sink: Unnamed (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:56,325 [Flat Map (3/4)] INFO  (Task.java:958) - Flat Map (3/4) (6261faa62991f4539b9ed8f045e49ef0) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,325 [Flat Map (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:56,325 [Sink: Print to Std. Out (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:56,325 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Sink: Print to Std. Out (4/4) (5c5fa427a24e6a84af4a04c2d3661709) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,324 [Flat Map (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:56,324 [Sink: Print to Std. Out (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:56,331 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Sink: Print to Std. Out (2/4) (8f12deba1d6471291e6527a93ed0474e) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,333 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Flat Map (4/4) (8b4829311aec3a64dbc419b77241ffb9) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,333 [Sink: Unnamed (4/4)] INFO  (AbstractConfig.java:347) - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-02-28 02:16:56,330 [Sink: Print to Std. Out (3/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (3/4) (2b09f78eade1d200c05c29ba9cd68c16) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,329 [Flat Map (3/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-28 02:16:56,329 [Sink: Unnamed (2/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-28 02:16:56,329 [KeyedProcess (3/4)] INFO  (Task.java:958) - KeyedProcess (3/4) (abd011e107dae07a7d14df1013e9838e) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,329 [Sink: Unnamed (1/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-28 02:16:56,341 [Sink: Unnamed (1/4)] WARN  (FlinkKafkaProducer.java:998) - Using EXACTLY_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-02-28 02:16:56,341 [Sink: Unnamed (1/4)] INFO  (TwoPhaseCommitSinkFunction.java:366) - FlinkKafkaProducer 0/4 - no state to restore
2020-02-28 02:16:56,341 [Sink: Unnamed (1/4)] INFO  (AbstractConfig.java:347) - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-02-28 02:16:56,326 [KeyedProcess (4/4)] INFO  (Task.java:958) - KeyedProcess (4/4) (cb9cb5b43a8091d8cc65a940d694adda) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,325 [Flat Map (2/4)] INFO  (Task.java:958) - Flat Map (2/4) (d53f62e920a3d200b4a718c620e80874) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,341 [KeyedProcess (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:56,342 [Flat Map (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:56,343 [Flat Map (2/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-28 02:16:56,344 [KeyedProcess (3/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-28 02:16:56,344 [KeyedProcess (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:56,344 [KeyedProcess (3/4)] INFO  (TypeExtractor.java:1815) - class java.util.Vector does not contain a getter for field elementData
2020-02-28 02:16:56,344 [KeyedProcess (3/4)] INFO  (TypeExtractor.java:1818) - class java.util.Vector does not contain a setter for field elementData
2020-02-28 02:16:56,345 [KeyedProcess (3/4)] INFO  (TypeExtractor.java:1857) - Class class java.util.Vector cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-28 02:16:56,340 [Sink: Unnamed (2/4)] WARN  (FlinkKafkaProducer.java:998) - Using EXACTLY_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-02-28 02:16:56,345 [Sink: Unnamed (2/4)] INFO  (TwoPhaseCommitSinkFunction.java:366) - FlinkKafkaProducer 1/4 - no state to restore
2020-02-28 02:16:56,346 [KeyedProcess (4/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-28 02:16:56,347 [KeyedProcess (4/4)] INFO  (TypeExtractor.java:1815) - class java.util.Vector does not contain a getter for field elementData
2020-02-28 02:16:56,347 [KeyedProcess (4/4)] INFO  (TypeExtractor.java:1818) - class java.util.Vector does not contain a setter for field elementData
2020-02-28 02:16:56,347 [KeyedProcess (4/4)] INFO  (TypeExtractor.java:1857) - Class class java.util.Vector cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-28 02:16:56,339 [Sink: Print to Std. Out (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:56,337 [Flat Map (4/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-28 02:16:56,334 [Sink: Unnamed (3/4)] INFO  (AbstractConfig.java:347) - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-02-28 02:16:56,337 [KeyedProcess (2/4)] INFO  (Task.java:958) - KeyedProcess (2/4) (84062b9addfdf242b60fbaf43c12bf13) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,333 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Sink: Print to Std. Out (1/4) (dd9c9bd104fbe907a44e33650f113513) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,346 [Sink: Unnamed (2/4)] INFO  (AbstractConfig.java:347) - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-02-28 02:16:56,353 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Flat Map (3/4) (6261faa62991f4539b9ed8f045e49ef0) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,354 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Sink: Print to Std. Out (3/4) (2b09f78eade1d200c05c29ba9cd68c16) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,355 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - KeyedProcess (3/4) (abd011e107dae07a7d14df1013e9838e) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,357 [KeyedProcess (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-28 02:16:56,367 [KeyedProcess (2/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-28 02:16:56,368 [KeyedProcess (2/4)] INFO  (TypeExtractor.java:1815) - class java.util.Vector does not contain a getter for field elementData
2020-02-28 02:16:56,368 [KeyedProcess (2/4)] INFO  (TypeExtractor.java:1818) - class java.util.Vector does not contain a setter for field elementData
2020-02-28 02:16:56,369 [KeyedProcess (2/4)] INFO  (TypeExtractor.java:1857) - Class class java.util.Vector cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-28 02:16:56,369 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Flat Map (2/4) (d53f62e920a3d200b4a718c620e80874) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,370 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - KeyedProcess (4/4) (cb9cb5b43a8091d8cc65a940d694adda) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,370 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - KeyedProcess (2/4) (84062b9addfdf242b60fbaf43c12bf13) switched from DEPLOYING to RUNNING.
2020-02-28 02:16:56,378 [Sink: Unnamed (4/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:56,378 [Sink: Unnamed (4/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:56,378 [Sink: Unnamed (4/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582849016378
2020-02-28 02:16:56,380 [Sink: Unnamed (4/4)] INFO  (FlinkKafkaProducer.java:1158) - Starting FlinkKafkaInternalProducer (4/4) to produce into default topic output2
2020-02-28 02:16:56,386 [Sink: Unnamed (2/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:56,386 [Sink: Unnamed (2/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:56,386 [Sink: Unnamed (2/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582849016386
2020-02-28 02:16:56,387 [Sink: Unnamed (2/4)] INFO  (FlinkKafkaProducer.java:1158) - Starting FlinkKafkaInternalProducer (2/4) to produce into default topic output2
2020-02-28 02:16:56,397 [Sink: Unnamed (3/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:56,397 [Sink: Unnamed (3/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:56,397 [Sink: Unnamed (3/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582849016397
2020-02-28 02:16:56,398 [Sink: Unnamed (3/4)] INFO  (FlinkKafkaProducer.java:1158) - Starting FlinkKafkaInternalProducer (3/4) to produce into default topic output2
2020-02-28 02:16:56,399 [Sink: Unnamed (1/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:56,399 [Sink: Unnamed (1/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:56,399 [Sink: Unnamed (1/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582849016399
2020-02-28 02:16:56,400 [Sink: Unnamed (1/4)] INFO  (FlinkKafkaProducer.java:1158) - Starting FlinkKafkaInternalProducer (1/4) to produce into default topic output2
2020-02-28 02:16:56,782 [kafka-producer-network-thread | producer-2] INFO  (Metadata.java:261) - [Producer clientId=producer-2] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:56,782 [kafka-producer-network-thread | producer-3] INFO  (Metadata.java:261) - [Producer clientId=producer-3] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:56,784 [Source: Custom Source (2/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-9, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:56,785 [kafka-producer-network-thread | producer-4] INFO  (Metadata.java:261) - [Producer clientId=producer-4] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:56,785 [Source: Custom Source (3/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-5, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:56,785 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-4, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:56,783 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-12, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:56,788 [kafka-producer-network-thread | producer-1] INFO  (Metadata.java:261) - [Producer clientId=producer-1] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:56,789 [Source: Custom Source (2/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-10, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:56,783 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-14, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:56,789 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-6, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:56,783 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-13, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:56,790 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-16, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:56,790 [Source: Custom Source (4/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-11, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:56,793 [Source: Custom Source (3/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-8, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:56,793 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (FlinkKafkaConsumerBase.java:604) - Consumer subtask 2 will start reading the following 2 partitions from the earliest offsets: [KafkaTopicPartition{topic='output', partition=3}, KafkaTopicPartition{topic='output', partition=7}]
2020-02-28 02:16:56,783 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-15, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:56,794 [Source: Custom Source (2/4)] INFO  (FlinkKafkaConsumerBase.java:604) - Consumer subtask 1 will start reading the following 2 partitions from the earliest offsets: [KafkaTopicPartition{topic='_input1', partition=7}, KafkaTopicPartition{topic='_input1', partition=3}]
2020-02-28 02:16:56,793 [Source: Custom Source (1/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-7, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:56,795 [Source: Custom Source (4/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-2, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:56,795 [Source: Custom Source (1/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-3, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:56,796 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (FlinkKafkaConsumerBase.java:604) - Consumer subtask 0 will start reading the following 2 partitions from the earliest offsets: [KafkaTopicPartition{topic='_input1', partition=6}, KafkaTopicPartition{topic='_input1', partition=2}]
2020-02-28 02:16:56,793 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-1, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:56,793 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (FlinkKafkaConsumerBase.java:604) - Consumer subtask 3 will start reading the following 2 partitions from the earliest offsets: [KafkaTopicPartition{topic='_input1', partition=5}, KafkaTopicPartition{topic='_input1', partition=1}]
2020-02-28 02:16:56,796 [Source: Custom Source (2/4)] INFO  (FlinkKafkaConsumerBase.java:604) - Consumer subtask 1 will start reading the following 2 partitions from the earliest offsets: [KafkaTopicPartition{topic='output', partition=2}, KafkaTopicPartition{topic='output', partition=6}]
2020-02-28 02:16:56,797 [Source: Custom Source (4/4)] INFO  (FlinkKafkaConsumerBase.java:604) - Consumer subtask 3 will start reading the following 2 partitions from the earliest offsets: [KafkaTopicPartition{topic='_input1', partition=5}, KafkaTopicPartition{topic='_input1', partition=1}]
2020-02-28 02:16:56,797 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (FlinkKafkaConsumerBase.java:604) - Consumer subtask 1 will start reading the following 2 partitions from the earliest offsets: [KafkaTopicPartition{topic='_input1', partition=7}, KafkaTopicPartition{topic='_input1', partition=3}]
2020-02-28 02:16:56,796 [Source: Custom Source (3/4)] INFO  (FlinkKafkaConsumerBase.java:604) - Consumer subtask 2 will start reading the following 2 partitions from the earliest offsets: [KafkaTopicPartition{topic='_input1', partition=4}, KafkaTopicPartition{topic='_input1', partition=0}]
2020-02-28 02:16:56,796 [Source: Custom Source (4/4)] INFO  (FlinkKafkaConsumerBase.java:604) - Consumer subtask 3 will start reading the following 2 partitions from the earliest offsets: [KafkaTopicPartition{topic='output', partition=4}, KafkaTopicPartition{topic='output', partition=0}]
2020-02-28 02:16:56,796 [Source: Custom Source (1/4)] INFO  (FlinkKafkaConsumerBase.java:604) - Consumer subtask 0 will start reading the following 2 partitions from the earliest offsets: [KafkaTopicPartition{topic='_input1', partition=6}, KafkaTopicPartition{topic='_input1', partition=2}]
2020-02-28 02:16:56,796 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (FlinkKafkaConsumerBase.java:604) - Consumer subtask 1 will start reading the following 2 partitions from the earliest offsets: [KafkaTopicPartition{topic='output', partition=2}, KafkaTopicPartition{topic='output', partition=6}]
2020-02-28 02:16:56,796 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (FlinkKafkaConsumerBase.java:604) - Consumer subtask 3 will start reading the following 2 partitions from the earliest offsets: [KafkaTopicPartition{topic='output', partition=4}, KafkaTopicPartition{topic='output', partition=0}]
2020-02-28 02:16:56,795 [Source: Custom Source (3/4)] INFO  (FlinkKafkaConsumerBase.java:604) - Consumer subtask 2 will start reading the following 2 partitions from the earliest offsets: [KafkaTopicPartition{topic='output', partition=3}, KafkaTopicPartition{topic='output', partition=7}]
2020-02-28 02:16:56,795 [Source: Custom Source (1/4)] INFO  (FlinkKafkaConsumerBase.java:604) - Consumer subtask 0 will start reading the following 2 partitions from the earliest offsets: [KafkaTopicPartition{topic='output', partition=1}, KafkaTopicPartition{topic='output', partition=5}]
2020-02-28 02:16:56,795 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (FlinkKafkaConsumerBase.java:604) - Consumer subtask 2 will start reading the following 2 partitions from the earliest offsets: [KafkaTopicPartition{topic='_input1', partition=4}, KafkaTopicPartition{topic='_input1', partition=0}]
2020-02-28 02:16:56,797 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (FlinkKafkaConsumerBase.java:604) - Consumer subtask 0 will start reading the following 2 partitions from the earliest offsets: [KafkaTopicPartition{topic='output', partition=1}, KafkaTopicPartition{topic='output', partition=5}]
2020-02-28 02:16:56,833 [Legacy Source Thread - Source: Custom Source (2/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='output', partition=2}=-915623761775, KafkaTopicPartition{topic='output', partition=6}=-915623761775}.
2020-02-28 02:16:56,836 [Legacy Source Thread - Source: Custom Source (1/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 0 creating fetcher with offsets {KafkaTopicPartition{topic='_input1', partition=6}=-915623761775, KafkaTopicPartition{topic='_input1', partition=2}=-915623761775}.
2020-02-28 02:16:56,839 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='output', partition=2}=-915623761775, KafkaTopicPartition{topic='output', partition=6}=-915623761775}.
2020-02-28 02:16:56,840 [Legacy Source Thread - Source: Custom Source (3/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 2 creating fetcher with offsets {KafkaTopicPartition{topic='output', partition=3}=-915623761775, KafkaTopicPartition{topic='output', partition=7}=-915623761775}.
2020-02-28 02:16:56,841 [Legacy Source Thread - Source: Custom Source (1/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 0 creating fetcher with offsets {KafkaTopicPartition{topic='output', partition=1}=-915623761775, KafkaTopicPartition{topic='output', partition=5}=-915623761775}.
2020-02-28 02:16:56,844 [Legacy Source Thread - Source: Custom Source (4/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 3 creating fetcher with offsets {KafkaTopicPartition{topic='_input1', partition=5}=-915623761775, KafkaTopicPartition{topic='_input1', partition=1}=-915623761775}.
2020-02-28 02:16:56,847 [Legacy Source Thread - Source: Custom Source (4/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 3 creating fetcher with offsets {KafkaTopicPartition{topic='output', partition=4}=-915623761775, KafkaTopicPartition{topic='output', partition=0}=-915623761775}.
2020-02-28 02:16:56,847 [Legacy Source Thread - Source: Custom Source (3/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 2 creating fetcher with offsets {KafkaTopicPartition{topic='_input1', partition=4}=-915623761775, KafkaTopicPartition{topic='_input1', partition=0}=-915623761775}.
2020-02-28 02:16:56,848 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 3 creating fetcher with offsets {KafkaTopicPartition{topic='output', partition=4}=-915623761775, KafkaTopicPartition{topic='output', partition=0}=-915623761775}.
2020-02-28 02:16:56,852 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 0 creating fetcher with offsets {KafkaTopicPartition{topic='output', partition=1}=-915623761775, KafkaTopicPartition{topic='output', partition=5}=-915623761775}.
2020-02-28 02:16:56,853 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:56,857 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:56,857 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:56,858 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582849016857
2020-02-28 02:16:56,859 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 2 creating fetcher with offsets {KafkaTopicPartition{topic='output', partition=3}=-915623761775, KafkaTopicPartition{topic='output', partition=7}=-915623761775}.
2020-02-28 02:16:56,869 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 3 creating fetcher with offsets {KafkaTopicPartition{topic='_input1', partition=5}=-915623761775, KafkaTopicPartition{topic='_input1', partition=1}=-915623761775}.
2020-02-28 02:16:56,869 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 2 creating fetcher with offsets {KafkaTopicPartition{topic='_input1', partition=4}=-915623761775, KafkaTopicPartition{topic='_input1', partition=0}=-915623761775}.
2020-02-28 02:16:56,869 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='_input1', partition=7}=-915623761775, KafkaTopicPartition{topic='_input1', partition=3}=-915623761775}.
2020-02-28 02:16:56,860 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:56,871 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 0 creating fetcher with offsets {KafkaTopicPartition{topic='_input1', partition=6}=-915623761775, KafkaTopicPartition{topic='_input1', partition=2}=-915623761775}.
2020-02-28 02:16:56,868 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (KafkaConsumer.java:1123) - [Consumer clientId=consumer-KafkaCsvProducer-17, groupId=KafkaCsvProducer] Subscribed to partition(s): output-1, output-5
2020-02-28 02:16:56,865 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:56,865 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:56,886 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-17, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition output-1
2020-02-28 02:16:56,864 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:56,863 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:56,862 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:56,862 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:56,861 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:56,860 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:56,907 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:56,901 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:56,889 [Legacy Source Thread - Source: Custom Source (2/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 1 creating fetcher with offsets {KafkaTopicPartition{topic='_input1', partition=7}=-915623761775, KafkaTopicPartition{topic='_input1', partition=3}=-915623761775}.
2020-02-28 02:16:56,887 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:56,874 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:56,873 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:56,939 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-17, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:56,929 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:56,947 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582849016874
2020-02-28 02:16:56,947 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:56,948 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:56,949 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582849016932
2020-02-28 02:16:56,920 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:56,950 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:56,950 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (KafkaConsumer.java:1123) - [Consumer clientId=consumer-KafkaCsvProducer-29, groupId=KafkaCsvProducer] Subscribed to partition(s): _input1-7, _input1-3
2020-02-28 02:16:56,950 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-28 02:16:56,950 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AbstractCoordinator.java:756) - [Consumer clientId=consumer-KafkaCsvProducer-17, groupId=KafkaCsvProducer] Discovered group coordinator skl:9092 (id: 2147483647 rack: null)
2020-02-28 02:16:56,948 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (KafkaConsumer.java:1123) - [Consumer clientId=consumer-KafkaCsvProducer-18, groupId=KafkaCsvProducer] Subscribed to partition(s): _input1-5, _input1-1
2020-02-28 02:16:56,961 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-18, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition _input1-5
2020-02-28 02:16:56,955 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-29, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition _input1-7
2020-02-28 02:16:56,951 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:56,963 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582849016931
2020-02-28 02:16:56,963 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:56,964 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:56,964 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582849016918
2020-02-28 02:16:56,964 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:56,964 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:56,964 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582849016916
2020-02-28 02:16:56,970 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (KafkaConsumer.java:1123) - [Consumer clientId=consumer-KafkaCsvProducer-28, groupId=KafkaCsvProducer] Subscribed to partition(s): _input1-4, _input1-0
2020-02-28 02:16:56,970 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-28, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition _input1-4
2020-02-28 02:16:56,970 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:56,971 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:56,972 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582849016906
2020-02-28 02:16:56,973 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:56,973 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:56,973 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582849016903
2020-02-28 02:16:56,970 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (KafkaConsumer.java:1123) - [Consumer clientId=consumer-KafkaCsvProducer-26, groupId=KafkaCsvProducer] Subscribed to partition(s): output-2, output-6
2020-02-28 02:16:56,975 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-26, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition output-2
2020-02-28 02:16:56,977 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:56,977 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:56,977 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582849016899
2020-02-28 02:16:56,978 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-18, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:56,978 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:56,979 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:56,979 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582849016895
2020-02-28 02:16:56,979 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:56,979 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:56,980 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582849016895
2020-02-28 02:16:56,980 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:56,980 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:56,980 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582849016888
2020-02-28 02:16:56,980 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:56,980 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:56,980 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582849016885
2020-02-28 02:16:56,981 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-28, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:56,982 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:56,982 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:56,982 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582849016954
2020-02-28 02:16:56,982 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:56,982 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:56,982 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582849016952
2020-02-28 02:16:56,984 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (KafkaConsumer.java:1123) - [Consumer clientId=consumer-KafkaCsvProducer-27, groupId=KafkaCsvProducer] Subscribed to partition(s): _input1-6, _input1-2
2020-02-28 02:16:56,986 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-27, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition _input1-6
2020-02-28 02:16:56,987 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (KafkaConsumer.java:1123) - [Consumer clientId=consumer-KafkaCsvProducer-25, groupId=KafkaCsvProducer] Subscribed to partition(s): _input1-6, _input1-2
2020-02-28 02:16:56,987 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-25, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition _input1-6
2020-02-28 02:16:56,988 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-26, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:56,989 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (KafkaConsumer.java:1123) - [Consumer clientId=consumer-KafkaCsvProducer-21, groupId=KafkaCsvProducer] Subscribed to partition(s): output-1, output-5
2020-02-28 02:16:56,989 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-21, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition output-1
2020-02-28 02:16:56,990 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (KafkaConsumer.java:1123) - [Consumer clientId=consumer-KafkaCsvProducer-22, groupId=KafkaCsvProducer] Subscribed to partition(s): output-4, output-0
2020-02-28 02:16:56,991 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-22, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition output-4
2020-02-28 02:16:56,991 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (KafkaConsumer.java:1123) - [Consumer clientId=consumer-KafkaCsvProducer-19, groupId=KafkaCsvProducer] Subscribed to partition(s): output-2, output-6
2020-02-28 02:16:56,992 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-19, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition output-2
2020-02-28 02:16:56,980 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (AbstractCoordinator.java:756) - [Consumer clientId=consumer-KafkaCsvProducer-18, groupId=KafkaCsvProducer] Discovered group coordinator skl:9092 (id: 2147483647 rack: null)
2020-02-28 02:16:56,995 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-29, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:56,995 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AbstractCoordinator.java:756) - [Consumer clientId=consumer-KafkaCsvProducer-29, groupId=KafkaCsvProducer] Discovered group coordinator skl:9092 (id: 2147483647 rack: null)
2020-02-28 02:16:56,984 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (KafkaConsumer.java:1123) - [Consumer clientId=consumer-KafkaCsvProducer-24, groupId=KafkaCsvProducer] Subscribed to partition(s): output-4, output-0
2020-02-28 02:16:56,996 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-24, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition output-4
2020-02-28 02:16:56,996 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (AbstractCoordinator.java:756) - [Consumer clientId=consumer-KafkaCsvProducer-26, groupId=KafkaCsvProducer] Discovered group coordinator skl:9092 (id: 2147483647 rack: null)
2020-02-28 02:16:57,009 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-22, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:57,010 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AbstractCoordinator.java:756) - [Consumer clientId=consumer-KafkaCsvProducer-22, groupId=KafkaCsvProducer] Discovered group coordinator skl:9092 (id: 2147483647 rack: null)
2020-02-28 02:16:57,013 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (ConsumerCoordinator.java:762) - [Consumer clientId=consumer-KafkaCsvProducer-18, groupId=KafkaCsvProducer] Setting offset for partition _input1-1 to the committed offset FetchPosition{offset=33, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=skl:9092 (id: 0 rack: null), epoch=0}}
2020-02-28 02:16:57,022 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-27, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:57,022 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AbstractCoordinator.java:756) - [Consumer clientId=consumer-KafkaCsvProducer-27, groupId=KafkaCsvProducer] Discovered group coordinator skl:9092 (id: 2147483647 rack: null)
2020-02-28 02:16:57,024 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-25, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:57,025 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (AbstractCoordinator.java:756) - [Consumer clientId=consumer-KafkaCsvProducer-25, groupId=KafkaCsvProducer] Discovered group coordinator skl:9092 (id: 2147483647 rack: null)
2020-02-28 02:16:57,027 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-21, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:57,027 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (AbstractCoordinator.java:756) - [Consumer clientId=consumer-KafkaCsvProducer-21, groupId=KafkaCsvProducer] Discovered group coordinator skl:9092 (id: 2147483647 rack: null)
2020-02-28 02:16:56,983 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AbstractCoordinator.java:756) - [Consumer clientId=consumer-KafkaCsvProducer-28, groupId=KafkaCsvProducer] Discovered group coordinator skl:9092 (id: 2147483647 rack: null)
2020-02-28 02:16:56,992 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (KafkaConsumer.java:1123) - [Consumer clientId=consumer-KafkaCsvProducer-20, groupId=KafkaCsvProducer] Subscribed to partition(s): output-3, output-7
2020-02-28 02:16:57,031 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-20, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition output-3
2020-02-28 02:16:56,988 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (KafkaConsumer.java:1123) - [Consumer clientId=consumer-KafkaCsvProducer-23, groupId=KafkaCsvProducer] Subscribed to partition(s): _input1-4, _input1-0
2020-02-28 02:16:57,032 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-23, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition _input1-4
2020-02-28 02:16:57,017 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-28 02:16:57,010 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-19, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:57,010 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-24, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:56,996 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (KafkaConsumer.java:1123) - [Consumer clientId=consumer-KafkaCsvProducer-31, groupId=KafkaCsvProducer] Subscribed to partition(s): _input1-5, _input1-1
2020-02-28 02:16:57,046 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-31, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition _input1-5
2020-02-28 02:16:57,046 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (AbstractCoordinator.java:756) - [Consumer clientId=consumer-KafkaCsvProducer-24, groupId=KafkaCsvProducer] Discovered group coordinator skl:9092 (id: 2147483647 rack: null)
2020-02-28 02:16:57,045 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AbstractCoordinator.java:756) - [Consumer clientId=consumer-KafkaCsvProducer-19, groupId=KafkaCsvProducer] Discovered group coordinator skl:9092 (id: 2147483647 rack: null)
2020-02-28 02:16:57,048 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (ConsumerCoordinator.java:762) - [Consumer clientId=consumer-KafkaCsvProducer-28, groupId=KafkaCsvProducer] Setting offset for partition _input1-0 to the committed offset FetchPosition{offset=25, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=skl:9092 (id: 0 rack: null), epoch=0}}
2020-02-28 02:16:57,044 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (ConsumerCoordinator.java:762) - [Consumer clientId=consumer-KafkaCsvProducer-25, groupId=KafkaCsvProducer] Setting offset for partition _input1-2 to the committed offset FetchPosition{offset=17, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=skl:9092 (id: 0 rack: null), epoch=0}}
2020-02-28 02:16:57,044 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-23, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:57,051 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (AbstractCoordinator.java:756) - [Consumer clientId=consumer-KafkaCsvProducer-23, groupId=KafkaCsvProducer] Discovered group coordinator skl:9092 (id: 2147483647 rack: null)
2020-02-28 02:16:57,051 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-20, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:57,052 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (AbstractCoordinator.java:756) - [Consumer clientId=consumer-KafkaCsvProducer-20, groupId=KafkaCsvProducer] Discovered group coordinator skl:9092 (id: 2147483647 rack: null)
2020-02-28 02:16:57,053 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-31, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:57,053 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (ConsumerCoordinator.java:762) - [Consumer clientId=consumer-KafkaCsvProducer-19, groupId=KafkaCsvProducer] Setting offset for partition output-6 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=skl:9092 (id: 0 rack: null), epoch=0}}
2020-02-28 02:16:57,053 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AbstractCoordinator.java:756) - [Consumer clientId=consumer-KafkaCsvProducer-31, groupId=KafkaCsvProducer] Discovered group coordinator skl:9092 (id: 2147483647 rack: null)
2020-02-28 02:16:57,057 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (ConsumerCoordinator.java:762) - [Consumer clientId=consumer-KafkaCsvProducer-31, groupId=KafkaCsvProducer] Setting offset for partition _input1-1 to the committed offset FetchPosition{offset=33, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=skl:9092 (id: 0 rack: null), epoch=0}}
2020-02-28 02:16:57,044 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-28 02:16:57,058 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582849017017
2020-02-28 02:16:57,061 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (ConsumerCoordinator.java:762) - [Consumer clientId=consumer-KafkaCsvProducer-20, groupId=KafkaCsvProducer] Setting offset for partition output-7 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=skl:9092 (id: 0 rack: null), epoch=0}}
2020-02-28 02:16:57,044 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (ConsumerCoordinator.java:762) - [Consumer clientId=consumer-KafkaCsvProducer-27, groupId=KafkaCsvProducer] Setting offset for partition _input1-2 to the committed offset FetchPosition{offset=17, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=skl:9092 (id: 0 rack: null), epoch=0}}
2020-02-28 02:16:57,042 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (KafkaConsumer.java:1123) - [Consumer clientId=consumer-KafkaCsvProducer-30, groupId=KafkaCsvProducer] Subscribed to partition(s): output-3, output-7
2020-02-28 02:16:57,061 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-30, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition output-3
2020-02-28 02:16:57,031 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (ConsumerCoordinator.java:762) - [Consumer clientId=consumer-KafkaCsvProducer-29, groupId=KafkaCsvProducer] Setting offset for partition _input1-3 to the committed offset FetchPosition{offset=12, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=skl:9092 (id: 0 rack: null), epoch=0}}
2020-02-28 02:16:57,031 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (ConsumerCoordinator.java:762) - [Consumer clientId=consumer-KafkaCsvProducer-21, groupId=KafkaCsvProducer] Setting offset for partition output-5 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=skl:9092 (id: 0 rack: null), epoch=0}}
2020-02-28 02:16:57,026 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (ConsumerCoordinator.java:762) - [Consumer clientId=consumer-KafkaCsvProducer-26, groupId=KafkaCsvProducer] Setting offset for partition output-6 to the committed offset FetchPosition{offset=4, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=skl:9092 (id: 0 rack: null), epoch=0}}
2020-02-28 02:16:57,070 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-30, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:57,022 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (ConsumerCoordinator.java:762) - [Consumer clientId=consumer-KafkaCsvProducer-17, groupId=KafkaCsvProducer] Setting offset for partition output-5 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=skl:9092 (id: 0 rack: null), epoch=0}}
2020-02-28 02:16:57,016 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (ConsumerCoordinator.java:762) - [Consumer clientId=consumer-KafkaCsvProducer-22, groupId=KafkaCsvProducer] Setting offset for partition output-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=skl:9092 (id: 0 rack: null), epoch=0}}
2020-02-28 02:16:57,071 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AbstractCoordinator.java:756) - [Consumer clientId=consumer-KafkaCsvProducer-30, groupId=KafkaCsvProducer] Discovered group coordinator skl:9092 (id: 2147483647 rack: null)
2020-02-28 02:16:57,079 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-20, groupId=KafkaCsvProducer] Resetting offset for partition output-3 to offset 0.
2020-02-28 02:16:57,079 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-20, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition output-7
2020-02-28 02:16:57,080 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-22, groupId=KafkaCsvProducer] Resetting offset for partition output-4 to offset 0.
2020-02-28 02:16:57,080 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-22, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition output-0
2020-02-28 02:16:57,080 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-17, groupId=KafkaCsvProducer] Resetting offset for partition output-1 to offset 0.
2020-02-28 02:16:57,081 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-17, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition output-5
2020-02-28 02:16:57,082 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-22, groupId=KafkaCsvProducer] Resetting offset for partition output-0 to offset 0.
2020-02-28 02:16:57,049 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (ConsumerCoordinator.java:762) - [Consumer clientId=consumer-KafkaCsvProducer-24, groupId=KafkaCsvProducer] Setting offset for partition output-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=skl:9092 (id: 0 rack: null), epoch=0}}
2020-02-28 02:16:57,061 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (ConsumerCoordinator.java:762) - [Consumer clientId=consumer-KafkaCsvProducer-23, groupId=KafkaCsvProducer] Setting offset for partition _input1-0 to the committed offset FetchPosition{offset=25, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=skl:9092 (id: 0 rack: null), epoch=0}}
2020-02-28 02:16:57,087 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-20, groupId=KafkaCsvProducer] Resetting offset for partition output-7 to offset 0.
2020-02-28 02:16:57,089 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-19, groupId=KafkaCsvProducer] Resetting offset for partition output-2 to offset 0.
2020-02-28 02:16:57,089 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-19, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition output-6
2020-02-28 02:16:57,090 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-21, groupId=KafkaCsvProducer] Resetting offset for partition output-1 to offset 0.
2020-02-28 02:16:57,090 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-21, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition output-5
2020-02-28 02:16:57,091 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-26, groupId=KafkaCsvProducer] Resetting offset for partition output-2 to offset 0.
2020-02-28 02:16:57,091 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-26, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition output-6
2020-02-28 02:16:57,092 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-21, groupId=KafkaCsvProducer] Resetting offset for partition output-5 to offset 0.
2020-02-28 02:16:57,091 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-29, groupId=KafkaCsvProducer] Resetting offset for partition _input1-7 to offset 0.
2020-02-28 02:16:57,093 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-29, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition _input1-3
2020-02-28 02:16:57,099 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-29, groupId=KafkaCsvProducer] Resetting offset for partition _input1-3 to offset 0.
2020-02-28 02:16:57,101 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-17, groupId=KafkaCsvProducer] Resetting offset for partition output-5 to offset 0.
2020-02-28 02:16:57,101 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-28, groupId=KafkaCsvProducer] Resetting offset for partition _input1-4 to offset 0.
2020-02-28 02:16:57,093 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (ConsumerCoordinator.java:762) - [Consumer clientId=consumer-KafkaCsvProducer-30, groupId=KafkaCsvProducer] Setting offset for partition output-7 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=skl:9092 (id: 0 rack: null), epoch=0}}
2020-02-28 02:16:57,105 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (KafkaConsumer.java:1123) - [Consumer clientId=consumer-KafkaCsvProducer-32, groupId=KafkaCsvProducer] Subscribed to partition(s): _input1-7, _input1-3
2020-02-28 02:16:57,107 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-32, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition _input1-7
2020-02-28 02:16:57,108 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-24, groupId=KafkaCsvProducer] Resetting offset for partition output-4 to offset 0.
2020-02-28 02:16:57,109 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-23, groupId=KafkaCsvProducer] Resetting offset for partition _input1-4 to offset 0.
2020-02-28 02:16:57,110 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-23, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition _input1-0
2020-02-28 02:16:57,112 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-30, groupId=KafkaCsvProducer] Resetting offset for partition output-3 to offset 0.
2020-02-28 02:16:57,112 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-30, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition output-7
2020-02-28 02:16:57,113 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-32, groupId=KafkaCsvProducer] Cluster ID: AZDT7CeLRi2BFIxGgN344Q
2020-02-28 02:16:57,113 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (AbstractCoordinator.java:756) - [Consumer clientId=consumer-KafkaCsvProducer-32, groupId=KafkaCsvProducer] Discovered group coordinator skl:9092 (id: 2147483647 rack: null)
2020-02-28 02:16:57,113 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-28, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition _input1-0
2020-02-28 02:16:57,101 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-31, groupId=KafkaCsvProducer] Resetting offset for partition _input1-5 to offset 0.
2020-02-28 02:16:57,117 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-31, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition _input1-1
2020-02-28 02:16:57,101 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-19, groupId=KafkaCsvProducer] Resetting offset for partition output-6 to offset 0.
2020-02-28 02:16:57,101 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-26, groupId=KafkaCsvProducer] Resetting offset for partition output-6 to offset 0.
2020-02-28 02:16:57,116 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-23, groupId=KafkaCsvProducer] Resetting offset for partition _input1-0 to offset 0.
2020-02-28 02:16:57,115 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-27, groupId=KafkaCsvProducer] Resetting offset for partition _input1-6 to offset 0.
2020-02-28 02:16:57,122 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-27, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition _input1-2
2020-02-28 02:16:57,115 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-25, groupId=KafkaCsvProducer] Resetting offset for partition _input1-6 to offset 0.
2020-02-28 02:16:57,123 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-25, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition _input1-2
2020-02-28 02:16:57,124 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-30, groupId=KafkaCsvProducer] Resetting offset for partition output-7 to offset 0.
2020-02-28 02:16:57,127 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-27, groupId=KafkaCsvProducer] Resetting offset for partition _input1-2 to offset 0.
2020-02-28 02:16:57,127 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-31, groupId=KafkaCsvProducer] Resetting offset for partition _input1-1 to offset 0.
2020-02-28 02:16:57,128 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-25, groupId=KafkaCsvProducer] Resetting offset for partition _input1-2 to offset 0.
2020-02-28 02:16:57,128 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (ConsumerCoordinator.java:762) - [Consumer clientId=consumer-KafkaCsvProducer-32, groupId=KafkaCsvProducer] Setting offset for partition _input1-3 to the committed offset FetchPosition{offset=12, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=skl:9092 (id: 0 rack: null), epoch=0}}
2020-02-28 02:16:57,109 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-24, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition output-0
2020-02-28 02:16:57,127 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-28, groupId=KafkaCsvProducer] Resetting offset for partition _input1-0 to offset 0.
2020-02-28 02:16:57,133 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-18, groupId=KafkaCsvProducer] Resetting offset for partition _input1-5 to offset 0.
2020-02-28 02:16:57,133 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-18, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition _input1-1
2020-02-28 02:16:57,137 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-24, groupId=KafkaCsvProducer] Resetting offset for partition output-0 to offset 0.
2020-02-28 02:16:57,139 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-32, groupId=KafkaCsvProducer] Resetting offset for partition _input1-7 to offset 0.
2020-02-28 02:16:57,139 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-32, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition _input1-3
2020-02-28 02:16:57,142 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-32, groupId=KafkaCsvProducer] Resetting offset for partition _input1-3 to offset 0.
2020-02-28 02:16:57,146 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-18, groupId=KafkaCsvProducer] Resetting offset for partition _input1-1 to offset 0.
