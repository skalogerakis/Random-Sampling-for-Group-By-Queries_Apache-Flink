2020-02-25 03:40:51,330 [main] WARN  (FlinkKafkaProducer.java:667) - Property [transaction.timeout.ms] not specified. Setting it to 3600000 ms
2020-02-25 03:40:51,454 [main] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.api.datastream.CoGroupedStreams$TaggedUnion does not contain a setter for field one
2020-02-25 03:40:51,454 [main] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.api.datastream.CoGroupedStreams$TaggedUnion cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-25 03:40:51,457 [main] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.api.datastream.CoGroupedStreams$TaggedUnion does not contain a setter for field one
2020-02-25 03:40:51,457 [main] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.api.datastream.CoGroupedStreams$TaggedUnion cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-25 03:40:51,956 [main] INFO  (LocalStreamEnvironment.java:108) - Running job on local embedded Flink mini cluster
2020-02-25 03:40:52,430 [main] INFO  (MiniCluster.java:253) - Starting Flink Mini Cluster
2020-02-25 03:40:52,438 [main] INFO  (MiniCluster.java:262) - Starting Metrics Registry
2020-02-25 03:40:52,621 [main] INFO  (MetricRegistryImpl.java:114) - No metrics reporter configured, no metrics will be exposed/reported.
2020-02-25 03:40:52,622 [main] INFO  (MiniCluster.java:266) - Starting RPC Service(s)
2020-02-25 03:40:53,468 [flink-akka.actor.default-dispatcher-3] INFO  (Slf4jLogger.scala:92) - Slf4jLogger started
2020-02-25 03:40:53,643 [main] INFO  (BootstrapTools.java:244) - Trying to start actor system at :0
2020-02-25 03:40:53,706 [flink-metrics-2] INFO  (Slf4jLogger.scala:92) - Slf4jLogger started
2020-02-25 03:40:53,730 [flink-metrics-2] INFO  (MarkerIgnoringBase.java:107) - Starting remoting
2020-02-25 03:40:53,867 [flink-metrics-2] INFO  (MarkerIgnoringBase.java:107) - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:34317]
2020-02-25 03:40:53,904 [main] INFO  (BootstrapTools.java:256) - Actor system started at akka.tcp://flink-metrics@127.0.1.1:34317
2020-02-25 03:40:53,911 [main] INFO  (AkkaRpcService.java:223) - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-02-25 03:40:53,923 [main] INFO  (MiniCluster.java:397) - Starting high-availability services
2020-02-25 03:40:53,935 [main] INFO  (BlobServer.java:141) - Created BLOB server storage directory /tmp/blobStore-d49f6c0f-cb0b-41b8-88fc-5563051289e7
2020-02-25 03:40:53,939 [main] INFO  (BlobServer.java:203) - Started BLOB server at 0.0.0.0:42975 - max concurrent requests: 50 - max backlog: 1000
2020-02-25 03:40:53,942 [main] INFO  (AbstractBlobCache.java:107) - Created BLOB cache storage directory /tmp/blobStore-edb26760-ae34-4b9b-974c-755e18f9c774
2020-02-25 03:40:53,943 [main] INFO  (AbstractBlobCache.java:107) - Created BLOB cache storage directory /tmp/blobStore-50300814-a864-40e8-a87e-c5fb8166a97e
2020-02-25 03:40:53,944 [main] INFO  (MiniCluster.java:479) - Starting 1 TaskManger(s)
2020-02-25 03:40:53,946 [main] INFO  (TaskManagerRunner.java:351) - Starting TaskManager with ResourceID: ebf5f964-f09f-42b8-9abd-e64eea74a85a
2020-02-25 03:40:54,069 [main] INFO  (TaskManagerServices.java:519) - Temporary file directory '/tmp': total 439 GB, usable 336 GB (76.54% usable)
2020-02-25 03:40:54,073 [main] INFO  (FileChannelManagerImpl.java:76) - FileChannelManager uses directory /tmp/flink-io-5ea762b4-15e4-4cb3-84d6-7af8a42ef2d8 for spill files.
2020-02-25 03:40:54,083 [main] INFO  (FileChannelManagerImpl.java:76) - FileChannelManager uses directory /tmp/flink-netty-shuffle-02867d11-68be-4a0d-868d-b3423f2a8756 for spill files.
2020-02-25 03:40:54,209 [main] INFO  (NetworkBufferPool.java:140) - Allocated 191 MB for network buffer pool (number of memory segments: 6113, bytes per segment: 32768).
2020-02-25 03:40:54,218 [main] INFO  (NettyShuffleEnvironment.java:283) - Starting the network environment and its components.
2020-02-25 03:40:54,219 [main] INFO  (KvStateService.java:89) - Starting the kvState service and its components.
2020-02-25 03:40:54,220 [main] INFO  (TaskManagerServices.java:364) - Limiting managed memory to 0.7 of the currently free heap space (1197 MB), memory will be allocated lazily.
2020-02-25 03:40:54,233 [main] INFO  (TaskManagerConfiguration.java:197) - Messages have a max timeout of 10000 ms
2020-02-25 03:40:54,244 [main] INFO  (AkkaRpcService.java:223) - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-02-25 03:40:54,256 [flink-akka.actor.default-dispatcher-4] INFO  (JobLeaderService.java:125) - Start job leader service.
2020-02-25 03:40:54,258 [flink-akka.actor.default-dispatcher-4] INFO  (FileCache.java:107) - User file cache uses directory /tmp/flink-dist-cache-6d686513-c966-4ca0-a8fe-57bc194d2121
2020-02-25 03:40:54,304 [main] INFO  (RestServerEndpoint.java:136) - Starting rest endpoint.
2020-02-25 03:40:54,366 [main] WARN  (WebMonitorUtils.java:87) - Log file environment variable 'log.file' is not set.
2020-02-25 03:40:54,367 [main] WARN  (WebMonitorUtils.java:93) - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-02-25 03:40:54,378 [main] INFO  (DispatcherRestEndpoint.java:113) - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-02-25 03:40:54,510 [main] INFO  (RestServerEndpoint.java:233) - Rest endpoint listening at localhost:44443
2020-02-25 03:40:54,511 [main] INFO  (EmbeddedLeaderService.java:300) - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@6df3e44c @ http://localhost:44443
2020-02-25 03:40:54,513 [mini-cluster-io-thread-1] INFO  (WebMonitorEndpoint.java:712) - http://localhost:44443 was granted leadership with leaderSessionID=b46d83bf-339b-4a7c-b9e7-95550a6d7742
2020-02-25 03:40:54,514 [mini-cluster-io-thread-1] INFO  (EmbeddedLeaderService.java:250) - Received confirmation of leadership for leader http://localhost:44443 , session=b46d83bf-339b-4a7c-b9e7-95550a6d7742
2020-02-25 03:40:54,531 [main] INFO  (AkkaRpcService.java:223) - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-02-25 03:40:54,544 [main] INFO  (AkkaRpcService.java:223) - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-02-25 03:40:54,558 [flink-akka.actor.default-dispatcher-4] INFO  (EmbeddedLeaderService.java:300) - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@5f6161a0 @ akka://flink/user/resourcemanager
2020-02-25 03:40:54,561 [flink-akka.actor.default-dispatcher-4] INFO  (ResourceManager.java:925) - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token ae12910febf174c347737a0e97604e73
2020-02-25 03:40:54,564 [flink-akka.actor.default-dispatcher-4] INFO  (SlotManagerImpl.java:219) - Starting the SlotManager.
2020-02-25 03:40:54,565 [flink-akka.actor.default-dispatcher-3] INFO  (EmbeddedLeaderService.java:300) - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@741a0997 @ akka://flink/user/dispatcher
2020-02-25 03:40:54,569 [flink-akka.actor.default-dispatcher-3] INFO  (EmbeddedLeaderService.java:250) - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=47737a0e-9760-4e73-ae12-910febf174c3
2020-02-25 03:40:54,580 [flink-akka.actor.default-dispatcher-2] INFO  (TaskExecutor.java:991) - Connecting to ResourceManager akka://flink/user/resourcemanager(ae12910febf174c347737a0e97604e73).
2020-02-25 03:40:54,581 [main] INFO  (MiniCluster.java:362) - Flink Mini Cluster started successfully
2020-02-25 03:40:54,587 [flink-akka.actor.default-dispatcher-4] INFO  (Dispatcher.java:884) - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token a2e320ad-da3e-4991-9327-cf37f3cf9518
2020-02-25 03:40:54,589 [flink-akka.actor.default-dispatcher-3] INFO  (Dispatcher.java:716) - Recovering all persisted jobs.
2020-02-25 03:40:54,593 [flink-akka.actor.default-dispatcher-5] INFO  (EmbeddedLeaderService.java:250) - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=a2e320ad-da3e-4991-9327-cf37f3cf9518
2020-02-25 03:40:54,596 [flink-akka.actor.default-dispatcher-2] INFO  (RetryingRegistration.java:155) - Resolved ResourceManager address, beginning registration
2020-02-25 03:40:54,596 [flink-akka.actor.default-dispatcher-2] INFO  (RetryingRegistration.java:204) - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-02-25 03:40:54,605 [flink-akka.actor.default-dispatcher-5] INFO  (ResourceManager.java:717) - Registering TaskManager with ResourceID ebf5f964-f09f-42b8-9abd-e64eea74a85a (akka://flink/user/taskmanager_0) at ResourceManager
2020-02-25 03:40:54,608 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutorToResourceManagerConnection.java:100) - Successful registration at resource manager akka://flink/user/resourcemanager under registration id d72b14719b8afb53c8911bb55526f689.
2020-02-25 03:40:54,611 [flink-akka.actor.default-dispatcher-2] INFO  (Dispatcher.java:264) - Received JobGraph submission eeb8abccd9f841491b409a2876b760d9 (SecondAlgorithmPass).
2020-02-25 03:40:54,612 [flink-akka.actor.default-dispatcher-2] INFO  (Dispatcher.java:321) - Submitting job eeb8abccd9f841491b409a2876b760d9 (SecondAlgorithmPass).
2020-02-25 03:40:54,630 [flink-akka.actor.default-dispatcher-4] INFO  (AkkaRpcService.java:223) - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-02-25 03:40:54,639 [flink-akka.actor.default-dispatcher-4] INFO  (JobMaster.java:242) - Initializing job SecondAlgorithmPass (eeb8abccd9f841491b409a2876b760d9).
2020-02-25 03:40:54,657 [flink-akka.actor.default-dispatcher-4] INFO  (LegacyScheduler.java:171) - Using restart strategy NoRestartStrategy for SecondAlgorithmPass (eeb8abccd9f841491b409a2876b760d9).
2020-02-25 03:40:54,674 [flink-akka.actor.default-dispatcher-4] INFO  (ExecutionGraph.java:519) - Job recovers via failover strategy: full graph restart
2020-02-25 03:40:54,685 [flink-akka.actor.default-dispatcher-4] INFO  (ExecutionGraphBuilder.java:204) - Running initialization on master for job SecondAlgorithmPass (eeb8abccd9f841491b409a2876b760d9).
2020-02-25 03:40:54,686 [flink-akka.actor.default-dispatcher-4] INFO  (ExecutionGraphBuilder.java:222) - Successfully ran initialization on master in 0 ms.
2020-02-25 03:40:54,727 [flink-akka.actor.default-dispatcher-4] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-25 03:40:54,738 [flink-akka.actor.default-dispatcher-4] INFO  (EmbeddedLeaderService.java:300) - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@67a30b8e @ akka://flink/user/jobmanager_1
2020-02-25 03:40:54,739 [mini-cluster-io-thread-4] INFO  (JobManagerRunner.java:313) - JobManager runner for job SecondAlgorithmPass (eeb8abccd9f841491b409a2876b760d9) was granted leadership with session id 615f9053-0b6c-4f61-a064-fd40dc2f0785 at akka://flink/user/jobmanager_1.
2020-02-25 03:40:54,742 [flink-akka.actor.default-dispatcher-2] INFO  (JobMaster.java:712) - Starting execution of job SecondAlgorithmPass (eeb8abccd9f841491b409a2876b760d9) under job master id a064fd40dc2f0785615f90530b6c4f61.
2020-02-25 03:40:54,743 [flink-akka.actor.default-dispatcher-2] INFO  (ExecutionGraph.java:1325) - Job SecondAlgorithmPass (eeb8abccd9f841491b409a2876b760d9) switched from state CREATED to RUNNING.
2020-02-25 03:40:54,746 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (1/4) (04b96df5ea82dcf36551a165e706aa28) switched from CREATED to SCHEDULED.
2020-02-25 03:40:54,761 [flink-akka.actor.default-dispatcher-2] INFO  (SlotPoolImpl.java:369) - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{7a457daf5492e0b3736e8240da7b6190}]
2020-02-25 03:40:54,767 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (2/4) (42923477d0ec4b54bed5628753e1f617) switched from CREATED to SCHEDULED.
2020-02-25 03:40:54,768 [flink-akka.actor.default-dispatcher-2] INFO  (SlotPoolImpl.java:369) - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{c2322cda8fc5b87dbedad4243abbe2b0}]
2020-02-25 03:40:54,768 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (3/4) (a38660f220eba4d241d38d1712b62b27) switched from CREATED to SCHEDULED.
2020-02-25 03:40:54,769 [flink-akka.actor.default-dispatcher-2] INFO  (SlotPoolImpl.java:369) - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{f6a3562715b31237d84e303c9c3c6827}]
2020-02-25 03:40:54,769 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (4/4) (22c2f9f4f9b93e5228616e3d7e1b2364) switched from CREATED to SCHEDULED.
2020-02-25 03:40:54,769 [flink-akka.actor.default-dispatcher-2] INFO  (SlotPoolImpl.java:369) - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{5b25135f33493af97ef3b16043be0298}]
2020-02-25 03:40:54,769 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (1/4) (3f4b2c63309b36828c6953949fb2223e) switched from CREATED to SCHEDULED.
2020-02-25 03:40:54,769 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (2/4) (2eaf41f488436a4eca56a5b1413c1d09) switched from CREATED to SCHEDULED.
2020-02-25 03:40:54,770 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (3/4) (2a3be7b60547796c723ad295f200937d) switched from CREATED to SCHEDULED.
2020-02-25 03:40:54,770 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (4/4) (6f5bc48482e4dad2afb5083b6406f836) switched from CREATED to SCHEDULED.
2020-02-25 03:40:54,770 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (1/4) (29255f981f83013a1026bf0cb2e4a935) switched from CREATED to SCHEDULED.
2020-02-25 03:40:54,771 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (2/4) (7e4f56f3d4a58fa535ff146ddc21785d) switched from CREATED to SCHEDULED.
2020-02-25 03:40:54,771 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (3/4) (6c04e5f492409dd55726f530ef74c3f7) switched from CREATED to SCHEDULED.
2020-02-25 03:40:54,772 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (4/4) (eb54bbcc81a10cd15bd81820435d1f2e) switched from CREATED to SCHEDULED.
2020-02-25 03:40:54,772 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - KeyedProcess (1/4) (ab7871a74bc3eb421cc68a449d993292) switched from CREATED to SCHEDULED.
2020-02-25 03:40:54,772 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - KeyedProcess (2/4) (0d28e01a3b1fe253e4195391e712fa1d) switched from CREATED to SCHEDULED.
2020-02-25 03:40:54,772 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - KeyedProcess (3/4) (b632e9e64e1760a43f77928a8f4c9206) switched from CREATED to SCHEDULED.
2020-02-25 03:40:54,773 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - KeyedProcess (4/4) (25cc69191ff0ee863eb6af3fd76f824d) switched from CREATED to SCHEDULED.
2020-02-25 03:40:54,773 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Sink: Print to Std. Out (1/4) (1409d3c91444fcc428e5e7cd50ac4810) switched from CREATED to SCHEDULED.
2020-02-25 03:40:54,773 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Sink: Print to Std. Out (2/4) (1051ae8a6a83db301a2fc05f00b0d778) switched from CREATED to SCHEDULED.
2020-02-25 03:40:54,773 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Sink: Print to Std. Out (3/4) (df3410c2d509330304bf4966fb8348a7) switched from CREATED to SCHEDULED.
2020-02-25 03:40:54,774 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Sink: Print to Std. Out (4/4) (2032aa1dfb33ba70e2c1bc3f2d83e1b3) switched from CREATED to SCHEDULED.
2020-02-25 03:40:54,774 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Sink: Unnamed (1/4) (c102f99f2882a02c4a35da5a763157cf) switched from CREATED to SCHEDULED.
2020-02-25 03:40:54,774 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Sink: Unnamed (2/4) (fad461f6af1fab30baf58bbb318d7eac) switched from CREATED to SCHEDULED.
2020-02-25 03:40:54,774 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Sink: Unnamed (3/4) (aff2af1a468512bd871670aa56130a1c) switched from CREATED to SCHEDULED.
2020-02-25 03:40:54,775 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Sink: Unnamed (4/4) (b492e10edc5a52a0ce555aa5291345f8) switched from CREATED to SCHEDULED.
2020-02-25 03:40:54,776 [jobmanager-future-thread-1] INFO  (EmbeddedLeaderService.java:250) - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=615f9053-0b6c-4f61-a064-fd40dc2f0785
2020-02-25 03:40:54,777 [flink-akka.actor.default-dispatcher-2] INFO  (JobMaster.java:936) - Connecting to ResourceManager akka://flink/user/resourcemanager(ae12910febf174c347737a0e97604e73)
2020-02-25 03:40:54,779 [flink-akka.actor.default-dispatcher-4] INFO  (RetryingRegistration.java:155) - Resolved ResourceManager address, beginning registration
2020-02-25 03:40:54,780 [flink-akka.actor.default-dispatcher-4] INFO  (RetryingRegistration.java:204) - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-02-25 03:40:54,781 [flink-akka.actor.default-dispatcher-3] INFO  (ResourceManager.java:306) - Registering job manager a064fd40dc2f0785615f90530b6c4f61@akka://flink/user/jobmanager_1 for job eeb8abccd9f841491b409a2876b760d9.
2020-02-25 03:40:54,786 [flink-akka.actor.default-dispatcher-4] INFO  (ResourceManager.java:661) - Registered job manager a064fd40dc2f0785615f90530b6c4f61@akka://flink/user/jobmanager_1 for job eeb8abccd9f841491b409a2876b760d9.
2020-02-25 03:40:54,787 [flink-akka.actor.default-dispatcher-4] INFO  (JobMaster.java:958) - JobManager successfully registered at ResourceManager, leader id: ae12910febf174c347737a0e97604e73.
2020-02-25 03:40:54,788 [flink-akka.actor.default-dispatcher-4] INFO  (SlotPoolImpl.java:319) - Requesting new slot [SlotRequestId{7a457daf5492e0b3736e8240da7b6190}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-02-25 03:40:54,789 [flink-akka.actor.default-dispatcher-3] INFO  (ResourceManager.java:441) - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job eeb8abccd9f841491b409a2876b760d9 with allocation id e7b1a3d7d1c02bba91b67c06b07eb184.
2020-02-25 03:40:54,790 [flink-akka.actor.default-dispatcher-4] INFO  (SlotPoolImpl.java:319) - Requesting new slot [SlotRequestId{c2322cda8fc5b87dbedad4243abbe2b0}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-02-25 03:40:54,790 [flink-akka.actor.default-dispatcher-4] INFO  (SlotPoolImpl.java:319) - Requesting new slot [SlotRequestId{f6a3562715b31237d84e303c9c3c6827}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-02-25 03:40:54,791 [flink-akka.actor.default-dispatcher-4] INFO  (SlotPoolImpl.java:319) - Requesting new slot [SlotRequestId{5b25135f33493af97ef3b16043be0298}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-02-25 03:40:54,794 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:822) - Receive slot request e7b1a3d7d1c02bba91b67c06b07eb184 for job eeb8abccd9f841491b409a2876b760d9 from resource manager with leader id ae12910febf174c347737a0e97604e73.
2020-02-25 03:40:54,796 [flink-akka.actor.default-dispatcher-3] INFO  (ResourceManager.java:441) - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job eeb8abccd9f841491b409a2876b760d9 with allocation id 3c509e2f59dd63d3370aa8dc68174cab.
2020-02-25 03:40:54,797 [flink-akka.actor.default-dispatcher-3] INFO  (ResourceManager.java:441) - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job eeb8abccd9f841491b409a2876b760d9 with allocation id 0450b587e4a5837a77973d27ab847afd.
2020-02-25 03:40:54,799 [flink-akka.actor.default-dispatcher-3] INFO  (ResourceManager.java:441) - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job eeb8abccd9f841491b409a2876b760d9 with allocation id 990810697687848e14d2ca7d85f6fc1d.
2020-02-25 03:40:54,805 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:834) - Allocated slot for e7b1a3d7d1c02bba91b67c06b07eb184.
2020-02-25 03:40:54,805 [flink-akka.actor.default-dispatcher-4] INFO  (JobLeaderService.java:193) - Add job eeb8abccd9f841491b409a2876b760d9 for job leader monitoring.
2020-02-25 03:40:54,807 [mini-cluster-io-thread-1] INFO  (JobLeaderService.java:333) - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 615f9053-0b6c-4f61-a064-fd40dc2f0785.
2020-02-25 03:40:54,807 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:822) - Receive slot request 3c509e2f59dd63d3370aa8dc68174cab for job eeb8abccd9f841491b409a2876b760d9 from resource manager with leader id ae12910febf174c347737a0e97604e73.
2020-02-25 03:40:54,807 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:834) - Allocated slot for 3c509e2f59dd63d3370aa8dc68174cab.
2020-02-25 03:40:54,808 [flink-akka.actor.default-dispatcher-4] INFO  (JobLeaderService.java:193) - Add job eeb8abccd9f841491b409a2876b760d9 for job leader monitoring.
2020-02-25 03:40:54,808 [flink-akka.actor.default-dispatcher-5] INFO  (RetryingRegistration.java:155) - Resolved JobManager address, beginning registration
2020-02-25 03:40:54,808 [flink-akka.actor.default-dispatcher-5] INFO  (RetryingRegistration.java:204) - Registration at JobManager attempt 1 (timeout=100ms)
2020-02-25 03:40:54,809 [mini-cluster-io-thread-4] INFO  (JobLeaderService.java:333) - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 615f9053-0b6c-4f61-a064-fd40dc2f0785.
2020-02-25 03:40:54,810 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:822) - Receive slot request 0450b587e4a5837a77973d27ab847afd for job eeb8abccd9f841491b409a2876b760d9 from resource manager with leader id ae12910febf174c347737a0e97604e73.
2020-02-25 03:40:54,810 [flink-akka.actor.default-dispatcher-5] INFO  (RetryingRegistration.java:155) - Resolved JobManager address, beginning registration
2020-02-25 03:40:54,811 [flink-akka.actor.default-dispatcher-5] INFO  (RetryingRegistration.java:204) - Registration at JobManager attempt 1 (timeout=100ms)
2020-02-25 03:40:54,812 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:834) - Allocated slot for 0450b587e4a5837a77973d27ab847afd.
2020-02-25 03:40:54,812 [flink-akka.actor.default-dispatcher-4] INFO  (JobLeaderService.java:193) - Add job eeb8abccd9f841491b409a2876b760d9 for job leader monitoring.
2020-02-25 03:40:54,812 [mini-cluster-io-thread-2] INFO  (JobLeaderService.java:333) - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 615f9053-0b6c-4f61-a064-fd40dc2f0785.
2020-02-25 03:40:54,813 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:822) - Receive slot request 990810697687848e14d2ca7d85f6fc1d for job eeb8abccd9f841491b409a2876b760d9 from resource manager with leader id ae12910febf174c347737a0e97604e73.
2020-02-25 03:40:54,813 [flink-akka.actor.default-dispatcher-5] INFO  (RetryingRegistration.java:155) - Resolved JobManager address, beginning registration
2020-02-25 03:40:54,814 [flink-akka.actor.default-dispatcher-5] INFO  (RetryingRegistration.java:204) - Registration at JobManager attempt 1 (timeout=100ms)
2020-02-25 03:40:54,815 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:834) - Allocated slot for 990810697687848e14d2ca7d85f6fc1d.
2020-02-25 03:40:54,815 [flink-akka.actor.default-dispatcher-4] INFO  (JobLeaderService.java:193) - Add job eeb8abccd9f841491b409a2876b760d9 for job leader monitoring.
2020-02-25 03:40:54,816 [mini-cluster-io-thread-3] INFO  (JobLeaderService.java:333) - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 615f9053-0b6c-4f61-a064-fd40dc2f0785.
2020-02-25 03:40:54,817 [flink-akka.actor.default-dispatcher-2] INFO  (RetryingRegistration.java:155) - Resolved JobManager address, beginning registration
2020-02-25 03:40:54,817 [flink-akka.actor.default-dispatcher-2] INFO  (RetryingRegistration.java:204) - Registration at JobManager attempt 1 (timeout=100ms)
2020-02-25 03:40:54,819 [flink-akka.actor.default-dispatcher-5] INFO  (JobLeaderService.java:382) - Successful registration at job manager akka://flink/user/jobmanager_1 for job eeb8abccd9f841491b409a2876b760d9.
2020-02-25 03:40:54,820 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:1227) - Establish JobManager connection for job eeb8abccd9f841491b409a2876b760d9.
2020-02-25 03:40:54,822 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:1128) - Offer reserved slots to the leader of job eeb8abccd9f841491b409a2876b760d9.
2020-02-25 03:40:54,838 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (1/4) (04b96df5ea82dcf36551a165e706aa28) switched from SCHEDULED to DEPLOYING.
2020-02-25 03:40:54,839 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Map (1/4) (attempt #0) to ebf5f964-f09f-42b8-9abd-e64eea74a85a @ localhost (dataPort=-1)
2020-02-25 03:40:54,853 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (2/4) (42923477d0ec4b54bed5628753e1f617) switched from SCHEDULED to DEPLOYING.
2020-02-25 03:40:54,853 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Map (2/4) (attempt #0) to ebf5f964-f09f-42b8-9abd-e64eea74a85a @ localhost (dataPort=-1)
2020-02-25 03:40:54,854 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (3/4) (a38660f220eba4d241d38d1712b62b27) switched from SCHEDULED to DEPLOYING.
2020-02-25 03:40:54,854 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Map (3/4) (attempt #0) to ebf5f964-f09f-42b8-9abd-e64eea74a85a @ localhost (dataPort=-1)
2020-02-25 03:40:54,855 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (4/4) (22c2f9f4f9b93e5228616e3d7e1b2364) switched from SCHEDULED to DEPLOYING.
2020-02-25 03:40:54,855 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Map (4/4) (attempt #0) to ebf5f964-f09f-42b8-9abd-e64eea74a85a @ localhost (dataPort=-1)
2020-02-25 03:40:54,856 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (1/4) (3f4b2c63309b36828c6953949fb2223e) switched from SCHEDULED to DEPLOYING.
2020-02-25 03:40:54,856 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Map (1/4) (attempt #0) to ebf5f964-f09f-42b8-9abd-e64eea74a85a @ localhost (dataPort=-1)
2020-02-25 03:40:54,857 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (2/4) (2eaf41f488436a4eca56a5b1413c1d09) switched from SCHEDULED to DEPLOYING.
2020-02-25 03:40:54,857 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Map (2/4) (attempt #0) to ebf5f964-f09f-42b8-9abd-e64eea74a85a @ localhost (dataPort=-1)
2020-02-25 03:40:54,858 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (3/4) (2a3be7b60547796c723ad295f200937d) switched from SCHEDULED to DEPLOYING.
2020-02-25 03:40:54,858 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Map (3/4) (attempt #0) to ebf5f964-f09f-42b8-9abd-e64eea74a85a @ localhost (dataPort=-1)
2020-02-25 03:40:54,858 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (4/4) (6f5bc48482e4dad2afb5083b6406f836) switched from SCHEDULED to DEPLOYING.
2020-02-25 03:40:54,859 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Map (4/4) (attempt #0) to ebf5f964-f09f-42b8-9abd-e64eea74a85a @ localhost (dataPort=-1)
2020-02-25 03:40:54,859 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (1/4) (29255f981f83013a1026bf0cb2e4a935) switched from SCHEDULED to DEPLOYING.
2020-02-25 03:40:54,859 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (1/4) (attempt #0) to ebf5f964-f09f-42b8-9abd-e64eea74a85a @ localhost (dataPort=-1)
2020-02-25 03:40:54,871 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (2/4) (7e4f56f3d4a58fa535ff146ddc21785d) switched from SCHEDULED to DEPLOYING.
2020-02-25 03:40:54,872 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (2/4) (attempt #0) to ebf5f964-f09f-42b8-9abd-e64eea74a85a @ localhost (dataPort=-1)
2020-02-25 03:40:54,872 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (3/4) (6c04e5f492409dd55726f530ef74c3f7) switched from SCHEDULED to DEPLOYING.
2020-02-25 03:40:54,877 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (3/4) (attempt #0) to ebf5f964-f09f-42b8-9abd-e64eea74a85a @ localhost (dataPort=-1)
2020-02-25 03:40:54,878 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (4/4) (eb54bbcc81a10cd15bd81820435d1f2e) switched from SCHEDULED to DEPLOYING.
2020-02-25 03:40:54,879 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (4/4) (attempt #0) to ebf5f964-f09f-42b8-9abd-e64eea74a85a @ localhost (dataPort=-1)
2020-02-25 03:40:54,879 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - KeyedProcess (1/4) (ab7871a74bc3eb421cc68a449d993292) switched from SCHEDULED to DEPLOYING.
2020-02-25 03:40:54,880 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:713) - Deploying KeyedProcess (1/4) (attempt #0) to ebf5f964-f09f-42b8-9abd-e64eea74a85a @ localhost (dataPort=-1)
2020-02-25 03:40:54,882 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - KeyedProcess (2/4) (0d28e01a3b1fe253e4195391e712fa1d) switched from SCHEDULED to DEPLOYING.
2020-02-25 03:40:54,882 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:713) - Deploying KeyedProcess (2/4) (attempt #0) to ebf5f964-f09f-42b8-9abd-e64eea74a85a @ localhost (dataPort=-1)
2020-02-25 03:40:54,884 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - KeyedProcess (3/4) (b632e9e64e1760a43f77928a8f4c9206) switched from SCHEDULED to DEPLOYING.
2020-02-25 03:40:54,887 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:713) - Deploying KeyedProcess (3/4) (attempt #0) to ebf5f964-f09f-42b8-9abd-e64eea74a85a @ localhost (dataPort=-1)
2020-02-25 03:40:54,889 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - KeyedProcess (4/4) (25cc69191ff0ee863eb6af3fd76f824d) switched from SCHEDULED to DEPLOYING.
2020-02-25 03:40:54,889 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:713) - Deploying KeyedProcess (4/4) (attempt #0) to ebf5f964-f09f-42b8-9abd-e64eea74a85a @ localhost (dataPort=-1)
2020-02-25 03:40:54,891 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Map (1/4).
2020-02-25 03:40:54,894 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Sink: Print to Std. Out (1/4) (1409d3c91444fcc428e5e7cd50ac4810) switched from SCHEDULED to DEPLOYING.
2020-02-25 03:40:54,895 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:713) - Deploying Sink: Print to Std. Out (1/4) (attempt #0) to ebf5f964-f09f-42b8-9abd-e64eea74a85a @ localhost (dataPort=-1)
2020-02-25 03:40:54,897 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Sink: Print to Std. Out (2/4) (1051ae8a6a83db301a2fc05f00b0d778) switched from SCHEDULED to DEPLOYING.
2020-02-25 03:40:54,898 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:713) - Deploying Sink: Print to Std. Out (2/4) (attempt #0) to ebf5f964-f09f-42b8-9abd-e64eea74a85a @ localhost (dataPort=-1)
2020-02-25 03:40:54,899 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Sink: Print to Std. Out (3/4) (df3410c2d509330304bf4966fb8348a7) switched from SCHEDULED to DEPLOYING.
2020-02-25 03:40:54,899 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:713) - Deploying Sink: Print to Std. Out (3/4) (attempt #0) to ebf5f964-f09f-42b8-9abd-e64eea74a85a @ localhost (dataPort=-1)
2020-02-25 03:40:54,902 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Sink: Print to Std. Out (4/4) (2032aa1dfb33ba70e2c1bc3f2d83e1b3) switched from SCHEDULED to DEPLOYING.
2020-02-25 03:40:54,903 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:713) - Deploying Sink: Print to Std. Out (4/4) (attempt #0) to ebf5f964-f09f-42b8-9abd-e64eea74a85a @ localhost (dataPort=-1)
2020-02-25 03:40:54,903 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Sink: Unnamed (1/4) (c102f99f2882a02c4a35da5a763157cf) switched from SCHEDULED to DEPLOYING.
2020-02-25 03:40:54,904 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:713) - Deploying Sink: Unnamed (1/4) (attempt #0) to ebf5f964-f09f-42b8-9abd-e64eea74a85a @ localhost (dataPort=-1)
2020-02-25 03:40:54,906 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Sink: Unnamed (2/4) (fad461f6af1fab30baf58bbb318d7eac) switched from SCHEDULED to DEPLOYING.
2020-02-25 03:40:54,906 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Map (2/4).
2020-02-25 03:40:54,906 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (1/4) (04b96df5ea82dcf36551a165e706aa28) switched from CREATED to DEPLOYING.
2020-02-25 03:40:54,907 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Map (1/4) (04b96df5ea82dcf36551a165e706aa28) [DEPLOYING]
2020-02-25 03:40:54,906 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:713) - Deploying Sink: Unnamed (2/4) (attempt #0) to ebf5f964-f09f-42b8-9abd-e64eea74a85a @ localhost (dataPort=-1)
2020-02-25 03:40:54,908 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Sink: Unnamed (3/4) (aff2af1a468512bd871670aa56130a1c) switched from SCHEDULED to DEPLOYING.
2020-02-25 03:40:54,908 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:713) - Deploying Sink: Unnamed (3/4) (attempt #0) to ebf5f964-f09f-42b8-9abd-e64eea74a85a @ localhost (dataPort=-1)
2020-02-25 03:40:54,909 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Sink: Unnamed (4/4) (b492e10edc5a52a0ce555aa5291345f8) switched from SCHEDULED to DEPLOYING.
2020-02-25 03:40:54,910 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:713) - Deploying Sink: Unnamed (4/4) (attempt #0) to ebf5f964-f09f-42b8-9abd-e64eea74a85a @ localhost (dataPort=-1)
2020-02-25 03:40:54,918 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Map (3/4).
2020-02-25 03:40:54,923 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Map (4/4).
2020-02-25 03:40:54,927 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Map (1/4).
2020-02-25 03:40:54,933 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Map (2/4).
2020-02-25 03:40:54,929 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (2/4) (42923477d0ec4b54bed5628753e1f617) switched from CREATED to DEPLOYING.
2020-02-25 03:40:54,927 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (4/4) (22c2f9f4f9b93e5228616e3d7e1b2364) switched from CREATED to DEPLOYING.
2020-02-25 03:40:54,941 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Map (2/4) (42923477d0ec4b54bed5628753e1f617) [DEPLOYING]
2020-02-25 03:40:54,933 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (1/4) (3f4b2c63309b36828c6953949fb2223e) switched from CREATED to DEPLOYING.
2020-02-25 03:40:54,941 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Map (1/4) (3f4b2c63309b36828c6953949fb2223e) [DEPLOYING]
2020-02-25 03:40:54,931 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (3/4) (a38660f220eba4d241d38d1712b62b27) switched from CREATED to DEPLOYING.
2020-02-25 03:40:54,942 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Map (3/4) (a38660f220eba4d241d38d1712b62b27) [DEPLOYING]
2020-02-25 03:40:54,941 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Map (4/4) (22c2f9f4f9b93e5228616e3d7e1b2364) [DEPLOYING]
2020-02-25 03:40:54,945 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Map (1/4) (04b96df5ea82dcf36551a165e706aa28) [DEPLOYING].
2020-02-25 03:40:54,946 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Map (1/4) (04b96df5ea82dcf36551a165e706aa28) [DEPLOYING].
2020-02-25 03:40:54,949 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Map (3/4).
2020-02-25 03:40:54,963 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Map (3/4) (a38660f220eba4d241d38d1712b62b27) [DEPLOYING].
2020-02-25 03:40:54,963 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Map (2/4) (42923477d0ec4b54bed5628753e1f617) [DEPLOYING].
2020-02-25 03:40:54,963 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Map (1/4) (3f4b2c63309b36828c6953949fb2223e) [DEPLOYING].
2020-02-25 03:40:54,964 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Map (4/4) (22c2f9f4f9b93e5228616e3d7e1b2364) [DEPLOYING].
2020-02-25 03:40:54,964 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Map (4/4).
2020-02-25 03:40:54,964 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (3/4) (2a3be7b60547796c723ad295f200937d) switched from CREATED to DEPLOYING.
2020-02-25 03:40:54,965 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Map (1/4) (3f4b2c63309b36828c6953949fb2223e) [DEPLOYING].
2020-02-25 03:40:54,964 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (2/4) (2eaf41f488436a4eca56a5b1413c1d09) switched from CREATED to DEPLOYING.
2020-02-25 03:40:54,966 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Map (2/4) (2eaf41f488436a4eca56a5b1413c1d09) [DEPLOYING]
2020-02-25 03:40:54,966 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Map (2/4) (2eaf41f488436a4eca56a5b1413c1d09) [DEPLOYING].
2020-02-25 03:40:54,967 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Map (3/4) (a38660f220eba4d241d38d1712b62b27) [DEPLOYING].
2020-02-25 03:40:54,967 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Map (2/4) (2eaf41f488436a4eca56a5b1413c1d09) [DEPLOYING].
2020-02-25 03:40:54,966 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Map (2/4) (42923477d0ec4b54bed5628753e1f617) [DEPLOYING].
2020-02-25 03:40:54,966 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Map (4/4) (22c2f9f4f9b93e5228616e3d7e1b2364) [DEPLOYING].
2020-02-25 03:40:54,967 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Map (3/4) (2a3be7b60547796c723ad295f200937d) [DEPLOYING]
2020-02-25 03:40:54,968 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Map (3/4) (2a3be7b60547796c723ad295f200937d) [DEPLOYING].
2020-02-25 03:40:54,969 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Map (3/4) (2a3be7b60547796c723ad295f200937d) [DEPLOYING].
2020-02-25 03:40:54,972 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (4/4) (6f5bc48482e4dad2afb5083b6406f836) switched from CREATED to DEPLOYING.
2020-02-25 03:40:54,972 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Map (4/4) (6f5bc48482e4dad2afb5083b6406f836) [DEPLOYING]
2020-02-25 03:40:54,977 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (4/4) (22c2f9f4f9b93e5228616e3d7e1b2364) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:54,978 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (4/4) (22c2f9f4f9b93e5228616e3d7e1b2364) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:54,979 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-25 03:40:54,985 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (1/4) (3f4b2c63309b36828c6953949fb2223e) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:54,985 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (1/4) (3f4b2c63309b36828c6953949fb2223e) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:54,987 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Map (4/4) (6f5bc48482e4dad2afb5083b6406f836) [DEPLOYING].
2020-02-25 03:40:54,988 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Map (4/4) (6f5bc48482e4dad2afb5083b6406f836) [DEPLOYING].
2020-02-25 03:40:54,985 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-25 03:40:54,996 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (3/4) (a38660f220eba4d241d38d1712b62b27) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:54,997 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-25 03:40:54,997 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (3/4) (a38660f220eba4d241d38d1712b62b27) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:54,997 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (1/4) (04b96df5ea82dcf36551a165e706aa28) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:54,998 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (1/4) (04b96df5ea82dcf36551a165e706aa28) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:54,999 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-25 03:40:55,001 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (2/4) (2eaf41f488436a4eca56a5b1413c1d09) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,001 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-25 03:40:55,001 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (2/4) (2eaf41f488436a4eca56a5b1413c1d09) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,008 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (3/4) (2a3be7b60547796c723ad295f200937d) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,009 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-25 03:40:55,010 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (3/4) (2a3be7b60547796c723ad295f200937d) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,013 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (4/4) (6f5bc48482e4dad2afb5083b6406f836) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,013 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (4/4) (6f5bc48482e4dad2afb5083b6406f836) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,013 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-25 03:40:55,020 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (2/4) (42923477d0ec4b54bed5628753e1f617) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,020 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-25 03:40:55,021 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (2/4) (42923477d0ec4b54bed5628753e1f617) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,023 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (1/4).
2020-02-25 03:40:55,038 [Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (1/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (1/4) (29255f981f83013a1026bf0cb2e4a935) switched from CREATED to DEPLOYING.
2020-02-25 03:40:55,038 [Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (1/4) (29255f981f83013a1026bf0cb2e4a935) [DEPLOYING]
2020-02-25 03:40:55,039 [Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (1/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (1/4) (29255f981f83013a1026bf0cb2e4a935) [DEPLOYING].
2020-02-25 03:40:55,039 [Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (1/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (1/4) (29255f981f83013a1026bf0cb2e4a935) [DEPLOYING].
2020-02-25 03:40:55,048 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (2/4).
2020-02-25 03:40:55,061 [Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (2/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (2/4) (7e4f56f3d4a58fa535ff146ddc21785d) switched from CREATED to DEPLOYING.
2020-02-25 03:40:55,063 [Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (1/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (1/4) (29255f981f83013a1026bf0cb2e4a935) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,069 [Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-25 03:40:55,062 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (3/4).
2020-02-25 03:40:55,069 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (1/4) (29255f981f83013a1026bf0cb2e4a935) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,068 [Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (2/4) (7e4f56f3d4a58fa535ff146ddc21785d) [DEPLOYING]
2020-02-25 03:40:55,075 [Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (2/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (2/4) (7e4f56f3d4a58fa535ff146ddc21785d) [DEPLOYING].
2020-02-25 03:40:55,076 [Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (2/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (2/4) (7e4f56f3d4a58fa535ff146ddc21785d) [DEPLOYING].
2020-02-25 03:40:55,084 [Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (3/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (3/4) (6c04e5f492409dd55726f530ef74c3f7) switched from CREATED to DEPLOYING.
2020-02-25 03:40:55,086 [Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (2/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (2/4) (7e4f56f3d4a58fa535ff146ddc21785d) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,087 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (2/4) (7e4f56f3d4a58fa535ff146ddc21785d) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,088 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (4/4).
2020-02-25 03:40:55,087 [Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (3/4) (6c04e5f492409dd55726f530ef74c3f7) [DEPLOYING]
2020-02-25 03:40:55,087 [Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-25 03:40:55,095 [Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (3/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (3/4) (6c04e5f492409dd55726f530ef74c3f7) [DEPLOYING].
2020-02-25 03:40:55,096 [Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (4/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (4/4) (eb54bbcc81a10cd15bd81820435d1f2e) switched from CREATED to DEPLOYING.
2020-02-25 03:40:55,100 [Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (4/4) (eb54bbcc81a10cd15bd81820435d1f2e) [DEPLOYING]
2020-02-25 03:40:55,100 [Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (4/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (4/4) (eb54bbcc81a10cd15bd81820435d1f2e) [DEPLOYING].
2020-02-25 03:40:55,102 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:592) - Received task KeyedProcess (1/4).
2020-02-25 03:40:55,102 [Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (3/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (3/4) (6c04e5f492409dd55726f530ef74c3f7) [DEPLOYING].
2020-02-25 03:40:55,113 [KeyedProcess (1/4)] INFO  (Task.java:958) - KeyedProcess (1/4) (ab7871a74bc3eb421cc68a449d993292) switched from CREATED to DEPLOYING.
2020-02-25 03:40:55,113 [KeyedProcess (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task KeyedProcess (1/4) (ab7871a74bc3eb421cc68a449d993292) [DEPLOYING]
2020-02-25 03:40:55,121 [Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (4/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (4/4) (eb54bbcc81a10cd15bd81820435d1f2e) [DEPLOYING].
2020-02-25 03:40:55,121 [KeyedProcess (1/4)] INFO  (Task.java:593) - Loading JAR files for task KeyedProcess (1/4) (ab7871a74bc3eb421cc68a449d993292) [DEPLOYING].
2020-02-25 03:40:55,122 [KeyedProcess (1/4)] INFO  (Task.java:619) - Registering task at network: KeyedProcess (1/4) (ab7871a74bc3eb421cc68a449d993292) [DEPLOYING].
2020-02-25 03:40:55,122 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:592) - Received task KeyedProcess (2/4).
2020-02-25 03:40:55,124 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:592) - Received task KeyedProcess (3/4).
2020-02-25 03:40:55,125 [KeyedProcess (2/4)] INFO  (Task.java:958) - KeyedProcess (2/4) (0d28e01a3b1fe253e4195391e712fa1d) switched from CREATED to DEPLOYING.
2020-02-25 03:40:55,125 [KeyedProcess (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task KeyedProcess (2/4) (0d28e01a3b1fe253e4195391e712fa1d) [DEPLOYING]
2020-02-25 03:40:55,125 [KeyedProcess (2/4)] INFO  (Task.java:593) - Loading JAR files for task KeyedProcess (2/4) (0d28e01a3b1fe253e4195391e712fa1d) [DEPLOYING].
2020-02-25 03:40:55,132 [KeyedProcess (3/4)] INFO  (Task.java:958) - KeyedProcess (3/4) (b632e9e64e1760a43f77928a8f4c9206) switched from CREATED to DEPLOYING.
2020-02-25 03:40:55,133 [Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (3/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (3/4) (6c04e5f492409dd55726f530ef74c3f7) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,135 [KeyedProcess (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task KeyedProcess (3/4) (b632e9e64e1760a43f77928a8f4c9206) [DEPLOYING]
2020-02-25 03:40:55,135 [KeyedProcess (3/4)] INFO  (Task.java:593) - Loading JAR files for task KeyedProcess (3/4) (b632e9e64e1760a43f77928a8f4c9206) [DEPLOYING].
2020-02-25 03:40:55,135 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (3/4) (6c04e5f492409dd55726f530ef74c3f7) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,135 [KeyedProcess (3/4)] INFO  (Task.java:619) - Registering task at network: KeyedProcess (3/4) (b632e9e64e1760a43f77928a8f4c9206) [DEPLOYING].
2020-02-25 03:40:55,135 [Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-25 03:40:55,138 [KeyedProcess (2/4)] INFO  (Task.java:619) - Registering task at network: KeyedProcess (2/4) (0d28e01a3b1fe253e4195391e712fa1d) [DEPLOYING].
2020-02-25 03:40:55,140 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-25 03:40:55,140 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-25 03:40:55,141 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-25 03:40:55,141 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-25 03:40:55,140 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-25 03:40:55,141 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-25 03:40:55,140 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-25 03:40:55,141 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-25 03:40:55,140 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-25 03:40:55,142 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-25 03:40:55,152 [KeyedProcess (1/4)] INFO  (Task.java:958) - KeyedProcess (1/4) (ab7871a74bc3eb421cc68a449d993292) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,153 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-25 03:40:55,153 [KeyedProcess (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-25 03:40:55,153 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-25 03:40:55,153 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-25 03:40:55,153 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - KeyedProcess (1/4) (ab7871a74bc3eb421cc68a449d993292) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,153 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-25 03:40:55,170 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task KeyedProcess (4/4).
2020-02-25 03:40:55,177 [KeyedProcess (3/4)] INFO  (Task.java:958) - KeyedProcess (3/4) (b632e9e64e1760a43f77928a8f4c9206) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,177 [KeyedProcess (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-25 03:40:55,177 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - KeyedProcess (3/4) (b632e9e64e1760a43f77928a8f4c9206) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,180 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-25 03:40:55,180 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-25 03:40:55,187 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Sink: Print to Std. Out (1/4).
2020-02-25 03:40:55,188 [Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (4/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (4/4) (eb54bbcc81a10cd15bd81820435d1f2e) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,188 [KeyedProcess (4/4)] INFO  (Task.java:958) - KeyedProcess (4/4) (25cc69191ff0ee863eb6af3fd76f824d) switched from CREATED to DEPLOYING.
2020-02-25 03:40:55,188 [KeyedProcess (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task KeyedProcess (4/4) (25cc69191ff0ee863eb6af3fd76f824d) [DEPLOYING]
2020-02-25 03:40:55,188 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (4/4) (eb54bbcc81a10cd15bd81820435d1f2e) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,189 [KeyedProcess (4/4)] INFO  (Task.java:593) - Loading JAR files for task KeyedProcess (4/4) (25cc69191ff0ee863eb6af3fd76f824d) [DEPLOYING].
2020-02-25 03:40:55,189 [KeyedProcess (4/4)] INFO  (Task.java:619) - Registering task at network: KeyedProcess (4/4) (25cc69191ff0ee863eb6af3fd76f824d) [DEPLOYING].
2020-02-25 03:40:55,192 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 2 has no restore state.
2020-02-25 03:40:55,192 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 1 has no restore state.
2020-02-25 03:40:55,188 [Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-25 03:40:55,192 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 1 has no restore state.
2020-02-25 03:40:55,192 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 3 has no restore state.
2020-02-25 03:40:55,192 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 3 has no restore state.
2020-02-25 03:40:55,192 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 0 has no restore state.
2020-02-25 03:40:55,194 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 2 has no restore state.
2020-02-25 03:40:55,195 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 0 has no restore state.
2020-02-25 03:40:55,205 [Sink: Print to Std. Out (1/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (1/4) (1409d3c91444fcc428e5e7cd50ac4810) switched from CREATED to DEPLOYING.
2020-02-25 03:40:55,205 [Sink: Print to Std. Out (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (1/4) (1409d3c91444fcc428e5e7cd50ac4810) [DEPLOYING]
2020-02-25 03:40:55,205 [Sink: Print to Std. Out (1/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Print to Std. Out (1/4) (1409d3c91444fcc428e5e7cd50ac4810) [DEPLOYING].
2020-02-25 03:40:55,206 [Sink: Print to Std. Out (1/4)] INFO  (Task.java:619) - Registering task at network: Sink: Print to Std. Out (1/4) (1409d3c91444fcc428e5e7cd50ac4810) [DEPLOYING].
2020-02-25 03:40:55,212 [KeyedProcess (2/4)] INFO  (Task.java:958) - KeyedProcess (2/4) (0d28e01a3b1fe253e4195391e712fa1d) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,212 [KeyedProcess (4/4)] INFO  (Task.java:958) - KeyedProcess (4/4) (25cc69191ff0ee863eb6af3fd76f824d) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,213 [KeyedProcess (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-25 03:40:55,213 [KeyedProcess (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-25 03:40:55,217 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Sink: Print to Std. Out (2/4).
2020-02-25 03:40:55,218 [Sink: Print to Std. Out (2/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (2/4) (1051ae8a6a83db301a2fc05f00b0d778) switched from CREATED to DEPLOYING.
2020-02-25 03:40:55,218 [Sink: Print to Std. Out (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (2/4) (1051ae8a6a83db301a2fc05f00b0d778) [DEPLOYING]
2020-02-25 03:40:55,218 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - KeyedProcess (2/4) (0d28e01a3b1fe253e4195391e712fa1d) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,219 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Sink: Print to Std. Out (3/4).
2020-02-25 03:40:55,222 [Sink: Print to Std. Out (2/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Print to Std. Out (2/4) (1051ae8a6a83db301a2fc05f00b0d778) [DEPLOYING].
2020-02-25 03:40:55,222 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - KeyedProcess (4/4) (25cc69191ff0ee863eb6af3fd76f824d) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,222 [Sink: Print to Std. Out (2/4)] INFO  (Task.java:619) - Registering task at network: Sink: Print to Std. Out (2/4) (1051ae8a6a83db301a2fc05f00b0d778) [DEPLOYING].
2020-02-25 03:40:55,223 [Sink: Print to Std. Out (2/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (2/4) (1051ae8a6a83db301a2fc05f00b0d778) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,223 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Sink: Print to Std. Out (2/4) (1051ae8a6a83db301a2fc05f00b0d778) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,224 [Sink: Print to Std. Out (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-25 03:40:55,224 [Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (3/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-25 03:40:55,227 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Sink: Print to Std. Out (4/4).
2020-02-25 03:40:55,227 [Sink: Print to Std. Out (3/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (3/4) (df3410c2d509330304bf4966fb8348a7) switched from CREATED to DEPLOYING.
2020-02-25 03:40:55,228 [Sink: Print to Std. Out (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (3/4) (df3410c2d509330304bf4966fb8348a7) [DEPLOYING]
2020-02-25 03:40:55,228 [Sink: Print to Std. Out (3/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Print to Std. Out (3/4) (df3410c2d509330304bf4966fb8348a7) [DEPLOYING].
2020-02-25 03:40:55,228 [Sink: Print to Std. Out (3/4)] INFO  (Task.java:619) - Registering task at network: Sink: Print to Std. Out (3/4) (df3410c2d509330304bf4966fb8348a7) [DEPLOYING].
2020-02-25 03:40:55,231 [KeyedProcess (4/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-25 03:40:55,231 [KeyedProcess (2/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-25 03:40:55,224 [KeyedProcess (3/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-25 03:40:55,231 [Sink: Print to Std. Out (1/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (1/4) (1409d3c91444fcc428e5e7cd50ac4810) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,224 [Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (4/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-25 03:40:55,232 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Print to Std. Out (1/4) (1409d3c91444fcc428e5e7cd50ac4810) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,232 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Sink: Unnamed (1/4).
2020-02-25 03:40:55,224 [Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (2/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-25 03:40:55,228 [Window(TumblingEventTimeWindows(60000), EventTimeTrigger, CoGroupWindowFunction) (1/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-25 03:40:55,228 [KeyedProcess (1/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-25 03:40:55,233 [Sink: Print to Std. Out (2/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-25 03:40:55,232 [Sink: Print to Std. Out (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-25 03:40:55,239 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Sink: Unnamed (2/4).
2020-02-25 03:40:55,239 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-25 03:40:55,238 [Sink: Print to Std. Out (4/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (4/4) (2032aa1dfb33ba70e2c1bc3f2d83e1b3) switched from CREATED to DEPLOYING.
2020-02-25 03:40:55,249 [Sink: Print to Std. Out (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (4/4) (2032aa1dfb33ba70e2c1bc3f2d83e1b3) [DEPLOYING]
2020-02-25 03:40:55,249 [Sink: Print to Std. Out (4/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Print to Std. Out (4/4) (2032aa1dfb33ba70e2c1bc3f2d83e1b3) [DEPLOYING].
2020-02-25 03:40:55,250 [Sink: Print to Std. Out (4/4)] INFO  (Task.java:619) - Registering task at network: Sink: Print to Std. Out (4/4) (2032aa1dfb33ba70e2c1bc3f2d83e1b3) [DEPLOYING].
2020-02-25 03:40:55,250 [Sink: Print to Std. Out (4/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (4/4) (2032aa1dfb33ba70e2c1bc3f2d83e1b3) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,251 [Sink: Print to Std. Out (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-25 03:40:55,251 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Print to Std. Out (4/4) (2032aa1dfb33ba70e2c1bc3f2d83e1b3) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,259 [Sink: Print to Std. Out (4/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-25 03:40:55,237 [Sink: Print to Std. Out (3/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (3/4) (df3410c2d509330304bf4966fb8348a7) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,255 [KeyedProcess (2/4)] INFO  (TypeExtractor.java:1815) - class java.util.Vector does not contain a getter for field elementData
2020-02-25 03:40:55,260 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Sink: Print to Std. Out (3/4) (df3410c2d509330304bf4966fb8348a7) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,253 [Sink: Print to Std. Out (1/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-25 03:40:55,261 [Sink: Print to Std. Out (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-25 03:40:55,252 [KeyedProcess (3/4)] INFO  (TypeExtractor.java:1815) - class java.util.Vector does not contain a getter for field elementData
2020-02-25 03:40:55,261 [KeyedProcess (3/4)] INFO  (TypeExtractor.java:1818) - class java.util.Vector does not contain a setter for field elementData
2020-02-25 03:40:55,261 [KeyedProcess (3/4)] INFO  (TypeExtractor.java:1857) - Class class java.util.Vector cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-25 03:40:55,249 [KeyedProcess (1/4)] INFO  (TypeExtractor.java:1815) - class java.util.Vector does not contain a getter for field elementData
2020-02-25 03:40:55,264 [KeyedProcess (1/4)] INFO  (TypeExtractor.java:1818) - class java.util.Vector does not contain a setter for field elementData
2020-02-25 03:40:55,264 [KeyedProcess (1/4)] INFO  (TypeExtractor.java:1857) - Class class java.util.Vector cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-25 03:40:55,248 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-25 03:40:55,239 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-25 03:40:55,245 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Sink: Unnamed (3/4).
2020-02-25 03:40:55,245 [KeyedProcess (4/4)] INFO  (TypeExtractor.java:1815) - class java.util.Vector does not contain a getter for field elementData
2020-02-25 03:40:55,270 [KeyedProcess (4/4)] INFO  (TypeExtractor.java:1818) - class java.util.Vector does not contain a setter for field elementData
2020-02-25 03:40:55,270 [KeyedProcess (4/4)] INFO  (TypeExtractor.java:1857) - Class class java.util.Vector cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-25 03:40:55,244 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-25 03:40:55,244 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-25 03:40:55,244 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-25 03:40:55,244 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-25 03:40:55,243 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-25 03:40:55,240 [Sink: Unnamed (2/4)] INFO  (Task.java:958) - Sink: Unnamed (2/4) (fad461f6af1fab30baf58bbb318d7eac) switched from CREATED to DEPLOYING.
2020-02-25 03:40:55,240 [Sink: Unnamed (1/4)] INFO  (Task.java:958) - Sink: Unnamed (1/4) (c102f99f2882a02c4a35da5a763157cf) switched from CREATED to DEPLOYING.
2020-02-25 03:40:55,278 [Sink: Unnamed (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Unnamed (2/4) (fad461f6af1fab30baf58bbb318d7eac) [DEPLOYING]
2020-02-25 03:40:55,278 [Sink: Unnamed (2/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Unnamed (2/4) (fad461f6af1fab30baf58bbb318d7eac) [DEPLOYING].
2020-02-25 03:40:55,279 [Sink: Unnamed (2/4)] INFO  (Task.java:619) - Registering task at network: Sink: Unnamed (2/4) (fad461f6af1fab30baf58bbb318d7eac) [DEPLOYING].
2020-02-25 03:40:55,279 [Sink: Unnamed (2/4)] INFO  (Task.java:958) - Sink: Unnamed (2/4) (fad461f6af1fab30baf58bbb318d7eac) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,269 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Sink: Unnamed (4/4).
2020-02-25 03:40:55,267 [Sink: Unnamed (3/4)] INFO  (Task.java:958) - Sink: Unnamed (3/4) (aff2af1a468512bd871670aa56130a1c) switched from CREATED to DEPLOYING.
2020-02-25 03:40:55,280 [Sink: Unnamed (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Unnamed (3/4) (aff2af1a468512bd871670aa56130a1c) [DEPLOYING]
2020-02-25 03:40:55,280 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Sink: Unnamed (2/4) (fad461f6af1fab30baf58bbb318d7eac) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,281 [Sink: Unnamed (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-25 03:40:55,263 [Sink: Print to Std. Out (3/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-25 03:40:55,260 [KeyedProcess (2/4)] INFO  (TypeExtractor.java:1818) - class java.util.Vector does not contain a setter for field elementData
2020-02-25 03:40:55,282 [KeyedProcess (2/4)] INFO  (TypeExtractor.java:1857) - Class class java.util.Vector cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-25 03:40:55,280 [Sink: Unnamed (3/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Unnamed (3/4) (aff2af1a468512bd871670aa56130a1c) [DEPLOYING].
2020-02-25 03:40:55,278 [Sink: Unnamed (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Unnamed (1/4) (c102f99f2882a02c4a35da5a763157cf) [DEPLOYING]
2020-02-25 03:40:55,283 [Sink: Unnamed (1/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Unnamed (1/4) (c102f99f2882a02c4a35da5a763157cf) [DEPLOYING].
2020-02-25 03:40:55,283 [Sink: Unnamed (3/4)] INFO  (Task.java:619) - Registering task at network: Sink: Unnamed (3/4) (aff2af1a468512bd871670aa56130a1c) [DEPLOYING].
2020-02-25 03:40:55,283 [Sink: Unnamed (1/4)] INFO  (Task.java:619) - Registering task at network: Sink: Unnamed (1/4) (c102f99f2882a02c4a35da5a763157cf) [DEPLOYING].
2020-02-25 03:40:55,283 [Sink: Unnamed (3/4)] INFO  (Task.java:958) - Sink: Unnamed (3/4) (aff2af1a468512bd871670aa56130a1c) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,283 [Sink: Unnamed (1/4)] INFO  (Task.java:958) - Sink: Unnamed (1/4) (c102f99f2882a02c4a35da5a763157cf) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,284 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Unnamed (3/4) (aff2af1a468512bd871670aa56130a1c) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,284 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Unnamed (1/4) (c102f99f2882a02c4a35da5a763157cf) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,285 [Sink: Unnamed (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-25 03:40:55,284 [Sink: Unnamed (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-25 03:40:55,287 [flink-akka.actor.default-dispatcher-3] INFO  (TaskSlotTable.java:242) - Activate slot 0450b587e4a5837a77973d27ab847afd.
2020-02-25 03:40:55,287 [flink-akka.actor.default-dispatcher-3] INFO  (TaskSlotTable.java:242) - Activate slot 3c509e2f59dd63d3370aa8dc68174cab.
2020-02-25 03:40:55,287 [flink-akka.actor.default-dispatcher-3] INFO  (TaskSlotTable.java:242) - Activate slot 990810697687848e14d2ca7d85f6fc1d.
2020-02-25 03:40:55,287 [flink-akka.actor.default-dispatcher-3] INFO  (TaskSlotTable.java:242) - Activate slot e7b1a3d7d1c02bba91b67c06b07eb184.
2020-02-25 03:40:55,288 [Sink: Unnamed (3/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-25 03:40:55,288 [Sink: Unnamed (3/4)] WARN  (FlinkKafkaProducer.java:998) - Using EXACTLY_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-02-25 03:40:55,289 [Sink: Unnamed (3/4)] INFO  (TwoPhaseCommitSinkFunction.java:366) - FlinkKafkaProducer 2/4 - no state to restore
2020-02-25 03:40:55,287 [Sink: Unnamed (1/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-25 03:40:55,293 [Sink: Unnamed (1/4)] WARN  (FlinkKafkaProducer.java:998) - Using EXACTLY_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-02-25 03:40:55,293 [Sink: Unnamed (1/4)] INFO  (TwoPhaseCommitSinkFunction.java:366) - FlinkKafkaProducer 0/4 - no state to restore
2020-02-25 03:40:55,288 [Sink: Unnamed (4/4)] INFO  (Task.java:958) - Sink: Unnamed (4/4) (b492e10edc5a52a0ce555aa5291345f8) switched from CREATED to DEPLOYING.
2020-02-25 03:40:55,287 [Sink: Unnamed (2/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-25 03:40:55,296 [Sink: Unnamed (2/4)] WARN  (FlinkKafkaProducer.java:998) - Using EXACTLY_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-02-25 03:40:55,297 [Sink: Unnamed (2/4)] INFO  (TwoPhaseCommitSinkFunction.java:366) - FlinkKafkaProducer 1/4 - no state to restore
2020-02-25 03:40:55,297 [Sink: Unnamed (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Unnamed (4/4) (b492e10edc5a52a0ce555aa5291345f8) [DEPLOYING]
2020-02-25 03:40:55,297 [Sink: Unnamed (4/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Unnamed (4/4) (b492e10edc5a52a0ce555aa5291345f8) [DEPLOYING].
2020-02-25 03:40:55,297 [Sink: Unnamed (4/4)] INFO  (Task.java:619) - Registering task at network: Sink: Unnamed (4/4) (b492e10edc5a52a0ce555aa5291345f8) [DEPLOYING].
2020-02-25 03:40:55,298 [Sink: Unnamed (4/4)] INFO  (Task.java:958) - Sink: Unnamed (4/4) (b492e10edc5a52a0ce555aa5291345f8) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,298 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Sink: Unnamed (4/4) (b492e10edc5a52a0ce555aa5291345f8) switched from DEPLOYING to RUNNING.
2020-02-25 03:40:55,298 [Sink: Unnamed (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-25 03:40:55,303 [Sink: Unnamed (1/4)] INFO  (AbstractConfig.java:347) - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-02-25 03:40:55,303 [Sink: Unnamed (3/4)] INFO  (AbstractConfig.java:347) - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-02-25 03:40:55,306 [Sink: Unnamed (4/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-25 03:40:55,305 [Sink: Unnamed (2/4)] INFO  (AbstractConfig.java:347) - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-02-25 03:40:55,313 [Sink: Unnamed (4/4)] WARN  (FlinkKafkaProducer.java:998) - Using EXACTLY_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-02-25 03:40:55,313 [Sink: Unnamed (4/4)] INFO  (TwoPhaseCommitSinkFunction.java:366) - FlinkKafkaProducer 3/4 - no state to restore
2020-02-25 03:40:55,313 [Sink: Unnamed (4/4)] INFO  (AbstractConfig.java:347) - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-02-25 03:40:55,386 [Sink: Unnamed (1/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-25 03:40:55,389 [Sink: Unnamed (1/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-25 03:40:55,389 [Sink: Unnamed (1/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582594855381
2020-02-25 03:40:55,391 [Sink: Unnamed (3/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-25 03:40:55,393 [Sink: Unnamed (3/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-25 03:40:55,393 [Sink: Unnamed (3/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582594855383
2020-02-25 03:40:55,396 [Sink: Unnamed (1/4)] INFO  (FlinkKafkaProducer.java:1158) - Starting FlinkKafkaInternalProducer (1/4) to produce into default topic output-topic-job2
2020-02-25 03:40:55,400 [Sink: Unnamed (3/4)] INFO  (FlinkKafkaProducer.java:1158) - Starting FlinkKafkaInternalProducer (3/4) to produce into default topic output-topic-job2
2020-02-25 03:40:55,400 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-25 03:40:55,400 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-25 03:40:55,400 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582594855383
2020-02-25 03:40:55,400 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-25 03:40:55,401 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-25 03:40:55,401 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582594855385
2020-02-25 03:40:55,401 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-25 03:40:55,401 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-25 03:40:55,402 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582594855399
2020-02-25 03:40:55,402 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-25 03:40:55,403 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-25 03:40:55,403 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582594855399
2020-02-25 03:40:55,403 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-25 03:40:55,403 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-25 03:40:55,403 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582594855396
2020-02-25 03:40:55,404 [Sink: Unnamed (4/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-25 03:40:55,404 [Sink: Unnamed (4/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-25 03:40:55,404 [Sink: Unnamed (4/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582594855393
2020-02-25 03:40:55,404 [Sink: Unnamed (4/4)] INFO  (FlinkKafkaProducer.java:1158) - Starting FlinkKafkaInternalProducer (4/4) to produce into default topic output-topic-job2
2020-02-25 03:40:55,405 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-25 03:40:55,405 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-25 03:40:55,405 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582594855405
2020-02-25 03:40:55,406 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-25 03:40:55,406 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-25 03:40:55,407 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582594855406
2020-02-25 03:40:55,407 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-25 03:40:55,408 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-25 03:40:55,408 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582594855407
2020-02-25 03:40:55,409 [Sink: Unnamed (2/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-25 03:40:55,410 [Sink: Unnamed (2/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-25 03:40:55,410 [Sink: Unnamed (2/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582594855409
2020-02-25 03:40:55,410 [Sink: Unnamed (2/4)] INFO  (FlinkKafkaProducer.java:1158) - Starting FlinkKafkaInternalProducer (2/4) to produce into default topic output-topic-job2
2020-02-25 03:40:55,728 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-2, groupId=KafkaCsvProducer] Cluster ID: g54BmaOlTjihW0VeJBBMyQ
2020-02-25 03:40:55,733 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-1, groupId=KafkaCsvProducer] Cluster ID: g54BmaOlTjihW0VeJBBMyQ
2020-02-25 03:40:55,729 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-5, groupId=KafkaCsvProducer] Cluster ID: g54BmaOlTjihW0VeJBBMyQ
2020-02-25 03:40:55,733 [kafka-producer-network-thread | producer-4] INFO  (Metadata.java:261) - [Producer clientId=producer-4] Cluster ID: g54BmaOlTjihW0VeJBBMyQ
2020-02-25 03:40:55,734 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-4, groupId=KafkaCsvProducer] Cluster ID: g54BmaOlTjihW0VeJBBMyQ
2020-02-25 03:40:55,735 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-8, groupId=KafkaCsvProducer] Cluster ID: g54BmaOlTjihW0VeJBBMyQ
2020-02-25 03:40:55,736 [kafka-producer-network-thread | producer-3] INFO  (Metadata.java:261) - [Producer clientId=producer-3] Cluster ID: g54BmaOlTjihW0VeJBBMyQ
2020-02-25 03:40:55,736 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (FlinkKafkaConsumerBase.java:651) - Consumer subtask 0 initially has no partitions to read from.
2020-02-25 03:40:55,737 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (FlinkKafkaConsumerBase.java:604) - Consumer subtask 2 will start reading the following 1 partitions from the earliest offsets: [KafkaTopicPartition{topic='output-topic-job1', partition=0}]
2020-02-25 03:40:55,728 [kafka-producer-network-thread | producer-1] INFO  (Metadata.java:261) - [Producer clientId=producer-1] Cluster ID: g54BmaOlTjihW0VeJBBMyQ
2020-02-25 03:40:55,729 [kafka-producer-network-thread | producer-2] INFO  (Metadata.java:261) - [Producer clientId=producer-2] Cluster ID: g54BmaOlTjihW0VeJBBMyQ
2020-02-25 03:40:55,737 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (FlinkKafkaConsumerBase.java:651) - Consumer subtask 1 initially has no partitions to read from.
2020-02-25 03:40:55,737 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (FlinkKafkaConsumerBase.java:604) - Consumer subtask 0 will start reading the following 1 partitions from the earliest offsets: [KafkaTopicPartition{topic='_input-topic-job1', partition=0}]
2020-02-25 03:40:55,736 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (FlinkKafkaConsumerBase.java:651) - Consumer subtask 2 initially has no partitions to read from.
2020-02-25 03:40:55,733 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-6, groupId=KafkaCsvProducer] Cluster ID: g54BmaOlTjihW0VeJBBMyQ
2020-02-25 03:40:55,733 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-3, groupId=KafkaCsvProducer] Cluster ID: g54BmaOlTjihW0VeJBBMyQ
2020-02-25 03:40:55,740 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (FlinkKafkaConsumerBase.java:651) - Consumer subtask 1 initially has no partitions to read from.
2020-02-25 03:40:55,733 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-7, groupId=KafkaCsvProducer] Cluster ID: g54BmaOlTjihW0VeJBBMyQ
2020-02-25 03:40:55,742 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (FlinkKafkaConsumerBase.java:651) - Consumer subtask 3 initially has no partitions to read from.
2020-02-25 03:40:55,740 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (FlinkKafkaConsumerBase.java:651) - Consumer subtask 3 initially has no partitions to read from.
2020-02-25 03:40:55,764 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 0 creating fetcher with offsets {KafkaTopicPartition{topic='_input-topic-job1', partition=0}=-915623761775}.
2020-02-25 03:40:55,773 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 0 creating fetcher with offsets {}.
2020-02-25 03:40:55,776 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 3 creating fetcher with offsets {}.
2020-02-25 03:40:55,776 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 1 creating fetcher with offsets {}.
2020-02-25 03:40:55,776 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 1 creating fetcher with offsets {}.
2020-02-25 03:40:55,781 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 2 creating fetcher with offsets {KafkaTopicPartition{topic='output-topic-job1', partition=0}=-915623761775}.
2020-02-25 03:40:55,781 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 2 creating fetcher with offsets {}.
2020-02-25 03:40:55,785 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-25 03:40:55,785 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-25 03:40:55,790 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-25 03:40:55,790 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-25 03:40:55,790 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582594855790
2020-02-25 03:40:55,790 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-25 03:40:55,795 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-25 03:40:55,795 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582594855790
2020-02-25 03:40:55,795 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-25 03:40:55,795 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-25 03:40:55,795 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 3 creating fetcher with offsets {}.
2020-02-25 03:40:55,792 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-25 03:40:55,792 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-25 03:40:55,791 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-25 03:40:55,807 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-25 03:40:55,803 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (KafkaConsumer.java:1123) - [Consumer clientId=consumer-KafkaCsvProducer-9, groupId=KafkaCsvProducer] Subscribed to partition(s): _input-topic-job1-0
2020-02-25 03:40:55,799 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-25 03:40:55,818 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-25 03:40:55,821 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582594855799
2020-02-25 03:40:55,821 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-25 03:40:55,821 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-25 03:40:55,821 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582594855820
2020-02-25 03:40:55,823 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-25 03:40:55,828 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-25 03:40:55,828 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582594855811
2020-02-25 03:40:55,828 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-9, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition _input-topic-job1-0
2020-02-25 03:40:55,830 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-25 03:40:55,830 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-25 03:40:55,831 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582594855813
2020-02-25 03:40:55,831 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-25 03:40:55,832 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-25 03:40:55,832 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582594855826
2020-02-25 03:40:55,837 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-25 03:40:55,837 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-25 03:40:55,837 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582594855824
2020-02-25 03:40:55,838 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (KafkaConsumer.java:1123) - [Consumer clientId=consumer-KafkaCsvProducer-12, groupId=KafkaCsvProducer] Subscribed to partition(s): output-topic-job1-0
2020-02-25 03:40:55,840 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-12, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition output-topic-job1-0
2020-02-25 03:40:55,849 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-9, groupId=KafkaCsvProducer] Cluster ID: g54BmaOlTjihW0VeJBBMyQ
2020-02-25 03:40:55,849 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-12, groupId=KafkaCsvProducer] Cluster ID: g54BmaOlTjihW0VeJBBMyQ
2020-02-25 03:40:55,859 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-9, groupId=KafkaCsvProducer] Resetting offset for partition _input-topic-job1-0 to offset 0.
2020-02-25 03:40:55,859 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-12, groupId=KafkaCsvProducer] Resetting offset for partition output-topic-job1-0 to offset 0.
