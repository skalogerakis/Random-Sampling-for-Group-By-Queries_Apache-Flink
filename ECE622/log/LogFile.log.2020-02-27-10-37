2020-02-27 10:37:12,259 [PermanentBlobCache shutdown hook] INFO  (AbstractBlobCache.java:247) - Shutting down BLOB cache
2020-02-27 10:37:12,264 [FileCache shutdown hook] INFO  (FileCache.java:153) - removed file cache directory /tmp/flink-dist-cache-142e92f8-5206-4ac6-af8a-04b24bb6d7d7
2020-02-27 10:37:12,270 [BlobServer shutdown hook] INFO  (BlobServer.java:340) - Stopped BLOB server at 0.0.0.0:45033
2020-02-27 10:37:12,273 [IOManagerAsync shutdown hook] INFO  (FileChannelManagerImpl.java:112) - FileChannelManager removed spill file directory /tmp/flink-io-56dc9d91-ff2d-44f1-a073-6c15603bc1c8
2020-02-27 10:37:12,269 [TransientBlobCache shutdown hook] INFO  (AbstractBlobCache.java:247) - Shutting down BLOB cache
2020-02-27 10:37:12,269 [TaskExecutorLocalStateStoresManager shutdown hook] INFO  (TaskExecutorLocalStateStoresManager.java:213) - Shutting down TaskExecutorLocalStateStoresManager.
2020-02-27 10:37:26,622 [main] WARN  (FlinkKafkaProducer.java:667) - Property [transaction.timeout.ms] not specified. Setting it to 3600000 ms
2020-02-27 10:37:26,765 [main] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.api.datastream.CoGroupedStreams$TaggedUnion does not contain a setter for field one
2020-02-27 10:37:26,766 [main] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.api.datastream.CoGroupedStreams$TaggedUnion cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-27 10:37:26,768 [main] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.api.datastream.CoGroupedStreams$TaggedUnion does not contain a setter for field one
2020-02-27 10:37:26,768 [main] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.api.datastream.CoGroupedStreams$TaggedUnion cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-27 10:37:27,149 [main] INFO  (LocalStreamEnvironment.java:108) - Running job on local embedded Flink mini cluster
2020-02-27 10:37:27,673 [main] INFO  (MiniCluster.java:253) - Starting Flink Mini Cluster
2020-02-27 10:37:27,676 [main] INFO  (MiniCluster.java:262) - Starting Metrics Registry
2020-02-27 10:37:27,746 [main] INFO  (MetricRegistryImpl.java:114) - No metrics reporter configured, no metrics will be exposed/reported.
2020-02-27 10:37:27,747 [main] INFO  (MiniCluster.java:266) - Starting RPC Service(s)
2020-02-27 10:37:28,613 [flink-akka.actor.default-dispatcher-4] INFO  (Slf4jLogger.scala:92) - Slf4jLogger started
2020-02-27 10:37:28,891 [main] INFO  (BootstrapTools.java:244) - Trying to start actor system at :0
2020-02-27 10:37:28,973 [flink-metrics-2] INFO  (Slf4jLogger.scala:92) - Slf4jLogger started
2020-02-27 10:37:29,001 [flink-metrics-2] INFO  (MarkerIgnoringBase.java:107) - Starting remoting
2020-02-27 10:37:29,168 [flink-metrics-2] INFO  (MarkerIgnoringBase.java:107) - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:35957]
2020-02-27 10:37:29,208 [main] INFO  (BootstrapTools.java:256) - Actor system started at akka.tcp://flink-metrics@127.0.1.1:35957
2020-02-27 10:37:29,218 [main] INFO  (AkkaRpcService.java:223) - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-02-27 10:37:29,232 [main] INFO  (MiniCluster.java:397) - Starting high-availability services
2020-02-27 10:37:29,244 [main] INFO  (BlobServer.java:141) - Created BLOB server storage directory /tmp/blobStore-546bc443-2815-4a6c-87b4-fe5811990a54
2020-02-27 10:37:29,250 [main] INFO  (BlobServer.java:203) - Started BLOB server at 0.0.0.0:46375 - max concurrent requests: 50 - max backlog: 1000
2020-02-27 10:37:29,253 [main] INFO  (AbstractBlobCache.java:107) - Created BLOB cache storage directory /tmp/blobStore-955a7eac-fe27-41a6-ae74-668735cbb018
2020-02-27 10:37:29,255 [main] INFO  (AbstractBlobCache.java:107) - Created BLOB cache storage directory /tmp/blobStore-86d83a00-58bb-4ee6-8070-fd9179d156cd
2020-02-27 10:37:29,255 [main] INFO  (MiniCluster.java:479) - Starting 1 TaskManger(s)
2020-02-27 10:37:29,258 [main] INFO  (TaskManagerRunner.java:351) - Starting TaskManager with ResourceID: a2e20270-6ddc-4223-9bd6-b8e48e5f245b
2020-02-27 10:37:29,368 [main] INFO  (TaskManagerServices.java:519) - Temporary file directory '/tmp': total 439 GB, usable 336 GB (76.54% usable)
2020-02-27 10:37:29,371 [main] INFO  (FileChannelManagerImpl.java:76) - FileChannelManager uses directory /tmp/flink-io-10d1affd-1872-4e4d-adef-062ef8f9b699 for spill files.
2020-02-27 10:37:29,378 [main] INFO  (FileChannelManagerImpl.java:76) - FileChannelManager uses directory /tmp/flink-netty-shuffle-1d5850cf-1184-4718-95e0-e49c4460c7a9 for spill files.
2020-02-27 10:37:29,476 [main] INFO  (NetworkBufferPool.java:140) - Allocated 191 MB for network buffer pool (number of memory segments: 6113, bytes per segment: 32768).
2020-02-27 10:37:29,491 [main] INFO  (NettyShuffleEnvironment.java:283) - Starting the network environment and its components.
2020-02-27 10:37:29,492 [main] INFO  (KvStateService.java:89) - Starting the kvState service and its components.
2020-02-27 10:37:29,492 [main] INFO  (TaskManagerServices.java:364) - Limiting managed memory to 0.7 of the currently free heap space (1197 MB), memory will be allocated lazily.
2020-02-27 10:37:29,501 [main] INFO  (TaskManagerConfiguration.java:197) - Messages have a max timeout of 10000 ms
2020-02-27 10:37:29,509 [main] INFO  (AkkaRpcService.java:223) - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-02-27 10:37:29,524 [flink-akka.actor.default-dispatcher-4] INFO  (JobLeaderService.java:125) - Start job leader service.
2020-02-27 10:37:29,526 [flink-akka.actor.default-dispatcher-4] INFO  (FileCache.java:107) - User file cache uses directory /tmp/flink-dist-cache-aef1efbf-db00-47ef-95e2-f0ae68b56282
2020-02-27 10:37:29,573 [main] INFO  (RestServerEndpoint.java:136) - Starting rest endpoint.
2020-02-27 10:37:29,643 [main] WARN  (WebMonitorUtils.java:87) - Log file environment variable 'log.file' is not set.
2020-02-27 10:37:29,643 [main] WARN  (WebMonitorUtils.java:93) - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-02-27 10:37:29,653 [main] INFO  (DispatcherRestEndpoint.java:113) - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-02-27 10:37:29,830 [main] INFO  (RestServerEndpoint.java:233) - Rest endpoint listening at localhost:44537
2020-02-27 10:37:29,832 [main] INFO  (EmbeddedLeaderService.java:300) - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@10ee04df @ http://localhost:44537
2020-02-27 10:37:29,838 [mini-cluster-io-thread-1] INFO  (WebMonitorEndpoint.java:712) - http://localhost:44537 was granted leadership with leaderSessionID=daac30b5-bd69-4339-a898-50f7106a23a2
2020-02-27 10:37:29,838 [mini-cluster-io-thread-1] INFO  (EmbeddedLeaderService.java:250) - Received confirmation of leadership for leader http://localhost:44537 , session=daac30b5-bd69-4339-a898-50f7106a23a2
2020-02-27 10:37:29,855 [main] INFO  (AkkaRpcService.java:223) - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-02-27 10:37:29,875 [main] INFO  (AkkaRpcService.java:223) - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-02-27 10:37:29,887 [flink-akka.actor.default-dispatcher-4] INFO  (EmbeddedLeaderService.java:300) - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@28eb5fd2 @ akka://flink/user/resourcemanager
2020-02-27 10:37:29,893 [flink-akka.actor.default-dispatcher-4] INFO  (EmbeddedLeaderService.java:300) - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@772bb707 @ akka://flink/user/dispatcher
2020-02-27 10:37:29,894 [flink-akka.actor.default-dispatcher-3] INFO  (ResourceManager.java:925) - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 830e0a65ba226f203f243466ab5e40c3
2020-02-27 10:37:29,896 [flink-akka.actor.default-dispatcher-4] INFO  (Dispatcher.java:884) - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token c633160d-8a1e-48d6-8450-4f5e062b108c
2020-02-27 10:37:29,898 [flink-akka.actor.default-dispatcher-3] INFO  (SlotManagerImpl.java:219) - Starting the SlotManager.
2020-02-27 10:37:29,900 [flink-akka.actor.default-dispatcher-2] INFO  (Dispatcher.java:716) - Recovering all persisted jobs.
2020-02-27 10:37:29,903 [flink-akka.actor.default-dispatcher-2] INFO  (EmbeddedLeaderService.java:250) - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=c633160d-8a1e-48d6-8450-4f5e062b108c
2020-02-27 10:37:29,918 [main] INFO  (MiniCluster.java:362) - Flink Mini Cluster started successfully
2020-02-27 10:37:29,918 [flink-akka.actor.default-dispatcher-4] INFO  (EmbeddedLeaderService.java:250) - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=3f243466-ab5e-40c3-830e-0a65ba226f20
2020-02-27 10:37:29,932 [flink-akka.actor.default-dispatcher-4] INFO  (TaskExecutor.java:991) - Connecting to ResourceManager akka://flink/user/resourcemanager(830e0a65ba226f203f243466ab5e40c3).
2020-02-27 10:37:29,941 [flink-akka.actor.default-dispatcher-5] INFO  (RetryingRegistration.java:155) - Resolved ResourceManager address, beginning registration
2020-02-27 10:37:29,942 [flink-akka.actor.default-dispatcher-5] INFO  (RetryingRegistration.java:204) - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-02-27 10:37:29,946 [flink-akka.actor.default-dispatcher-5] INFO  (Dispatcher.java:264) - Received JobGraph submission eb6f3e9b3817d4cd40fff7f8c87555d9 (SecondAlgorithmPass).
2020-02-27 10:37:29,947 [flink-akka.actor.default-dispatcher-5] INFO  (Dispatcher.java:321) - Submitting job eb6f3e9b3817d4cd40fff7f8c87555d9 (SecondAlgorithmPass).
2020-02-27 10:37:29,953 [flink-akka.actor.default-dispatcher-4] INFO  (ResourceManager.java:717) - Registering TaskManager with ResourceID a2e20270-6ddc-4223-9bd6-b8e48e5f245b (akka://flink/user/taskmanager_0) at ResourceManager
2020-02-27 10:37:29,957 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutorToResourceManagerConnection.java:100) - Successful registration at resource manager akka://flink/user/resourcemanager under registration id 109e952d2b7d79619c09676e86813d1a.
2020-02-27 10:37:29,992 [flink-akka.actor.default-dispatcher-2] INFO  (AkkaRpcService.java:223) - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-02-27 10:37:30,003 [flink-akka.actor.default-dispatcher-2] INFO  (JobMaster.java:242) - Initializing job SecondAlgorithmPass (eb6f3e9b3817d4cd40fff7f8c87555d9).
2020-02-27 10:37:30,025 [flink-akka.actor.default-dispatcher-2] INFO  (LegacyScheduler.java:171) - Using restart strategy NoRestartStrategy for SecondAlgorithmPass (eb6f3e9b3817d4cd40fff7f8c87555d9).
2020-02-27 10:37:30,046 [flink-akka.actor.default-dispatcher-2] INFO  (ExecutionGraph.java:519) - Job recovers via failover strategy: full graph restart
2020-02-27 10:37:30,063 [flink-akka.actor.default-dispatcher-2] INFO  (ExecutionGraphBuilder.java:204) - Running initialization on master for job SecondAlgorithmPass (eb6f3e9b3817d4cd40fff7f8c87555d9).
2020-02-27 10:37:30,063 [flink-akka.actor.default-dispatcher-2] INFO  (ExecutionGraphBuilder.java:222) - Successfully ran initialization on master in 0 ms.
2020-02-27 10:37:30,112 [flink-akka.actor.default-dispatcher-2] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-27 10:37:30,128 [flink-akka.actor.default-dispatcher-2] INFO  (EmbeddedLeaderService.java:300) - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@3c84580a @ akka://flink/user/jobmanager_1
2020-02-27 10:37:30,129 [mini-cluster-io-thread-2] INFO  (JobManagerRunner.java:313) - JobManager runner for job SecondAlgorithmPass (eb6f3e9b3817d4cd40fff7f8c87555d9) was granted leadership with session id 6f258f08-8892-47b4-ab29-61b49aa822ad at akka://flink/user/jobmanager_1.
2020-02-27 10:37:30,135 [flink-akka.actor.default-dispatcher-5] INFO  (JobMaster.java:712) - Starting execution of job SecondAlgorithmPass (eb6f3e9b3817d4cd40fff7f8c87555d9) under job master id ab2961b49aa822ad6f258f08889247b4.
2020-02-27 10:37:30,137 [flink-akka.actor.default-dispatcher-5] INFO  (ExecutionGraph.java:1325) - Job SecondAlgorithmPass (eb6f3e9b3817d4cd40fff7f8c87555d9) switched from state CREATED to RUNNING.
2020-02-27 10:37:30,143 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (1/4) (54d69e75180049ae091c2a3d7f7e7ab5) switched from CREATED to SCHEDULED.
2020-02-27 10:37:30,161 [flink-akka.actor.default-dispatcher-5] INFO  (SlotPoolImpl.java:369) - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{51f835b022e8f273da0c03bdeb6d566b}]
2020-02-27 10:37:30,171 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (2/4) (b52aa2a95b109c1962fe8a294fc6a431) switched from CREATED to SCHEDULED.
2020-02-27 10:37:30,172 [flink-akka.actor.default-dispatcher-5] INFO  (SlotPoolImpl.java:369) - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{adf8d3262ea731b29457cd9188128ad7}]
2020-02-27 10:37:30,172 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (3/4) (84fc7a8d28b51e32ee481ccc05c443f6) switched from CREATED to SCHEDULED.
2020-02-27 10:37:30,173 [flink-akka.actor.default-dispatcher-5] INFO  (SlotPoolImpl.java:369) - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{b9b9ab78e67bd5f9eb2d5835cfa70eee}]
2020-02-27 10:37:30,173 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (4/4) (0211f3c95da77ce095d93ee28114c0d5) switched from CREATED to SCHEDULED.
2020-02-27 10:37:30,174 [flink-akka.actor.default-dispatcher-5] INFO  (SlotPoolImpl.java:369) - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{90232966a2ef5293187a576cc8afa7f4}]
2020-02-27 10:37:30,174 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (1/4) (da188a39a41326b245c029eccc1bc69c) switched from CREATED to SCHEDULED.
2020-02-27 10:37:30,175 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (2/4) (dfa09b3d8eec12ce7276f686bccb30d8) switched from CREATED to SCHEDULED.
2020-02-27 10:37:30,175 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (3/4) (3092ed8e27a60a6736b6717f3c48a3f9) switched from CREATED to SCHEDULED.
2020-02-27 10:37:30,176 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (4/4) (ddb8289b42d93b5add519973ff1573b9) switched from CREATED to SCHEDULED.
2020-02-27 10:37:30,176 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (1/4) (9948b706e704a8a3091285597333c792) switched from CREATED to SCHEDULED.
2020-02-27 10:37:30,178 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (2/4) (d1a6792711fe2ae6dbdd9af64b1bcf43) switched from CREATED to SCHEDULED.
2020-02-27 10:37:30,178 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (3/4) (c5aa47884f3200e741951566c973074f) switched from CREATED to SCHEDULED.
2020-02-27 10:37:30,179 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (4/4) (a32f4566f313f012d876db9abdb78d7d) switched from CREATED to SCHEDULED.
2020-02-27 10:37:30,179 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - KeyedProcess (1/4) (bc951382e25e4b75c9458a041e3c652f) switched from CREATED to SCHEDULED.
2020-02-27 10:37:30,180 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - KeyedProcess (2/4) (22cfa17a278058ca215f6412f4bb401a) switched from CREATED to SCHEDULED.
2020-02-27 10:37:30,180 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - KeyedProcess (3/4) (9035dee9b4429ecee727777407f341a7) switched from CREATED to SCHEDULED.
2020-02-27 10:37:30,180 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - KeyedProcess (4/4) (68592e4cd36ced623c2e549aeb8c0c6d) switched from CREATED to SCHEDULED.
2020-02-27 10:37:30,181 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Print to Std. Out (1/4) (f690ac5d7274df33bedb96a7f6f2a0e2) switched from CREATED to SCHEDULED.
2020-02-27 10:37:30,181 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Print to Std. Out (2/4) (c98de38b5a29db19942025eb48a612a3) switched from CREATED to SCHEDULED.
2020-02-27 10:37:30,182 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Print to Std. Out (3/4) (255fd14ca27128be12041880b392cf40) switched from CREATED to SCHEDULED.
2020-02-27 10:37:30,182 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Print to Std. Out (4/4) (3b5c2f8be35cd85a5827504c68b13ec5) switched from CREATED to SCHEDULED.
2020-02-27 10:37:30,182 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Unnamed (1/4) (f509009b0b49919eb4836a08d8d4873f) switched from CREATED to SCHEDULED.
2020-02-27 10:37:30,183 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Unnamed (2/4) (927e666431cfecd3af7509a064a3847e) switched from CREATED to SCHEDULED.
2020-02-27 10:37:30,183 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Unnamed (3/4) (a6b238e3380fba43761d17be21c2f81b) switched from CREATED to SCHEDULED.
2020-02-27 10:37:30,183 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Unnamed (4/4) (ad420fd81e5ddbd7621fc49fb72435bc) switched from CREATED to SCHEDULED.
2020-02-27 10:37:30,184 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Flat Map -> Sink: Print to Std. Out (1/4) (4d67b3b7dcc39501e7d0643267dbcf96) switched from CREATED to SCHEDULED.
2020-02-27 10:37:30,184 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Flat Map -> Sink: Print to Std. Out (2/4) (580f29e3b94874dccd36775878180733) switched from CREATED to SCHEDULED.
2020-02-27 10:37:30,184 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Flat Map -> Sink: Print to Std. Out (3/4) (1ac4d01d6aee3e9056497689d3070675) switched from CREATED to SCHEDULED.
2020-02-27 10:37:30,185 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Flat Map -> Sink: Print to Std. Out (4/4) (e1a53b3654d873fb028631a626f924da) switched from CREATED to SCHEDULED.
2020-02-27 10:37:30,187 [jobmanager-future-thread-1] INFO  (EmbeddedLeaderService.java:250) - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=6f258f08-8892-47b4-ab29-61b49aa822ad
2020-02-27 10:37:30,192 [flink-akka.actor.default-dispatcher-5] INFO  (JobMaster.java:936) - Connecting to ResourceManager akka://flink/user/resourcemanager(830e0a65ba226f203f243466ab5e40c3)
2020-02-27 10:37:30,195 [flink-akka.actor.default-dispatcher-4] INFO  (RetryingRegistration.java:155) - Resolved ResourceManager address, beginning registration
2020-02-27 10:37:30,195 [flink-akka.actor.default-dispatcher-4] INFO  (RetryingRegistration.java:204) - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-02-27 10:37:30,198 [flink-akka.actor.default-dispatcher-5] INFO  (ResourceManager.java:306) - Registering job manager ab2961b49aa822ad6f258f08889247b4@akka://flink/user/jobmanager_1 for job eb6f3e9b3817d4cd40fff7f8c87555d9.
2020-02-27 10:37:30,208 [flink-akka.actor.default-dispatcher-5] INFO  (ResourceManager.java:661) - Registered job manager ab2961b49aa822ad6f258f08889247b4@akka://flink/user/jobmanager_1 for job eb6f3e9b3817d4cd40fff7f8c87555d9.
2020-02-27 10:37:30,211 [flink-akka.actor.default-dispatcher-5] INFO  (JobMaster.java:958) - JobManager successfully registered at ResourceManager, leader id: 830e0a65ba226f203f243466ab5e40c3.
2020-02-27 10:37:30,212 [flink-akka.actor.default-dispatcher-5] INFO  (SlotPoolImpl.java:319) - Requesting new slot [SlotRequestId{51f835b022e8f273da0c03bdeb6d566b}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-02-27 10:37:30,214 [flink-akka.actor.default-dispatcher-4] INFO  (ResourceManager.java:441) - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job eb6f3e9b3817d4cd40fff7f8c87555d9 with allocation id eb069f5cc6b3e3069670e0cabb0d47b7.
2020-02-27 10:37:30,216 [flink-akka.actor.default-dispatcher-5] INFO  (SlotPoolImpl.java:319) - Requesting new slot [SlotRequestId{adf8d3262ea731b29457cd9188128ad7}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-02-27 10:37:30,217 [flink-akka.actor.default-dispatcher-5] INFO  (SlotPoolImpl.java:319) - Requesting new slot [SlotRequestId{b9b9ab78e67bd5f9eb2d5835cfa70eee}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-02-27 10:37:30,217 [flink-akka.actor.default-dispatcher-5] INFO  (SlotPoolImpl.java:319) - Requesting new slot [SlotRequestId{90232966a2ef5293187a576cc8afa7f4}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-02-27 10:37:30,219 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:822) - Receive slot request eb069f5cc6b3e3069670e0cabb0d47b7 for job eb6f3e9b3817d4cd40fff7f8c87555d9 from resource manager with leader id 830e0a65ba226f203f243466ab5e40c3.
2020-02-27 10:37:30,221 [flink-akka.actor.default-dispatcher-4] INFO  (ResourceManager.java:441) - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job eb6f3e9b3817d4cd40fff7f8c87555d9 with allocation id 46ffea9e354e8da5e628b5cd1f31d4cf.
2020-02-27 10:37:30,222 [flink-akka.actor.default-dispatcher-4] INFO  (ResourceManager.java:441) - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job eb6f3e9b3817d4cd40fff7f8c87555d9 with allocation id fa232fd08db6b6960a3e2ac59ae6c693.
2020-02-27 10:37:30,223 [flink-akka.actor.default-dispatcher-4] INFO  (ResourceManager.java:441) - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job eb6f3e9b3817d4cd40fff7f8c87555d9 with allocation id 639a26436ef2f683f46a0c6d4804c62d.
2020-02-27 10:37:30,226 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:834) - Allocated slot for eb069f5cc6b3e3069670e0cabb0d47b7.
2020-02-27 10:37:30,226 [flink-akka.actor.default-dispatcher-5] INFO  (JobLeaderService.java:193) - Add job eb6f3e9b3817d4cd40fff7f8c87555d9 for job leader monitoring.
2020-02-27 10:37:30,228 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:822) - Receive slot request 46ffea9e354e8da5e628b5cd1f31d4cf for job eb6f3e9b3817d4cd40fff7f8c87555d9 from resource manager with leader id 830e0a65ba226f203f243466ab5e40c3.
2020-02-27 10:37:30,228 [mini-cluster-io-thread-4] INFO  (JobLeaderService.java:333) - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 6f258f08-8892-47b4-ab29-61b49aa822ad.
2020-02-27 10:37:30,228 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:834) - Allocated slot for 46ffea9e354e8da5e628b5cd1f31d4cf.
2020-02-27 10:37:30,229 [flink-akka.actor.default-dispatcher-5] INFO  (JobLeaderService.java:193) - Add job eb6f3e9b3817d4cd40fff7f8c87555d9 for job leader monitoring.
2020-02-27 10:37:30,230 [flink-akka.actor.default-dispatcher-3] INFO  (RetryingRegistration.java:155) - Resolved JobManager address, beginning registration
2020-02-27 10:37:30,230 [mini-cluster-io-thread-2] INFO  (JobLeaderService.java:333) - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 6f258f08-8892-47b4-ab29-61b49aa822ad.
2020-02-27 10:37:30,232 [flink-akka.actor.default-dispatcher-2] INFO  (RetryingRegistration.java:155) - Resolved JobManager address, beginning registration
2020-02-27 10:37:30,232 [flink-akka.actor.default-dispatcher-2] INFO  (RetryingRegistration.java:204) - Registration at JobManager attempt 1 (timeout=100ms)
2020-02-27 10:37:30,232 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:822) - Receive slot request fa232fd08db6b6960a3e2ac59ae6c693 for job eb6f3e9b3817d4cd40fff7f8c87555d9 from resource manager with leader id 830e0a65ba226f203f243466ab5e40c3.
2020-02-27 10:37:30,234 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:834) - Allocated slot for fa232fd08db6b6960a3e2ac59ae6c693.
2020-02-27 10:37:30,234 [flink-akka.actor.default-dispatcher-5] INFO  (JobLeaderService.java:193) - Add job eb6f3e9b3817d4cd40fff7f8c87555d9 for job leader monitoring.
2020-02-27 10:37:30,235 [mini-cluster-io-thread-3] INFO  (JobLeaderService.java:333) - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 6f258f08-8892-47b4-ab29-61b49aa822ad.
2020-02-27 10:37:30,236 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:822) - Receive slot request 639a26436ef2f683f46a0c6d4804c62d for job eb6f3e9b3817d4cd40fff7f8c87555d9 from resource manager with leader id 830e0a65ba226f203f243466ab5e40c3.
2020-02-27 10:37:30,236 [flink-akka.actor.default-dispatcher-4] INFO  (RetryingRegistration.java:155) - Resolved JobManager address, beginning registration
2020-02-27 10:37:30,236 [flink-akka.actor.default-dispatcher-4] INFO  (RetryingRegistration.java:204) - Registration at JobManager attempt 1 (timeout=100ms)
2020-02-27 10:37:30,238 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:834) - Allocated slot for 639a26436ef2f683f46a0c6d4804c62d.
2020-02-27 10:37:30,238 [flink-akka.actor.default-dispatcher-5] INFO  (JobLeaderService.java:193) - Add job eb6f3e9b3817d4cd40fff7f8c87555d9 for job leader monitoring.
2020-02-27 10:37:30,238 [mini-cluster-io-thread-1] INFO  (JobLeaderService.java:333) - Try to register at job manager akka://flink/user/jobmanager_1 with leader id 6f258f08-8892-47b4-ab29-61b49aa822ad.
2020-02-27 10:37:30,239 [flink-akka.actor.default-dispatcher-3] INFO  (RetryingRegistration.java:155) - Resolved JobManager address, beginning registration
2020-02-27 10:37:30,240 [flink-akka.actor.default-dispatcher-3] INFO  (RetryingRegistration.java:204) - Registration at JobManager attempt 1 (timeout=100ms)
2020-02-27 10:37:30,242 [flink-akka.actor.default-dispatcher-4] INFO  (JobLeaderService.java:382) - Successful registration at job manager akka://flink/user/jobmanager_1 for job eb6f3e9b3817d4cd40fff7f8c87555d9.
2020-02-27 10:37:30,243 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:1227) - Establish JobManager connection for job eb6f3e9b3817d4cd40fff7f8c87555d9.
2020-02-27 10:37:30,246 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:1128) - Offer reserved slots to the leader of job eb6f3e9b3817d4cd40fff7f8c87555d9.
2020-02-27 10:37:30,264 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (1/4) (54d69e75180049ae091c2a3d7f7e7ab5) switched from SCHEDULED to DEPLOYING.
2020-02-27 10:37:30,264 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Map (1/4) (attempt #0) to a2e20270-6ddc-4223-9bd6-b8e48e5f245b @ localhost (dataPort=-1)
2020-02-27 10:37:30,270 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (2/4) (b52aa2a95b109c1962fe8a294fc6a431) switched from SCHEDULED to DEPLOYING.
2020-02-27 10:37:30,270 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Map (2/4) (attempt #0) to a2e20270-6ddc-4223-9bd6-b8e48e5f245b @ localhost (dataPort=-1)
2020-02-27 10:37:30,271 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (3/4) (84fc7a8d28b51e32ee481ccc05c443f6) switched from SCHEDULED to DEPLOYING.
2020-02-27 10:37:30,271 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Map (3/4) (attempt #0) to a2e20270-6ddc-4223-9bd6-b8e48e5f245b @ localhost (dataPort=-1)
2020-02-27 10:37:30,274 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (4/4) (0211f3c95da77ce095d93ee28114c0d5) switched from SCHEDULED to DEPLOYING.
2020-02-27 10:37:30,274 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Map (4/4) (attempt #0) to a2e20270-6ddc-4223-9bd6-b8e48e5f245b @ localhost (dataPort=-1)
2020-02-27 10:37:30,275 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (1/4) (da188a39a41326b245c029eccc1bc69c) switched from SCHEDULED to DEPLOYING.
2020-02-27 10:37:30,275 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Map (1/4) (attempt #0) to a2e20270-6ddc-4223-9bd6-b8e48e5f245b @ localhost (dataPort=-1)
2020-02-27 10:37:30,276 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (2/4) (dfa09b3d8eec12ce7276f686bccb30d8) switched from SCHEDULED to DEPLOYING.
2020-02-27 10:37:30,276 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Map (2/4) (attempt #0) to a2e20270-6ddc-4223-9bd6-b8e48e5f245b @ localhost (dataPort=-1)
2020-02-27 10:37:30,277 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (3/4) (3092ed8e27a60a6736b6717f3c48a3f9) switched from SCHEDULED to DEPLOYING.
2020-02-27 10:37:30,277 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Map (3/4) (attempt #0) to a2e20270-6ddc-4223-9bd6-b8e48e5f245b @ localhost (dataPort=-1)
2020-02-27 10:37:30,278 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (4/4) (ddb8289b42d93b5add519973ff1573b9) switched from SCHEDULED to DEPLOYING.
2020-02-27 10:37:30,279 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Map (4/4) (attempt #0) to a2e20270-6ddc-4223-9bd6-b8e48e5f245b @ localhost (dataPort=-1)
2020-02-27 10:37:30,279 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (1/4) (9948b706e704a8a3091285597333c792) switched from SCHEDULED to DEPLOYING.
2020-02-27 10:37:30,280 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (1/4) (attempt #0) to a2e20270-6ddc-4223-9bd6-b8e48e5f245b @ localhost (dataPort=-1)
2020-02-27 10:37:30,285 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (2/4) (d1a6792711fe2ae6dbdd9af64b1bcf43) switched from SCHEDULED to DEPLOYING.
2020-02-27 10:37:30,285 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (2/4) (attempt #0) to a2e20270-6ddc-4223-9bd6-b8e48e5f245b @ localhost (dataPort=-1)
2020-02-27 10:37:30,286 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (3/4) (c5aa47884f3200e741951566c973074f) switched from SCHEDULED to DEPLOYING.
2020-02-27 10:37:30,286 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (3/4) (attempt #0) to a2e20270-6ddc-4223-9bd6-b8e48e5f245b @ localhost (dataPort=-1)
2020-02-27 10:37:30,287 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (4/4) (a32f4566f313f012d876db9abdb78d7d) switched from SCHEDULED to DEPLOYING.
2020-02-27 10:37:30,287 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (4/4) (attempt #0) to a2e20270-6ddc-4223-9bd6-b8e48e5f245b @ localhost (dataPort=-1)
2020-02-27 10:37:30,287 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - KeyedProcess (1/4) (bc951382e25e4b75c9458a041e3c652f) switched from SCHEDULED to DEPLOYING.
2020-02-27 10:37:30,288 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying KeyedProcess (1/4) (attempt #0) to a2e20270-6ddc-4223-9bd6-b8e48e5f245b @ localhost (dataPort=-1)
2020-02-27 10:37:30,290 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - KeyedProcess (2/4) (22cfa17a278058ca215f6412f4bb401a) switched from SCHEDULED to DEPLOYING.
2020-02-27 10:37:30,291 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying KeyedProcess (2/4) (attempt #0) to a2e20270-6ddc-4223-9bd6-b8e48e5f245b @ localhost (dataPort=-1)
2020-02-27 10:37:30,292 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - KeyedProcess (3/4) (9035dee9b4429ecee727777407f341a7) switched from SCHEDULED to DEPLOYING.
2020-02-27 10:37:30,293 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying KeyedProcess (3/4) (attempt #0) to a2e20270-6ddc-4223-9bd6-b8e48e5f245b @ localhost (dataPort=-1)
2020-02-27 10:37:30,295 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - KeyedProcess (4/4) (68592e4cd36ced623c2e549aeb8c0c6d) switched from SCHEDULED to DEPLOYING.
2020-02-27 10:37:30,295 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying KeyedProcess (4/4) (attempt #0) to a2e20270-6ddc-4223-9bd6-b8e48e5f245b @ localhost (dataPort=-1)
2020-02-27 10:37:30,296 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Sink: Print to Std. Out (1/4) (f690ac5d7274df33bedb96a7f6f2a0e2) switched from SCHEDULED to DEPLOYING.
2020-02-27 10:37:30,296 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Sink: Print to Std. Out (1/4) (attempt #0) to a2e20270-6ddc-4223-9bd6-b8e48e5f245b @ localhost (dataPort=-1)
2020-02-27 10:37:30,297 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Sink: Print to Std. Out (2/4) (c98de38b5a29db19942025eb48a612a3) switched from SCHEDULED to DEPLOYING.
2020-02-27 10:37:30,298 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Sink: Print to Std. Out (2/4) (attempt #0) to a2e20270-6ddc-4223-9bd6-b8e48e5f245b @ localhost (dataPort=-1)
2020-02-27 10:37:30,300 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Sink: Print to Std. Out (3/4) (255fd14ca27128be12041880b392cf40) switched from SCHEDULED to DEPLOYING.
2020-02-27 10:37:30,300 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Sink: Print to Std. Out (3/4) (attempt #0) to a2e20270-6ddc-4223-9bd6-b8e48e5f245b @ localhost (dataPort=-1)
2020-02-27 10:37:30,300 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Sink: Print to Std. Out (4/4) (3b5c2f8be35cd85a5827504c68b13ec5) switched from SCHEDULED to DEPLOYING.
2020-02-27 10:37:30,301 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Sink: Print to Std. Out (4/4) (attempt #0) to a2e20270-6ddc-4223-9bd6-b8e48e5f245b @ localhost (dataPort=-1)
2020-02-27 10:37:30,301 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Sink: Unnamed (1/4) (f509009b0b49919eb4836a08d8d4873f) switched from SCHEDULED to DEPLOYING.
2020-02-27 10:37:30,302 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Sink: Unnamed (1/4) (attempt #0) to a2e20270-6ddc-4223-9bd6-b8e48e5f245b @ localhost (dataPort=-1)
2020-02-27 10:37:30,303 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Sink: Unnamed (2/4) (927e666431cfecd3af7509a064a3847e) switched from SCHEDULED to DEPLOYING.
2020-02-27 10:37:30,304 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Sink: Unnamed (2/4) (attempt #0) to a2e20270-6ddc-4223-9bd6-b8e48e5f245b @ localhost (dataPort=-1)
2020-02-27 10:37:30,304 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Sink: Unnamed (3/4) (a6b238e3380fba43761d17be21c2f81b) switched from SCHEDULED to DEPLOYING.
2020-02-27 10:37:30,305 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Sink: Unnamed (3/4) (attempt #0) to a2e20270-6ddc-4223-9bd6-b8e48e5f245b @ localhost (dataPort=-1)
2020-02-27 10:37:30,305 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Sink: Unnamed (4/4) (ad420fd81e5ddbd7621fc49fb72435bc) switched from SCHEDULED to DEPLOYING.
2020-02-27 10:37:30,305 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Sink: Unnamed (4/4) (attempt #0) to a2e20270-6ddc-4223-9bd6-b8e48e5f245b @ localhost (dataPort=-1)
2020-02-27 10:37:30,306 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Flat Map -> Sink: Print to Std. Out (1/4) (4d67b3b7dcc39501e7d0643267dbcf96) switched from SCHEDULED to DEPLOYING.
2020-02-27 10:37:30,306 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Flat Map -> Sink: Print to Std. Out (1/4) (attempt #0) to a2e20270-6ddc-4223-9bd6-b8e48e5f245b @ localhost (dataPort=-1)
2020-02-27 10:37:30,307 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Flat Map -> Sink: Print to Std. Out (2/4) (580f29e3b94874dccd36775878180733) switched from SCHEDULED to DEPLOYING.
2020-02-27 10:37:30,308 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Flat Map -> Sink: Print to Std. Out (2/4) (attempt #0) to a2e20270-6ddc-4223-9bd6-b8e48e5f245b @ localhost (dataPort=-1)
2020-02-27 10:37:30,308 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Flat Map -> Sink: Print to Std. Out (3/4) (1ac4d01d6aee3e9056497689d3070675) switched from SCHEDULED to DEPLOYING.
2020-02-27 10:37:30,309 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Flat Map -> Sink: Print to Std. Out (3/4) (attempt #0) to a2e20270-6ddc-4223-9bd6-b8e48e5f245b @ localhost (dataPort=-1)
2020-02-27 10:37:30,309 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Flat Map -> Sink: Print to Std. Out (4/4) (e1a53b3654d873fb028631a626f924da) switched from SCHEDULED to DEPLOYING.
2020-02-27 10:37:30,310 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Flat Map -> Sink: Print to Std. Out (4/4) (attempt #0) to a2e20270-6ddc-4223-9bd6-b8e48e5f245b @ localhost (dataPort=-1)
2020-02-27 10:37:30,324 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Map (1/4).
2020-02-27 10:37:30,325 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (1/4) (54d69e75180049ae091c2a3d7f7e7ab5) switched from CREATED to DEPLOYING.
2020-02-27 10:37:30,325 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Map (1/4) (54d69e75180049ae091c2a3d7f7e7ab5) [DEPLOYING]
2020-02-27 10:37:30,336 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Map (1/4) (54d69e75180049ae091c2a3d7f7e7ab5) [DEPLOYING].
2020-02-27 10:37:30,336 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Map (2/4).
2020-02-27 10:37:30,337 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Map (1/4) (54d69e75180049ae091c2a3d7f7e7ab5) [DEPLOYING].
2020-02-27 10:37:30,341 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Map (3/4).
2020-02-27 10:37:30,343 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (2/4) (b52aa2a95b109c1962fe8a294fc6a431) switched from CREATED to DEPLOYING.
2020-02-27 10:37:30,346 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Map (2/4) (b52aa2a95b109c1962fe8a294fc6a431) [DEPLOYING]
2020-02-27 10:37:30,348 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Map (2/4) (b52aa2a95b109c1962fe8a294fc6a431) [DEPLOYING].
2020-02-27 10:37:30,351 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Map (2/4) (b52aa2a95b109c1962fe8a294fc6a431) [DEPLOYING].
2020-02-27 10:37:30,351 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (3/4) (84fc7a8d28b51e32ee481ccc05c443f6) switched from CREATED to DEPLOYING.
2020-02-27 10:37:30,351 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Map (3/4) (84fc7a8d28b51e32ee481ccc05c443f6) [DEPLOYING]
2020-02-27 10:37:30,351 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Map (3/4) (84fc7a8d28b51e32ee481ccc05c443f6) [DEPLOYING].
2020-02-27 10:37:30,352 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Map (3/4) (84fc7a8d28b51e32ee481ccc05c443f6) [DEPLOYING].
2020-02-27 10:37:30,357 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Map (4/4).
2020-02-27 10:37:30,371 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (4/4) (0211f3c95da77ce095d93ee28114c0d5) switched from CREATED to DEPLOYING.
2020-02-27 10:37:30,372 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Map (1/4).
2020-02-27 10:37:30,372 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Map (4/4) (0211f3c95da77ce095d93ee28114c0d5) [DEPLOYING]
2020-02-27 10:37:30,372 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Map (4/4) (0211f3c95da77ce095d93ee28114c0d5) [DEPLOYING].
2020-02-27 10:37:30,375 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Map (4/4) (0211f3c95da77ce095d93ee28114c0d5) [DEPLOYING].
2020-02-27 10:37:30,378 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Map (2/4).
2020-02-27 10:37:30,384 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Map (3/4).
2020-02-27 10:37:30,387 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (2/4) (dfa09b3d8eec12ce7276f686bccb30d8) switched from CREATED to DEPLOYING.
2020-02-27 10:37:30,387 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Map (2/4) (dfa09b3d8eec12ce7276f686bccb30d8) [DEPLOYING]
2020-02-27 10:37:30,387 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Map (2/4) (dfa09b3d8eec12ce7276f686bccb30d8) [DEPLOYING].
2020-02-27 10:37:30,388 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Map (2/4) (dfa09b3d8eec12ce7276f686bccb30d8) [DEPLOYING].
2020-02-27 10:37:30,393 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (1/4) (da188a39a41326b245c029eccc1bc69c) switched from CREATED to DEPLOYING.
2020-02-27 10:37:30,394 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Map (1/4) (da188a39a41326b245c029eccc1bc69c) [DEPLOYING]
2020-02-27 10:37:30,395 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Map (1/4) (da188a39a41326b245c029eccc1bc69c) [DEPLOYING].
2020-02-27 10:37:30,396 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Map (1/4) (da188a39a41326b245c029eccc1bc69c) [DEPLOYING].
2020-02-27 10:37:30,399 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Map (4/4).
2020-02-27 10:37:30,423 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (3/4) (3092ed8e27a60a6736b6717f3c48a3f9) switched from CREATED to DEPLOYING.
2020-02-27 10:37:30,423 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (2/4) (b52aa2a95b109c1962fe8a294fc6a431) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,424 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Map (3/4) (3092ed8e27a60a6736b6717f3c48a3f9) [DEPLOYING]
2020-02-27 10:37:30,424 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Map (3/4) (3092ed8e27a60a6736b6717f3c48a3f9) [DEPLOYING].
2020-02-27 10:37:30,424 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (2/4) (b52aa2a95b109c1962fe8a294fc6a431) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,425 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Map (3/4) (3092ed8e27a60a6736b6717f3c48a3f9) [DEPLOYING].
2020-02-27 10:37:30,425 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-27 10:37:30,426 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (4/4) (ddb8289b42d93b5add519973ff1573b9) switched from CREATED to DEPLOYING.
2020-02-27 10:37:30,426 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Map (4/4) (ddb8289b42d93b5add519973ff1573b9) [DEPLOYING]
2020-02-27 10:37:30,427 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Map (4/4) (ddb8289b42d93b5add519973ff1573b9) [DEPLOYING].
2020-02-27 10:37:30,428 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Map (4/4) (ddb8289b42d93b5add519973ff1573b9) [DEPLOYING].
2020-02-27 10:37:30,429 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (4/4) (0211f3c95da77ce095d93ee28114c0d5) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,429 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (1/4) (da188a39a41326b245c029eccc1bc69c) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,430 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (4/4) (0211f3c95da77ce095d93ee28114c0d5) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,430 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (2/4) (dfa09b3d8eec12ce7276f686bccb30d8) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,430 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (1/4) (da188a39a41326b245c029eccc1bc69c) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,431 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (2/4) (dfa09b3d8eec12ce7276f686bccb30d8) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,437 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (1/4) (54d69e75180049ae091c2a3d7f7e7ab5) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,438 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-27 10:37:30,438 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (1/4) (54d69e75180049ae091c2a3d7f7e7ab5) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,430 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-27 10:37:30,430 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-27 10:37:30,430 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-27 10:37:30,452 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (3/4) (84fc7a8d28b51e32ee481ccc05c443f6) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,452 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-27 10:37:30,451 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (3/4) (3092ed8e27a60a6736b6717f3c48a3f9) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,449 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (1/4).
2020-02-27 10:37:30,453 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-27 10:37:30,452 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (3/4) (84fc7a8d28b51e32ee481ccc05c443f6) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,454 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (3/4) (3092ed8e27a60a6736b6717f3c48a3f9) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,460 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (1/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (1/4) (9948b706e704a8a3091285597333c792) switched from CREATED to DEPLOYING.
2020-02-27 10:37:30,461 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (1/4) (9948b706e704a8a3091285597333c792) [DEPLOYING]
2020-02-27 10:37:30,461 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (1/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (1/4) (9948b706e704a8a3091285597333c792) [DEPLOYING].
2020-02-27 10:37:30,461 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (1/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (1/4) (9948b706e704a8a3091285597333c792) [DEPLOYING].
2020-02-27 10:37:30,463 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Map (4/4) (ddb8289b42d93b5add519973ff1573b9) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,463 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-27 10:37:30,465 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Map (4/4) (ddb8289b42d93b5add519973ff1573b9) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,479 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (1/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (1/4) (9948b706e704a8a3091285597333c792) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,480 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (1/4) (9948b706e704a8a3091285597333c792) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,480 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-27 10:37:30,483 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (2/4).
2020-02-27 10:37:30,495 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (3/4).
2020-02-27 10:37:30,497 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (2/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (2/4) (d1a6792711fe2ae6dbdd9af64b1bcf43) switched from CREATED to DEPLOYING.
2020-02-27 10:37:30,499 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (2/4) (d1a6792711fe2ae6dbdd9af64b1bcf43) [DEPLOYING]
2020-02-27 10:37:30,501 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (2/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (2/4) (d1a6792711fe2ae6dbdd9af64b1bcf43) [DEPLOYING].
2020-02-27 10:37:30,509 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (2/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (2/4) (d1a6792711fe2ae6dbdd9af64b1bcf43) [DEPLOYING].
2020-02-27 10:37:30,509 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (3/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (3/4) (c5aa47884f3200e741951566c973074f) switched from CREATED to DEPLOYING.
2020-02-27 10:37:30,510 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (3/4) (c5aa47884f3200e741951566c973074f) [DEPLOYING]
2020-02-27 10:37:30,510 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (3/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (3/4) (c5aa47884f3200e741951566c973074f) [DEPLOYING].
2020-02-27 10:37:30,510 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (4/4).
2020-02-27 10:37:30,512 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (3/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (3/4) (c5aa47884f3200e741951566c973074f) [DEPLOYING].
2020-02-27 10:37:30,521 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task KeyedProcess (1/4).
2020-02-27 10:37:30,537 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task KeyedProcess (2/4).
2020-02-27 10:37:30,538 [KeyedProcess (1/4)] INFO  (Task.java:958) - KeyedProcess (1/4) (bc951382e25e4b75c9458a041e3c652f) switched from CREATED to DEPLOYING.
2020-02-27 10:37:30,538 [KeyedProcess (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task KeyedProcess (1/4) (bc951382e25e4b75c9458a041e3c652f) [DEPLOYING]
2020-02-27 10:37:30,538 [KeyedProcess (1/4)] INFO  (Task.java:593) - Loading JAR files for task KeyedProcess (1/4) (bc951382e25e4b75c9458a041e3c652f) [DEPLOYING].
2020-02-27 10:37:30,539 [KeyedProcess (1/4)] INFO  (Task.java:619) - Registering task at network: KeyedProcess (1/4) (bc951382e25e4b75c9458a041e3c652f) [DEPLOYING].
2020-02-27 10:37:30,539 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (4/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (4/4) (a32f4566f313f012d876db9abdb78d7d) switched from CREATED to DEPLOYING.
2020-02-27 10:37:30,539 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (4/4) (a32f4566f313f012d876db9abdb78d7d) [DEPLOYING]
2020-02-27 10:37:30,544 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (4/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (4/4) (a32f4566f313f012d876db9abdb78d7d) [DEPLOYING].
2020-02-27 10:37:30,544 [KeyedProcess (2/4)] INFO  (Task.java:958) - KeyedProcess (2/4) (22cfa17a278058ca215f6412f4bb401a) switched from CREATED to DEPLOYING.
2020-02-27 10:37:30,544 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (4/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (4/4) (a32f4566f313f012d876db9abdb78d7d) [DEPLOYING].
2020-02-27 10:37:30,544 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task KeyedProcess (3/4).
2020-02-27 10:37:30,546 [KeyedProcess (3/4)] INFO  (Task.java:958) - KeyedProcess (3/4) (9035dee9b4429ecee727777407f341a7) switched from CREATED to DEPLOYING.
2020-02-27 10:37:30,547 [KeyedProcess (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task KeyedProcess (3/4) (9035dee9b4429ecee727777407f341a7) [DEPLOYING]
2020-02-27 10:37:30,547 [KeyedProcess (3/4)] INFO  (Task.java:593) - Loading JAR files for task KeyedProcess (3/4) (9035dee9b4429ecee727777407f341a7) [DEPLOYING].
2020-02-27 10:37:30,547 [KeyedProcess (3/4)] INFO  (Task.java:619) - Registering task at network: KeyedProcess (3/4) (9035dee9b4429ecee727777407f341a7) [DEPLOYING].
2020-02-27 10:37:30,555 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task KeyedProcess (4/4).
2020-02-27 10:37:30,546 [KeyedProcess (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task KeyedProcess (2/4) (22cfa17a278058ca215f6412f4bb401a) [DEPLOYING]
2020-02-27 10:37:30,555 [KeyedProcess (2/4)] INFO  (Task.java:593) - Loading JAR files for task KeyedProcess (2/4) (22cfa17a278058ca215f6412f4bb401a) [DEPLOYING].
2020-02-27 10:37:30,556 [KeyedProcess (2/4)] INFO  (Task.java:619) - Registering task at network: KeyedProcess (2/4) (22cfa17a278058ca215f6412f4bb401a) [DEPLOYING].
2020-02-27 10:37:30,560 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-27 10:37:30,561 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-27 10:37:30,561 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-27 10:37:30,561 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-27 10:37:30,561 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-27 10:37:30,560 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-27 10:37:30,562 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-27 10:37:30,560 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-27 10:37:30,562 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-27 10:37:30,561 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-27 10:37:30,569 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Sink: Print to Std. Out (1/4).
2020-02-27 10:37:30,572 [KeyedProcess (4/4)] INFO  (Task.java:958) - KeyedProcess (4/4) (68592e4cd36ced623c2e549aeb8c0c6d) switched from CREATED to DEPLOYING.
2020-02-27 10:37:30,572 [KeyedProcess (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task KeyedProcess (4/4) (68592e4cd36ced623c2e549aeb8c0c6d) [DEPLOYING]
2020-02-27 10:37:30,573 [KeyedProcess (4/4)] INFO  (Task.java:593) - Loading JAR files for task KeyedProcess (4/4) (68592e4cd36ced623c2e549aeb8c0c6d) [DEPLOYING].
2020-02-27 10:37:30,578 [KeyedProcess (4/4)] INFO  (Task.java:619) - Registering task at network: KeyedProcess (4/4) (68592e4cd36ced623c2e549aeb8c0c6d) [DEPLOYING].
2020-02-27 10:37:30,579 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Sink: Print to Std. Out (2/4).
2020-02-27 10:37:30,581 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Sink: Print to Std. Out (3/4).
2020-02-27 10:37:30,585 [Sink: Print to Std. Out (1/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (1/4) (f690ac5d7274df33bedb96a7f6f2a0e2) switched from CREATED to DEPLOYING.
2020-02-27 10:37:30,585 [Sink: Print to Std. Out (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (1/4) (f690ac5d7274df33bedb96a7f6f2a0e2) [DEPLOYING]
2020-02-27 10:37:30,585 [Sink: Print to Std. Out (1/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Print to Std. Out (1/4) (f690ac5d7274df33bedb96a7f6f2a0e2) [DEPLOYING].
2020-02-27 10:37:30,586 [Sink: Print to Std. Out (1/4)] INFO  (Task.java:619) - Registering task at network: Sink: Print to Std. Out (1/4) (f690ac5d7274df33bedb96a7f6f2a0e2) [DEPLOYING].
2020-02-27 10:37:30,587 [Sink: Print to Std. Out (2/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (2/4) (c98de38b5a29db19942025eb48a612a3) switched from CREATED to DEPLOYING.
2020-02-27 10:37:30,587 [Sink: Print to Std. Out (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (2/4) (c98de38b5a29db19942025eb48a612a3) [DEPLOYING]
2020-02-27 10:37:30,588 [Sink: Print to Std. Out (2/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Print to Std. Out (2/4) (c98de38b5a29db19942025eb48a612a3) [DEPLOYING].
2020-02-27 10:37:30,588 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 0 has no restore state.
2020-02-27 10:37:30,588 [Sink: Print to Std. Out (2/4)] INFO  (Task.java:619) - Registering task at network: Sink: Print to Std. Out (2/4) (c98de38b5a29db19942025eb48a612a3) [DEPLOYING].
2020-02-27 10:37:30,595 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-27 10:37:30,595 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-27 10:37:30,595 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-27 10:37:30,595 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-27 10:37:30,595 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 3 has no restore state.
2020-02-27 10:37:30,596 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 3 has no restore state.
2020-02-27 10:37:30,596 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Sink: Print to Std. Out (4/4).
2020-02-27 10:37:30,598 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Sink: Unnamed (1/4).
2020-02-27 10:37:30,598 [Sink: Print to Std. Out (4/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (4/4) (3b5c2f8be35cd85a5827504c68b13ec5) switched from CREATED to DEPLOYING.
2020-02-27 10:37:30,599 [Sink: Print to Std. Out (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (4/4) (3b5c2f8be35cd85a5827504c68b13ec5) [DEPLOYING]
2020-02-27 10:37:30,599 [Sink: Print to Std. Out (4/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Print to Std. Out (4/4) (3b5c2f8be35cd85a5827504c68b13ec5) [DEPLOYING].
2020-02-27 10:37:30,599 [Sink: Print to Std. Out (4/4)] INFO  (Task.java:619) - Registering task at network: Sink: Print to Std. Out (4/4) (3b5c2f8be35cd85a5827504c68b13ec5) [DEPLOYING].
2020-02-27 10:37:30,602 [Sink: Print to Std. Out (3/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (3/4) (255fd14ca27128be12041880b392cf40) switched from CREATED to DEPLOYING.
2020-02-27 10:37:30,602 [Sink: Print to Std. Out (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (3/4) (255fd14ca27128be12041880b392cf40) [DEPLOYING]
2020-02-27 10:37:30,602 [Sink: Print to Std. Out (3/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Print to Std. Out (3/4) (255fd14ca27128be12041880b392cf40) [DEPLOYING].
2020-02-27 10:37:30,603 [Sink: Print to Std. Out (3/4)] INFO  (Task.java:619) - Registering task at network: Sink: Print to Std. Out (3/4) (255fd14ca27128be12041880b392cf40) [DEPLOYING].
2020-02-27 10:37:30,603 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Sink: Unnamed (2/4).
2020-02-27 10:37:30,603 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-27 10:37:30,603 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-27 10:37:30,603 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 2 has no restore state.
2020-02-27 10:37:30,604 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 1 has no restore state.
2020-02-27 10:37:30,604 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 1 has no restore state.
2020-02-27 10:37:30,604 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 0 has no restore state.
2020-02-27 10:37:30,604 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 2 has no restore state.
2020-02-27 10:37:30,605 [Sink: Unnamed (1/4)] INFO  (Task.java:958) - Sink: Unnamed (1/4) (f509009b0b49919eb4836a08d8d4873f) switched from CREATED to DEPLOYING.
2020-02-27 10:37:30,605 [Sink: Unnamed (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Unnamed (1/4) (f509009b0b49919eb4836a08d8d4873f) [DEPLOYING]
2020-02-27 10:37:30,605 [Sink: Unnamed (1/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Unnamed (1/4) (f509009b0b49919eb4836a08d8d4873f) [DEPLOYING].
2020-02-27 10:37:30,606 [Sink: Unnamed (1/4)] INFO  (Task.java:619) - Registering task at network: Sink: Unnamed (1/4) (f509009b0b49919eb4836a08d8d4873f) [DEPLOYING].
2020-02-27 10:37:30,610 [Sink: Unnamed (2/4)] INFO  (Task.java:958) - Sink: Unnamed (2/4) (927e666431cfecd3af7509a064a3847e) switched from CREATED to DEPLOYING.
2020-02-27 10:37:30,610 [Sink: Unnamed (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Unnamed (2/4) (927e666431cfecd3af7509a064a3847e) [DEPLOYING]
2020-02-27 10:37:30,610 [Sink: Unnamed (2/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Unnamed (2/4) (927e666431cfecd3af7509a064a3847e) [DEPLOYING].
2020-02-27 10:37:30,611 [Sink: Unnamed (2/4)] INFO  (Task.java:619) - Registering task at network: Sink: Unnamed (2/4) (927e666431cfecd3af7509a064a3847e) [DEPLOYING].
2020-02-27 10:37:30,611 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (2/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (2/4) (d1a6792711fe2ae6dbdd9af64b1bcf43) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,611 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Sink: Unnamed (3/4).
2020-02-27 10:37:30,611 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (2/4) (d1a6792711fe2ae6dbdd9af64b1bcf43) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,611 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-27 10:37:30,615 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (1/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-27 10:37:30,616 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Sink: Unnamed (4/4).
2020-02-27 10:37:30,617 [Sink: Unnamed (3/4)] INFO  (Task.java:958) - Sink: Unnamed (3/4) (a6b238e3380fba43761d17be21c2f81b) switched from CREATED to DEPLOYING.
2020-02-27 10:37:30,618 [Sink: Unnamed (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Unnamed (3/4) (a6b238e3380fba43761d17be21c2f81b) [DEPLOYING]
2020-02-27 10:37:30,619 [Sink: Unnamed (3/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Unnamed (3/4) (a6b238e3380fba43761d17be21c2f81b) [DEPLOYING].
2020-02-27 10:37:30,619 [Sink: Unnamed (3/4)] INFO  (Task.java:619) - Registering task at network: Sink: Unnamed (3/4) (a6b238e3380fba43761d17be21c2f81b) [DEPLOYING].
2020-02-27 10:37:30,620 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Flat Map -> Sink: Print to Std. Out (1/4).
2020-02-27 10:37:30,621 [Sink: Unnamed (4/4)] INFO  (Task.java:958) - Sink: Unnamed (4/4) (ad420fd81e5ddbd7621fc49fb72435bc) switched from CREATED to DEPLOYING.
2020-02-27 10:37:30,621 [Sink: Unnamed (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Unnamed (4/4) (ad420fd81e5ddbd7621fc49fb72435bc) [DEPLOYING]
2020-02-27 10:37:30,621 [Sink: Unnamed (4/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Unnamed (4/4) (ad420fd81e5ddbd7621fc49fb72435bc) [DEPLOYING].
2020-02-27 10:37:30,622 [Sink: Unnamed (4/4)] INFO  (Task.java:619) - Registering task at network: Sink: Unnamed (4/4) (ad420fd81e5ddbd7621fc49fb72435bc) [DEPLOYING].
2020-02-27 10:37:30,624 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Flat Map -> Sink: Print to Std. Out (2/4).
2020-02-27 10:37:30,630 [Flat Map -> Sink: Print to Std. Out (1/4)] INFO  (Task.java:958) - Flat Map -> Sink: Print to Std. Out (1/4) (4d67b3b7dcc39501e7d0643267dbcf96) switched from CREATED to DEPLOYING.
2020-02-27 10:37:30,630 [Flat Map -> Sink: Print to Std. Out (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Flat Map -> Sink: Print to Std. Out (1/4) (4d67b3b7dcc39501e7d0643267dbcf96) [DEPLOYING]
2020-02-27 10:37:30,630 [Flat Map -> Sink: Print to Std. Out (1/4)] INFO  (Task.java:593) - Loading JAR files for task Flat Map -> Sink: Print to Std. Out (1/4) (4d67b3b7dcc39501e7d0643267dbcf96) [DEPLOYING].
2020-02-27 10:37:30,631 [Flat Map -> Sink: Print to Std. Out (1/4)] INFO  (Task.java:619) - Registering task at network: Flat Map -> Sink: Print to Std. Out (1/4) (4d67b3b7dcc39501e7d0643267dbcf96) [DEPLOYING].
2020-02-27 10:37:30,635 [Flat Map -> Sink: Print to Std. Out (2/4)] INFO  (Task.java:958) - Flat Map -> Sink: Print to Std. Out (2/4) (580f29e3b94874dccd36775878180733) switched from CREATED to DEPLOYING.
2020-02-27 10:37:30,636 [Flat Map -> Sink: Print to Std. Out (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Flat Map -> Sink: Print to Std. Out (2/4) (580f29e3b94874dccd36775878180733) [DEPLOYING]
2020-02-27 10:37:30,636 [Flat Map -> Sink: Print to Std. Out (2/4)] INFO  (Task.java:593) - Loading JAR files for task Flat Map -> Sink: Print to Std. Out (2/4) (580f29e3b94874dccd36775878180733) [DEPLOYING].
2020-02-27 10:37:30,636 [Flat Map -> Sink: Print to Std. Out (2/4)] INFO  (Task.java:619) - Registering task at network: Flat Map -> Sink: Print to Std. Out (2/4) (580f29e3b94874dccd36775878180733) [DEPLOYING].
2020-02-27 10:37:30,637 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Flat Map -> Sink: Print to Std. Out (3/4).
2020-02-27 10:37:30,630 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (2/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-27 10:37:30,644 [Flat Map -> Sink: Print to Std. Out (3/4)] INFO  (Task.java:958) - Flat Map -> Sink: Print to Std. Out (3/4) (1ac4d01d6aee3e9056497689d3070675) switched from CREATED to DEPLOYING.
2020-02-27 10:37:30,644 [Flat Map -> Sink: Print to Std. Out (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Flat Map -> Sink: Print to Std. Out (3/4) (1ac4d01d6aee3e9056497689d3070675) [DEPLOYING]
2020-02-27 10:37:30,644 [Flat Map -> Sink: Print to Std. Out (3/4)] INFO  (Task.java:593) - Loading JAR files for task Flat Map -> Sink: Print to Std. Out (3/4) (1ac4d01d6aee3e9056497689d3070675) [DEPLOYING].
2020-02-27 10:37:30,644 [Flat Map -> Sink: Print to Std. Out (3/4)] INFO  (Task.java:619) - Registering task at network: Flat Map -> Sink: Print to Std. Out (3/4) (1ac4d01d6aee3e9056497689d3070675) [DEPLOYING].
2020-02-27 10:37:30,645 [Sink: Unnamed (1/4)] INFO  (Task.java:958) - Sink: Unnamed (1/4) (f509009b0b49919eb4836a08d8d4873f) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,645 [Sink: Unnamed (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-27 10:37:30,646 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutor.java:592) - Received task Flat Map -> Sink: Print to Std. Out (4/4).
2020-02-27 10:37:30,647 [flink-akka.actor.default-dispatcher-5] INFO  (Execution.java:1509) - Sink: Unnamed (1/4) (f509009b0b49919eb4836a08d8d4873f) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,653 [Flat Map -> Sink: Print to Std. Out (4/4)] INFO  (Task.java:958) - Flat Map -> Sink: Print to Std. Out (4/4) (e1a53b3654d873fb028631a626f924da) switched from CREATED to DEPLOYING.
2020-02-27 10:37:30,653 [flink-akka.actor.default-dispatcher-3] INFO  (TaskSlotTable.java:242) - Activate slot 46ffea9e354e8da5e628b5cd1f31d4cf.
2020-02-27 10:37:30,654 [flink-akka.actor.default-dispatcher-3] INFO  (TaskSlotTable.java:242) - Activate slot fa232fd08db6b6960a3e2ac59ae6c693.
2020-02-27 10:37:30,654 [flink-akka.actor.default-dispatcher-3] INFO  (TaskSlotTable.java:242) - Activate slot 639a26436ef2f683f46a0c6d4804c62d.
2020-02-27 10:37:30,654 [flink-akka.actor.default-dispatcher-3] INFO  (TaskSlotTable.java:242) - Activate slot eb069f5cc6b3e3069670e0cabb0d47b7.
2020-02-27 10:37:30,653 [Sink: Print to Std. Out (3/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (3/4) (255fd14ca27128be12041880b392cf40) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,653 [Sink: Unnamed (1/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-27 10:37:30,656 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Sink: Print to Std. Out (3/4) (255fd14ca27128be12041880b392cf40) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,656 [Sink: Unnamed (1/4)] WARN  (FlinkKafkaProducer.java:998) - Using EXACTLY_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-02-27 10:37:30,657 [Sink: Print to Std. Out (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-27 10:37:30,657 [Sink: Unnamed (1/4)] INFO  (TwoPhaseCommitSinkFunction.java:366) - FlinkKafkaProducer 0/4 - no state to restore
2020-02-27 10:37:30,658 [Flat Map -> Sink: Print to Std. Out (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Flat Map -> Sink: Print to Std. Out (4/4) (e1a53b3654d873fb028631a626f924da) [DEPLOYING]
2020-02-27 10:37:30,658 [Flat Map -> Sink: Print to Std. Out (4/4)] INFO  (Task.java:593) - Loading JAR files for task Flat Map -> Sink: Print to Std. Out (4/4) (e1a53b3654d873fb028631a626f924da) [DEPLOYING].
2020-02-27 10:37:30,658 [Flat Map -> Sink: Print to Std. Out (4/4)] INFO  (Task.java:619) - Registering task at network: Flat Map -> Sink: Print to Std. Out (4/4) (e1a53b3654d873fb028631a626f924da) [DEPLOYING].
2020-02-27 10:37:30,661 [Sink: Print to Std. Out (4/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (4/4) (3b5c2f8be35cd85a5827504c68b13ec5) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,662 [Sink: Print to Std. Out (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-27 10:37:30,662 [Sink: Print to Std. Out (3/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-27 10:37:30,668 [Sink: Print to Std. Out (2/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (2/4) (c98de38b5a29db19942025eb48a612a3) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,668 [Sink: Print to Std. Out (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-27 10:37:30,669 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (3/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (3/4) (c5aa47884f3200e741951566c973074f) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,669 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-27 10:37:30,672 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Sink: Print to Std. Out (4/4) (3b5c2f8be35cd85a5827504c68b13ec5) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,672 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Sink: Print to Std. Out (2/4) (c98de38b5a29db19942025eb48a612a3) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,673 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (3/4) (c5aa47884f3200e741951566c973074f) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,674 [Sink: Print to Std. Out (1/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (1/4) (f690ac5d7274df33bedb96a7f6f2a0e2) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,674 [Sink: Print to Std. Out (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-27 10:37:30,674 [Sink: Print to Std. Out (4/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-27 10:37:30,675 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Sink: Print to Std. Out (1/4) (f690ac5d7274df33bedb96a7f6f2a0e2) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,675 [KeyedProcess (4/4)] INFO  (Task.java:958) - KeyedProcess (4/4) (68592e4cd36ced623c2e549aeb8c0c6d) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,675 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - KeyedProcess (4/4) (68592e4cd36ced623c2e549aeb8c0c6d) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,675 [KeyedProcess (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-27 10:37:30,676 [Flat Map -> Sink: Print to Std. Out (3/4)] INFO  (Task.java:958) - Flat Map -> Sink: Print to Std. Out (3/4) (1ac4d01d6aee3e9056497689d3070675) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,677 [Flat Map -> Sink: Print to Std. Out (1/4)] INFO  (Task.java:958) - Flat Map -> Sink: Print to Std. Out (1/4) (4d67b3b7dcc39501e7d0643267dbcf96) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,677 [Flat Map -> Sink: Print to Std. Out (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-27 10:37:30,677 [Sink: Unnamed (4/4)] INFO  (Task.java:958) - Sink: Unnamed (4/4) (ad420fd81e5ddbd7621fc49fb72435bc) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,677 [Sink: Unnamed (2/4)] INFO  (Task.java:958) - Sink: Unnamed (2/4) (927e666431cfecd3af7509a064a3847e) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,676 [Flat Map -> Sink: Print to Std. Out (2/4)] INFO  (Task.java:958) - Flat Map -> Sink: Print to Std. Out (2/4) (580f29e3b94874dccd36775878180733) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,677 [Sink: Unnamed (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-27 10:37:30,677 [Flat Map -> Sink: Print to Std. Out (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-27 10:37:30,678 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Flat Map -> Sink: Print to Std. Out (3/4) (1ac4d01d6aee3e9056497689d3070675) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,677 [Sink: Unnamed (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-27 10:37:30,677 [Sink: Unnamed (3/4)] INFO  (Task.java:958) - Sink: Unnamed (3/4) (a6b238e3380fba43761d17be21c2f81b) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,678 [Flat Map -> Sink: Print to Std. Out (4/4)] INFO  (Task.java:958) - Flat Map -> Sink: Print to Std. Out (4/4) (e1a53b3654d873fb028631a626f924da) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,678 [Sink: Unnamed (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-27 10:37:30,679 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (3/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-27 10:37:30,677 [Flat Map -> Sink: Print to Std. Out (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-27 10:37:30,678 [Flat Map -> Sink: Print to Std. Out (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-27 10:37:30,678 [Sink: Print to Std. Out (2/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-27 10:37:30,678 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Flat Map -> Sink: Print to Std. Out (1/4) (4d67b3b7dcc39501e7d0643267dbcf96) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,681 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Sink: Unnamed (4/4) (ad420fd81e5ddbd7621fc49fb72435bc) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,681 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Sink: Unnamed (2/4) (927e666431cfecd3af7509a064a3847e) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,681 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Flat Map -> Sink: Print to Std. Out (2/4) (580f29e3b94874dccd36775878180733) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,682 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Flat Map -> Sink: Print to Std. Out (4/4) (e1a53b3654d873fb028631a626f924da) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,682 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Sink: Unnamed (3/4) (a6b238e3380fba43761d17be21c2f81b) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,687 [KeyedProcess (2/4)] INFO  (Task.java:958) - KeyedProcess (2/4) (22cfa17a278058ca215f6412f4bb401a) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,688 [KeyedProcess (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-27 10:37:30,689 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - KeyedProcess (2/4) (22cfa17a278058ca215f6412f4bb401a) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,691 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (4/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (4/4) (a32f4566f313f012d876db9abdb78d7d) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,695 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (4/4) (a32f4566f313f012d876db9abdb78d7d) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,695 [Flat Map -> Sink: Print to Std. Out (1/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-27 10:37:30,694 [Sink: Unnamed (3/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-27 10:37:30,696 [Sink: Unnamed (3/4)] WARN  (FlinkKafkaProducer.java:998) - Using EXACTLY_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-02-27 10:37:30,696 [Sink: Unnamed (3/4)] INFO  (TwoPhaseCommitSinkFunction.java:366) - FlinkKafkaProducer 2/4 - no state to restore
2020-02-27 10:37:30,693 [Flat Map -> Sink: Print to Std. Out (2/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-27 10:37:30,693 [Sink: Unnamed (4/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-27 10:37:30,696 [Sink: Unnamed (4/4)] WARN  (FlinkKafkaProducer.java:998) - Using EXACTLY_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-02-27 10:37:30,697 [Sink: Unnamed (4/4)] INFO  (TwoPhaseCommitSinkFunction.java:366) - FlinkKafkaProducer 3/4 - no state to restore
2020-02-27 10:37:30,697 [KeyedProcess (2/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-27 10:37:30,693 [Flat Map -> Sink: Print to Std. Out (3/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-27 10:37:30,692 [Sink: Unnamed (2/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-27 10:37:30,692 [KeyedProcess (3/4)] INFO  (Task.java:958) - KeyedProcess (3/4) (9035dee9b4429ecee727777407f341a7) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,698 [Sink: Unnamed (2/4)] WARN  (FlinkKafkaProducer.java:998) - Using EXACTLY_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-02-27 10:37:30,698 [Sink: Unnamed (2/4)] INFO  (TwoPhaseCommitSinkFunction.java:366) - FlinkKafkaProducer 1/4 - no state to restore
2020-02-27 10:37:30,692 [KeyedProcess (4/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-27 10:37:30,699 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - KeyedProcess (3/4) (9035dee9b4429ecee727777407f341a7) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,692 [Sink: Print to Std. Out (1/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-27 10:37:30,699 [KeyedProcess (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-27 10:37:30,695 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-27 10:37:30,701 [KeyedProcess (3/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-27 10:37:30,702 [Flat Map -> Sink: Print to Std. Out (4/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-27 10:37:30,701 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) (4/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-27 10:37:30,706 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-27 10:37:30,709 [KeyedProcess (4/4)] INFO  (TypeExtractor.java:1815) - class java.util.Vector does not contain a getter for field elementData
2020-02-27 10:37:30,709 [KeyedProcess (2/4)] INFO  (TypeExtractor.java:1815) - class java.util.Vector does not contain a getter for field elementData
2020-02-27 10:37:30,708 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-27 10:37:30,708 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-27 10:37:30,708 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-27 10:37:30,707 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-27 10:37:30,707 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-27 10:37:30,707 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-27 10:37:30,706 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-27 10:37:30,711 [KeyedProcess (1/4)] INFO  (Task.java:958) - KeyedProcess (1/4) (bc951382e25e4b75c9458a041e3c652f) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,709 [KeyedProcess (3/4)] INFO  (TypeExtractor.java:1815) - class java.util.Vector does not contain a getter for field elementData
2020-02-27 10:37:30,727 [KeyedProcess (3/4)] INFO  (TypeExtractor.java:1818) - class java.util.Vector does not contain a setter for field elementData
2020-02-27 10:37:30,727 [KeyedProcess (3/4)] INFO  (TypeExtractor.java:1857) - Class class java.util.Vector cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-27 10:37:30,728 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - KeyedProcess (1/4) (bc951382e25e4b75c9458a041e3c652f) switched from DEPLOYING to RUNNING.
2020-02-27 10:37:30,728 [Sink: Unnamed (4/4)] INFO  (AbstractConfig.java:347) - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-02-27 10:37:30,709 [KeyedProcess (4/4)] INFO  (TypeExtractor.java:1818) - class java.util.Vector does not contain a setter for field elementData
2020-02-27 10:37:30,734 [KeyedProcess (4/4)] INFO  (TypeExtractor.java:1857) - Class class java.util.Vector cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-27 10:37:30,728 [Sink: Unnamed (2/4)] INFO  (AbstractConfig.java:347) - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-02-27 10:37:30,727 [KeyedProcess (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-27 10:37:30,719 [KeyedProcess (2/4)] INFO  (TypeExtractor.java:1818) - class java.util.Vector does not contain a setter for field elementData
2020-02-27 10:37:30,735 [Sink: Unnamed (1/4)] INFO  (AbstractConfig.java:347) - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-02-27 10:37:30,735 [Sink: Unnamed (3/4)] INFO  (AbstractConfig.java:347) - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-02-27 10:37:30,739 [KeyedProcess (2/4)] INFO  (TypeExtractor.java:1857) - Class class java.util.Vector cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-27 10:37:30,741 [KeyedProcess (1/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-27 10:37:30,742 [KeyedProcess (1/4)] INFO  (TypeExtractor.java:1815) - class java.util.Vector does not contain a getter for field elementData
2020-02-27 10:37:30,742 [KeyedProcess (1/4)] INFO  (TypeExtractor.java:1818) - class java.util.Vector does not contain a setter for field elementData
2020-02-27 10:37:30,742 [KeyedProcess (1/4)] INFO  (TypeExtractor.java:1857) - Class class java.util.Vector cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-27 10:37:30,827 [Sink: Unnamed (3/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-27 10:37:30,827 [Sink: Unnamed (3/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-27 10:37:30,827 [Sink: Unnamed (3/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582792650825
2020-02-27 10:37:30,830 [Sink: Unnamed (3/4)] INFO  (FlinkKafkaProducer.java:1158) - Starting FlinkKafkaInternalProducer (3/4) to produce into default topic output-topic-job2
2020-02-27 10:37:30,846 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-27 10:37:30,847 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-27 10:37:30,847 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582792650846
2020-02-27 10:37:30,857 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-27 10:37:30,857 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-27 10:37:30,857 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582792650846
2020-02-27 10:37:30,858 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-27 10:37:30,858 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-27 10:37:30,859 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582792650852
2020-02-27 10:37:30,859 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-27 10:37:30,860 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-27 10:37:30,860 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582792650850
2020-02-27 10:37:30,863 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-27 10:37:30,863 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-27 10:37:30,863 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582792650849
2020-02-27 10:37:30,873 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-27 10:37:30,873 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-27 10:37:30,873 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582792650873
2020-02-27 10:37:30,874 [Sink: Unnamed (1/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-27 10:37:30,874 [Sink: Unnamed (1/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-27 10:37:30,874 [Sink: Unnamed (1/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582792650869
2020-02-27 10:37:30,874 [Sink: Unnamed (1/4)] INFO  (FlinkKafkaProducer.java:1158) - Starting FlinkKafkaInternalProducer (1/4) to produce into default topic output-topic-job2
2020-02-27 10:37:30,874 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-27 10:37:30,874 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-27 10:37:30,874 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582792650863
2020-02-27 10:37:30,875 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-27 10:37:30,875 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-27 10:37:30,875 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582792650861
2020-02-27 10:37:30,878 [Sink: Unnamed (4/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-27 10:37:30,878 [Sink: Unnamed (4/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-27 10:37:30,878 [Sink: Unnamed (4/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582792650878
2020-02-27 10:37:30,878 [Sink: Unnamed (4/4)] INFO  (FlinkKafkaProducer.java:1158) - Starting FlinkKafkaInternalProducer (4/4) to produce into default topic output-topic-job2
2020-02-27 10:37:30,881 [Sink: Unnamed (2/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-27 10:37:30,883 [Sink: Unnamed (2/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-27 10:37:30,884 [Sink: Unnamed (2/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582792650881
2020-02-27 10:37:30,885 [Sink: Unnamed (2/4)] INFO  (FlinkKafkaProducer.java:1158) - Starting FlinkKafkaInternalProducer (2/4) to produce into default topic output-topic-job2
2020-02-27 10:37:31,259 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-7, groupId=KafkaCsvProducer] Cluster ID: Ac9bjeJjT7mUd0__SxsHgg
2020-02-27 10:37:31,262 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-1, groupId=KafkaCsvProducer] Cluster ID: Ac9bjeJjT7mUd0__SxsHgg
2020-02-27 10:37:31,259 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-5, groupId=KafkaCsvProducer] Cluster ID: Ac9bjeJjT7mUd0__SxsHgg
2020-02-27 10:37:31,263 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-6, groupId=KafkaCsvProducer] Cluster ID: Ac9bjeJjT7mUd0__SxsHgg
2020-02-27 10:37:31,262 [kafka-producer-network-thread | producer-4] INFO  (Metadata.java:261) - [Producer clientId=producer-4] Cluster ID: Ac9bjeJjT7mUd0__SxsHgg
2020-02-27 10:37:31,264 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-8, groupId=KafkaCsvProducer] Cluster ID: Ac9bjeJjT7mUd0__SxsHgg
2020-02-27 10:37:31,265 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-4, groupId=KafkaCsvProducer] Cluster ID: Ac9bjeJjT7mUd0__SxsHgg
2020-02-27 10:37:31,265 [kafka-producer-network-thread | producer-1] INFO  (Metadata.java:261) - [Producer clientId=producer-1] Cluster ID: Ac9bjeJjT7mUd0__SxsHgg
2020-02-27 10:37:31,266 [kafka-producer-network-thread | producer-3] INFO  (Metadata.java:261) - [Producer clientId=producer-3] Cluster ID: Ac9bjeJjT7mUd0__SxsHgg
2020-02-27 10:37:31,269 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-3, groupId=KafkaCsvProducer] Cluster ID: Ac9bjeJjT7mUd0__SxsHgg
2020-02-27 10:37:31,270 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-2, groupId=KafkaCsvProducer] Cluster ID: Ac9bjeJjT7mUd0__SxsHgg
2020-02-27 10:37:31,270 [kafka-producer-network-thread | producer-2] INFO  (Metadata.java:261) - [Producer clientId=producer-2] Cluster ID: Ac9bjeJjT7mUd0__SxsHgg
2020-02-27 10:37:31,271 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (FlinkKafkaConsumerBase.java:651) - Consumer subtask 1 initially has no partitions to read from.
2020-02-27 10:37:31,271 [Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (FlinkKafkaConsumerBase.java:651) - Consumer subtask 1 initially has no partitions to read from.
2020-02-27 10:37:31,271 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (FlinkKafkaConsumerBase.java:651) - Consumer subtask 0 initially has no partitions to read from.
2020-02-27 10:37:31,271 [Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (FlinkKafkaConsumerBase.java:604) - Consumer subtask 0 will start reading the following 1 partitions from the earliest offsets: [KafkaTopicPartition{topic='_input-topic-job1', partition=0}]
2020-02-27 10:37:31,271 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (FlinkKafkaConsumerBase.java:604) - Consumer subtask 2 will start reading the following 1 partitions from the earliest offsets: [KafkaTopicPartition{topic='output-topic-job1', partition=0}]
2020-02-27 10:37:31,272 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (FlinkKafkaConsumerBase.java:651) - Consumer subtask 3 initially has no partitions to read from.
2020-02-27 10:37:31,271 [Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (FlinkKafkaConsumerBase.java:651) - Consumer subtask 2 initially has no partitions to read from.
2020-02-27 10:37:31,272 [Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (FlinkKafkaConsumerBase.java:651) - Consumer subtask 3 initially has no partitions to read from.
2020-02-27 10:37:31,300 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 2 creating fetcher with offsets {KafkaTopicPartition{topic='output-topic-job1', partition=0}=-915623761775}.
2020-02-27 10:37:31,312 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 0 creating fetcher with offsets {KafkaTopicPartition{topic='_input-topic-job1', partition=0}=-915623761775}.
2020-02-27 10:37:31,322 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 2 creating fetcher with offsets {}.
2020-02-27 10:37:31,328 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 1 creating fetcher with offsets {}.
2020-02-27 10:37:31,328 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 3 creating fetcher with offsets {}.
2020-02-27 10:37:31,328 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 0 creating fetcher with offsets {}.
2020-02-27 10:37:31,328 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-27 10:37:31,333 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 3 creating fetcher with offsets {}.
2020-02-27 10:37:31,333 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 1 creating fetcher with offsets {}.
2020-02-27 10:37:31,340 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-27 10:37:31,334 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-27 10:37:31,336 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-27 10:37:31,359 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-27 10:37:31,359 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582792651336
2020-02-27 10:37:31,356 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-27 10:37:31,355 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-27 10:37:31,348 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-27 10:37:31,370 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-27 10:37:31,361 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-27 10:37:31,360 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-27 10:37:31,381 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-27 10:37:31,381 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582792651349
2020-02-27 10:37:31,389 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-27 10:37:31,391 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-27 10:37:31,391 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582792651345
2020-02-27 10:37:31,393 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-27 10:37:31,394 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-27 10:37:31,394 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (4/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582792651389
2020-02-27 10:37:31,395 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-27 10:37:31,395 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-27 10:37:31,395 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582792651388
2020-02-27 10:37:31,396 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (KafkaConsumer.java:1123) - [Consumer clientId=consumer-KafkaCsvProducer-12, groupId=KafkaCsvProducer] Subscribed to partition(s): _input-topic-job1-0
2020-02-27 10:37:31,400 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-27 10:37:31,400 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-27 10:37:31,400 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582792651400
2020-02-27 10:37:31,406 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-27 10:37:31,407 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-27 10:37:31,407 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582792651406
2020-02-27 10:37:31,410 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-12, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition _input-topic-job1-0
2020-02-27 10:37:31,408 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (KafkaConsumer.java:1123) - [Consumer clientId=consumer-KafkaCsvProducer-15, groupId=KafkaCsvProducer] Subscribed to partition(s): output-topic-job1-0
2020-02-27 10:37:31,417 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-27 10:37:31,417 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-27 10:37:31,417 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (2/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582792651416
2020-02-27 10:37:31,412 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-15, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition output-topic-job1-0
2020-02-27 10:37:31,434 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-12, groupId=KafkaCsvProducer] Cluster ID: Ac9bjeJjT7mUd0__SxsHgg
2020-02-27 10:37:31,443 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-15, groupId=KafkaCsvProducer] Cluster ID: Ac9bjeJjT7mUd0__SxsHgg
2020-02-27 10:37:31,449 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-12, groupId=KafkaCsvProducer] Resetting offset for partition _input-topic-job1-0 to offset 0.
2020-02-27 10:37:31,456 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-15, groupId=KafkaCsvProducer] Resetting offset for partition output-topic-job1-0 to offset 0.
2020-02-27 10:37:36,548 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (3/4)] INFO  (AbstractCoordinator.java:756) - [Consumer clientId=consumer-KafkaCsvProducer-15, groupId=KafkaCsvProducer] Discovered group coordinator skl:9092 (id: 2147483647 rack: null)
2020-02-27 10:37:36,794 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Map (1/4)] INFO  (AbstractCoordinator.java:756) - [Consumer clientId=consumer-KafkaCsvProducer-12, groupId=KafkaCsvProducer] Discovered group coordinator skl:9092 (id: 2147483647 rack: null)
