2020-02-26 22:20:00,736 [flink-akka.actor.default-dispatcher-3] INFO  (Slf4jLogger.scala:92) - Slf4jLogger started
2020-02-26 22:20:00,952 [main] INFO  (BootstrapTools.java:244) - Trying to start actor system at :0
2020-02-26 22:20:01,025 [flink-metrics-2] INFO  (Slf4jLogger.scala:92) - Slf4jLogger started
2020-02-26 22:20:01,052 [flink-metrics-2] INFO  (MarkerIgnoringBase.java:107) - Starting remoting
2020-02-26 22:20:01,218 [flink-metrics-2] INFO  (MarkerIgnoringBase.java:107) - Remoting started; listening on addresses :[akka.tcp://flink-metrics@127.0.1.1:45683]
2020-02-26 22:20:01,253 [main] INFO  (BootstrapTools.java:256) - Actor system started at akka.tcp://flink-metrics@127.0.1.1:45683
2020-02-26 22:20:01,260 [main] INFO  (AkkaRpcService.java:223) - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
2020-02-26 22:20:01,274 [main] INFO  (MiniCluster.java:397) - Starting high-availability services
2020-02-26 22:20:01,288 [main] INFO  (BlobServer.java:141) - Created BLOB server storage directory /tmp/blobStore-4b954a17-2efe-46ed-9d9f-e81b5029ca4f
2020-02-26 22:20:01,291 [main] INFO  (BlobServer.java:203) - Started BLOB server at 0.0.0.0:42455 - max concurrent requests: 50 - max backlog: 1000
2020-02-26 22:20:01,294 [main] INFO  (AbstractBlobCache.java:107) - Created BLOB cache storage directory /tmp/blobStore-090e2af6-7ff4-458b-94f1-1b41c4fc9630
2020-02-26 22:20:01,298 [main] INFO  (AbstractBlobCache.java:107) - Created BLOB cache storage directory /tmp/blobStore-92431748-9c6a-402a-aec6-2013235a90a1
2020-02-26 22:20:01,298 [main] INFO  (MiniCluster.java:479) - Starting 1 TaskManger(s)
2020-02-26 22:20:01,302 [main] INFO  (TaskManagerRunner.java:351) - Starting TaskManager with ResourceID: bcc58e16-332e-42d1-86fb-5126dbc8df8c
2020-02-26 22:20:01,465 [main] INFO  (TaskManagerServices.java:519) - Temporary file directory '/tmp': total 439 GB, usable 336 GB (76.54% usable)
2020-02-26 22:20:01,468 [main] INFO  (FileChannelManagerImpl.java:76) - FileChannelManager uses directory /tmp/flink-io-f9ed5c84-da1a-4e65-91e6-dce50771e529 for spill files.
2020-02-26 22:20:01,479 [main] INFO  (FileChannelManagerImpl.java:76) - FileChannelManager uses directory /tmp/flink-netty-shuffle-a05eb206-063c-4f04-b518-b15d6ef3b9d4 for spill files.
2020-02-26 22:20:01,620 [main] INFO  (NetworkBufferPool.java:140) - Allocated 191 MB for network buffer pool (number of memory segments: 6113, bytes per segment: 32768).
2020-02-26 22:20:01,626 [main] INFO  (NettyShuffleEnvironment.java:283) - Starting the network environment and its components.
2020-02-26 22:20:01,627 [main] INFO  (KvStateService.java:89) - Starting the kvState service and its components.
2020-02-26 22:20:01,628 [main] INFO  (TaskManagerServices.java:364) - Limiting managed memory to 0.7 of the currently free heap space (1197 MB), memory will be allocated lazily.
2020-02-26 22:20:01,638 [main] INFO  (TaskManagerConfiguration.java:197) - Messages have a max timeout of 10000 ms
2020-02-26 22:20:01,647 [main] INFO  (AkkaRpcService.java:223) - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
2020-02-26 22:20:01,678 [flink-akka.actor.default-dispatcher-2] INFO  (JobLeaderService.java:125) - Start job leader service.
2020-02-26 22:20:01,680 [flink-akka.actor.default-dispatcher-2] INFO  (FileCache.java:107) - User file cache uses directory /tmp/flink-dist-cache-9195f8bc-f4af-45b1-9cb3-a84b2fb5706c
2020-02-26 22:20:01,741 [main] INFO  (RestServerEndpoint.java:136) - Starting rest endpoint.
2020-02-26 22:20:01,819 [main] WARN  (WebMonitorUtils.java:87) - Log file environment variable 'log.file' is not set.
2020-02-26 22:20:01,820 [main] WARN  (WebMonitorUtils.java:93) - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
2020-02-26 22:20:01,833 [main] INFO  (DispatcherRestEndpoint.java:113) - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
2020-02-26 22:20:02,000 [main] INFO  (RestServerEndpoint.java:233) - Rest endpoint listening at localhost:37121
2020-02-26 22:20:02,001 [main] INFO  (EmbeddedLeaderService.java:300) - Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@7aead3af @ http://localhost:37121
2020-02-26 22:20:02,003 [mini-cluster-io-thread-1] INFO  (WebMonitorEndpoint.java:712) - http://localhost:37121 was granted leadership with leaderSessionID=a3bec8a6-ebe5-48c6-9a5f-2a2942f6354b
2020-02-26 22:20:02,003 [mini-cluster-io-thread-1] INFO  (EmbeddedLeaderService.java:250) - Received confirmation of leadership for leader http://localhost:37121 , session=a3bec8a6-ebe5-48c6-9a5f-2a2942f6354b
2020-02-26 22:20:02,025 [main] INFO  (AkkaRpcService.java:223) - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
2020-02-26 22:20:02,042 [main] INFO  (AkkaRpcService.java:223) - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
2020-02-26 22:20:02,058 [flink-akka.actor.default-dispatcher-3] INFO  (EmbeddedLeaderService.java:300) - Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@66dbf933 @ akka://flink/user/dispatcher
2020-02-26 22:20:02,058 [flink-akka.actor.default-dispatcher-2] INFO  (EmbeddedLeaderService.java:300) - Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@6d753890 @ akka://flink/user/resourcemanager
2020-02-26 22:20:02,064 [main] INFO  (MiniCluster.java:362) - Flink Mini Cluster started successfully
2020-02-26 22:20:02,071 [flink-akka.actor.default-dispatcher-3] INFO  (Dispatcher.java:884) - Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token 09693e8b-363e-4ec1-8da9-5a3d9c800f06
2020-02-26 22:20:02,074 [flink-akka.actor.default-dispatcher-2] INFO  (ResourceManager.java:925) - ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token b80c6526778a6e8fd103613414a8417e
2020-02-26 22:20:02,078 [flink-akka.actor.default-dispatcher-4] INFO  (Dispatcher.java:716) - Recovering all persisted jobs.
2020-02-26 22:20:02,080 [flink-akka.actor.default-dispatcher-2] INFO  (SlotManagerImpl.java:219) - Starting the SlotManager.
2020-02-26 22:20:02,086 [flink-akka.actor.default-dispatcher-4] INFO  (EmbeddedLeaderService.java:250) - Received confirmation of leadership for leader akka://flink/user/dispatcher , session=09693e8b-363e-4ec1-8da9-5a3d9c800f06
2020-02-26 22:20:02,087 [flink-akka.actor.default-dispatcher-3] INFO  (EmbeddedLeaderService.java:250) - Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=d1036134-14a8-417e-b80c-6526778a6e8f
2020-02-26 22:20:02,090 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:991) - Connecting to ResourceManager akka://flink/user/resourcemanager(b80c6526778a6e8fd103613414a8417e).
2020-02-26 22:20:02,123 [flink-akka.actor.default-dispatcher-5] INFO  (RetryingRegistration.java:155) - Resolved ResourceManager address, beginning registration
2020-02-26 22:20:02,123 [flink-akka.actor.default-dispatcher-5] INFO  (RetryingRegistration.java:204) - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-02-26 22:20:02,132 [flink-akka.actor.default-dispatcher-4] INFO  (ResourceManager.java:717) - Registering TaskManager with ResourceID bcc58e16-332e-42d1-86fb-5126dbc8df8c (akka://flink/user/taskmanager_0) at ResourceManager
2020-02-26 22:20:02,134 [flink-akka.actor.default-dispatcher-5] INFO  (Dispatcher.java:264) - Received JobGraph submission a5562a7a9be7788645b2065f6272c4ee (Streaming FirstAlgorithmPass).
2020-02-26 22:20:02,134 [flink-akka.actor.default-dispatcher-5] INFO  (Dispatcher.java:321) - Submitting job a5562a7a9be7788645b2065f6272c4ee (Streaming FirstAlgorithmPass).
2020-02-26 22:20:02,137 [flink-akka.actor.default-dispatcher-3] INFO  (TaskExecutorToResourceManagerConnection.java:100) - Successful registration at resource manager akka://flink/user/resourcemanager under registration id feef08845dc711e72c4231637dc1d95a.
2020-02-26 22:20:02,173 [flink-akka.actor.default-dispatcher-4] INFO  (AkkaRpcService.java:223) - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
2020-02-26 22:20:02,190 [flink-akka.actor.default-dispatcher-4] INFO  (JobMaster.java:242) - Initializing job Streaming FirstAlgorithmPass (a5562a7a9be7788645b2065f6272c4ee).
2020-02-26 22:20:02,214 [flink-akka.actor.default-dispatcher-4] INFO  (LegacyScheduler.java:171) - Using restart strategy NoRestartStrategy for Streaming FirstAlgorithmPass (a5562a7a9be7788645b2065f6272c4ee).
2020-02-26 22:20:02,239 [flink-akka.actor.default-dispatcher-4] INFO  (ExecutionGraph.java:519) - Job recovers via failover strategy: full graph restart
2020-02-26 22:20:02,258 [flink-akka.actor.default-dispatcher-4] INFO  (ExecutionGraphBuilder.java:204) - Running initialization on master for job Streaming FirstAlgorithmPass (a5562a7a9be7788645b2065f6272c4ee).
2020-02-26 22:20:02,258 [flink-akka.actor.default-dispatcher-4] INFO  (ExecutionGraphBuilder.java:222) - Successfully ran initialization on master in 0 ms.
2020-02-26 22:20:02,330 [flink-akka.actor.default-dispatcher-4] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-26 22:20:02,343 [flink-akka.actor.default-dispatcher-4] INFO  (EmbeddedLeaderService.java:300) - Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@2dc2f2d @ akka://flink/user/jobmanager_1
2020-02-26 22:20:02,344 [mini-cluster-io-thread-1] INFO  (JobManagerRunner.java:313) - JobManager runner for job Streaming FirstAlgorithmPass (a5562a7a9be7788645b2065f6272c4ee) was granted leadership with session id cadeae43-f183-4656-8a52-a759f5e313f3 at akka://flink/user/jobmanager_1.
2020-02-26 22:20:02,347 [flink-akka.actor.default-dispatcher-2] INFO  (JobMaster.java:712) - Starting execution of job Streaming FirstAlgorithmPass (a5562a7a9be7788645b2065f6272c4ee) under job master id 8a52a759f5e313f3cadeae43f1834656.
2020-02-26 22:20:02,355 [flink-akka.actor.default-dispatcher-2] INFO  (ExecutionGraph.java:1325) - Job Streaming FirstAlgorithmPass (a5562a7a9be7788645b2065f6272c4ee) switched from state CREATED to RUNNING.
2020-02-26 22:20:02,361 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source (1/4) (4fd5504004c1d984ee36664503e3c51f) switched from CREATED to SCHEDULED.
2020-02-26 22:20:02,376 [flink-akka.actor.default-dispatcher-2] INFO  (SlotPoolImpl.java:369) - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{bd37d26892ccc1c58c219647a2ad2071}]
2020-02-26 22:20:02,385 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source (2/4) (1657b7adc1bf25ab532ca57f5cee45d6) switched from CREATED to SCHEDULED.
2020-02-26 22:20:02,385 [flink-akka.actor.default-dispatcher-2] INFO  (SlotPoolImpl.java:369) - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{4efefd92bfe69a58f64b16ed15c5f2c2}]
2020-02-26 22:20:02,386 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source (3/4) (41592fd17203dc2c46352cc4e09cd562) switched from CREATED to SCHEDULED.
2020-02-26 22:20:02,386 [flink-akka.actor.default-dispatcher-2] INFO  (SlotPoolImpl.java:369) - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{71bb8a8be5c3f0172d8b6738947489d1}]
2020-02-26 22:20:02,387 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source (4/4) (e93d17433cb33d68820fce905d44973a) switched from CREATED to SCHEDULED.
2020-02-26 22:20:02,387 [flink-akka.actor.default-dispatcher-2] INFO  (SlotPoolImpl.java:369) - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{eb72792b1ee9631b055a4a9f8b920d9b}]
2020-02-26 22:20:02,387 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4) (50baf9c0c4861a12a546491958b6294c) switched from CREATED to SCHEDULED.
2020-02-26 22:20:02,388 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4) (59a190ae874509b3e42c7ae06f7efe78) switched from CREATED to SCHEDULED.
2020-02-26 22:20:02,388 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4) (41c9539174e2f1253202a728c80b8913) switched from CREATED to SCHEDULED.
2020-02-26 22:20:02,388 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4) (08989892d3f1d9193d6bca79c6f43565) switched from CREATED to SCHEDULED.
2020-02-26 22:20:02,389 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Sink: Print to Std. Out (1/4) (61c928a92feed1db7ab5e67fb614ce34) switched from CREATED to SCHEDULED.
2020-02-26 22:20:02,391 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Sink: Print to Std. Out (2/4) (c7bb4502c66c149130a9ff1ed0ff342b) switched from CREATED to SCHEDULED.
2020-02-26 22:20:02,392 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Sink: Print to Std. Out (3/4) (98b889bb5be6cb29ec87b7e28c346bee) switched from CREATED to SCHEDULED.
2020-02-26 22:20:02,392 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Sink: Print to Std. Out (4/4) (3bf00dd1670bb7660252f1a62ea11515) switched from CREATED to SCHEDULED.
2020-02-26 22:20:02,393 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (1/4) (a69f498976633da8e430c8ed67eee5df) switched from CREATED to SCHEDULED.
2020-02-26 22:20:02,393 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (2/4) (6b1a2f1c8705622b03cf5d1807adaf55) switched from CREATED to SCHEDULED.
2020-02-26 22:20:02,394 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (3/4) (98883c2cf60d487d73a97f2fc642884f) switched from CREATED to SCHEDULED.
2020-02-26 22:20:02,394 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (4/4) (a3df989a998a116af2a4547e7809e6e0) switched from CREATED to SCHEDULED.
2020-02-26 22:20:02,394 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (1/4) (bd79ab8827776d8b318642799c5a9de4) switched from CREATED to SCHEDULED.
2020-02-26 22:20:02,394 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (2/4) (9de42685a678ab01084ce68b22edf05e) switched from CREATED to SCHEDULED.
2020-02-26 22:20:02,395 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (3/4) (05202b94319913beb08f1f2d9c24b77c) switched from CREATED to SCHEDULED.
2020-02-26 22:20:02,395 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (4/4) (270a925248d1a08ceb99b31fe630c95d) switched from CREATED to SCHEDULED.
2020-02-26 22:20:02,395 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4) (ec11297c588f48bb897a213d5845afde) switched from CREATED to SCHEDULED.
2020-02-26 22:20:02,395 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4) (b9577886fef87f86c24295e5cf942398) switched from CREATED to SCHEDULED.
2020-02-26 22:20:02,395 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4) (f55881f4988792b64015bae668f76c00) switched from CREATED to SCHEDULED.
2020-02-26 22:20:02,396 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4) (623f629c9aaaea9add303c45a96ae5b4) switched from CREATED to SCHEDULED.
2020-02-26 22:20:02,396 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Flat Map (1/4) (b4907c89f885251b707847ce8963e5ab) switched from CREATED to SCHEDULED.
2020-02-26 22:20:02,396 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Flat Map (2/4) (b67fec23112b4e0eea0700cbca0a1bae) switched from CREATED to SCHEDULED.
2020-02-26 22:20:02,396 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Flat Map (3/4) (9457ab8b531dc8c93beeec14626f2806) switched from CREATED to SCHEDULED.
2020-02-26 22:20:02,396 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Flat Map (4/4) (67920849e76dbef8de2e9845c7bd5876) switched from CREATED to SCHEDULED.
2020-02-26 22:20:02,402 [jobmanager-future-thread-1] INFO  (EmbeddedLeaderService.java:250) - Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=cadeae43-f183-4656-8a52-a759f5e313f3
2020-02-26 22:20:02,404 [flink-akka.actor.default-dispatcher-2] INFO  (JobMaster.java:936) - Connecting to ResourceManager akka://flink/user/resourcemanager(b80c6526778a6e8fd103613414a8417e)
2020-02-26 22:20:02,407 [flink-akka.actor.default-dispatcher-5] INFO  (RetryingRegistration.java:155) - Resolved ResourceManager address, beginning registration
2020-02-26 22:20:02,408 [flink-akka.actor.default-dispatcher-5] INFO  (RetryingRegistration.java:204) - Registration at ResourceManager attempt 1 (timeout=100ms)
2020-02-26 22:20:02,410 [flink-akka.actor.default-dispatcher-2] INFO  (ResourceManager.java:306) - Registering job manager 8a52a759f5e313f3cadeae43f1834656@akka://flink/user/jobmanager_1 for job a5562a7a9be7788645b2065f6272c4ee.
2020-02-26 22:20:02,418 [flink-akka.actor.default-dispatcher-4] INFO  (ResourceManager.java:661) - Registered job manager 8a52a759f5e313f3cadeae43f1834656@akka://flink/user/jobmanager_1 for job a5562a7a9be7788645b2065f6272c4ee.
2020-02-26 22:20:02,420 [flink-akka.actor.default-dispatcher-5] INFO  (JobMaster.java:958) - JobManager successfully registered at ResourceManager, leader id: b80c6526778a6e8fd103613414a8417e.
2020-02-26 22:20:02,421 [flink-akka.actor.default-dispatcher-5] INFO  (SlotPoolImpl.java:319) - Requesting new slot [SlotRequestId{bd37d26892ccc1c58c219647a2ad2071}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-02-26 22:20:02,428 [flink-akka.actor.default-dispatcher-5] INFO  (SlotPoolImpl.java:319) - Requesting new slot [SlotRequestId{4efefd92bfe69a58f64b16ed15c5f2c2}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-02-26 22:20:02,428 [flink-akka.actor.default-dispatcher-5] INFO  (SlotPoolImpl.java:319) - Requesting new slot [SlotRequestId{71bb8a8be5c3f0172d8b6738947489d1}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-02-26 22:20:02,429 [flink-akka.actor.default-dispatcher-5] INFO  (SlotPoolImpl.java:319) - Requesting new slot [SlotRequestId{eb72792b1ee9631b055a4a9f8b920d9b}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
2020-02-26 22:20:02,429 [flink-akka.actor.default-dispatcher-4] INFO  (ResourceManager.java:441) - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job a5562a7a9be7788645b2065f6272c4ee with allocation id e7539bb0c69d945fe422d653d01fd560.
2020-02-26 22:20:02,433 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:822) - Receive slot request e7539bb0c69d945fe422d653d01fd560 for job a5562a7a9be7788645b2065f6272c4ee from resource manager with leader id b80c6526778a6e8fd103613414a8417e.
2020-02-26 22:20:02,437 [flink-akka.actor.default-dispatcher-4] INFO  (ResourceManager.java:441) - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job a5562a7a9be7788645b2065f6272c4ee with allocation id ffd61c9714979d83b51d2cfd7e216d3a.
2020-02-26 22:20:02,440 [flink-akka.actor.default-dispatcher-4] INFO  (ResourceManager.java:441) - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job a5562a7a9be7788645b2065f6272c4ee with allocation id 9c7ac154ef8e1ca94ab905087932f898.
2020-02-26 22:20:02,440 [flink-akka.actor.default-dispatcher-4] INFO  (ResourceManager.java:441) - Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job a5562a7a9be7788645b2065f6272c4ee with allocation id 92c9573f6b32ed5921fc4fc01bda507b.
2020-02-26 22:20:02,442 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:834) - Allocated slot for e7539bb0c69d945fe422d653d01fd560.
2020-02-26 22:20:02,442 [flink-akka.actor.default-dispatcher-5] INFO  (JobLeaderService.java:193) - Add job a5562a7a9be7788645b2065f6272c4ee for job leader monitoring.
2020-02-26 22:20:02,444 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:822) - Receive slot request ffd61c9714979d83b51d2cfd7e216d3a for job a5562a7a9be7788645b2065f6272c4ee from resource manager with leader id b80c6526778a6e8fd103613414a8417e.
2020-02-26 22:20:02,444 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:834) - Allocated slot for ffd61c9714979d83b51d2cfd7e216d3a.
2020-02-26 22:20:02,445 [flink-akka.actor.default-dispatcher-5] INFO  (JobLeaderService.java:193) - Add job a5562a7a9be7788645b2065f6272c4ee for job leader monitoring.
2020-02-26 22:20:02,444 [mini-cluster-io-thread-4] INFO  (JobLeaderService.java:333) - Try to register at job manager akka://flink/user/jobmanager_1 with leader id cadeae43-f183-4656-8a52-a759f5e313f3.
2020-02-26 22:20:02,446 [mini-cluster-io-thread-4] WARN  (EmbeddedLeaderService.java:516) - Error notifying leader listener about new leader
java.lang.IllegalStateException: The RPC connection is already closed
	at org.apache.flink.util.Preconditions.checkState(Preconditions.java:195)
	at org.apache.flink.runtime.registration.RegisteredRpcConnection.start(RegisteredRpcConnection.java:90)
	at org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener.notifyLeaderAddress(JobLeaderService.java:334)
	at org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService$NotifyOfLeaderCall.run(EmbeddedLeaderService.java:513)
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1626)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-02-26 22:20:02,445 [mini-cluster-io-thread-1] INFO  (JobLeaderService.java:333) - Try to register at job manager akka://flink/user/jobmanager_1 with leader id cadeae43-f183-4656-8a52-a759f5e313f3.
2020-02-26 22:20:02,451 [flink-akka.actor.default-dispatcher-3] INFO  (RetryingRegistration.java:155) - Resolved JobManager address, beginning registration
2020-02-26 22:20:02,452 [flink-akka.actor.default-dispatcher-3] INFO  (RetryingRegistration.java:204) - Registration at JobManager attempt 1 (timeout=100ms)
2020-02-26 22:20:02,449 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:822) - Receive slot request 9c7ac154ef8e1ca94ab905087932f898 for job a5562a7a9be7788645b2065f6272c4ee from resource manager with leader id b80c6526778a6e8fd103613414a8417e.
2020-02-26 22:20:02,454 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:834) - Allocated slot for 9c7ac154ef8e1ca94ab905087932f898.
2020-02-26 22:20:02,454 [flink-akka.actor.default-dispatcher-5] INFO  (JobLeaderService.java:193) - Add job a5562a7a9be7788645b2065f6272c4ee for job leader monitoring.
2020-02-26 22:20:02,455 [mini-cluster-io-thread-2] INFO  (JobLeaderService.java:333) - Try to register at job manager akka://flink/user/jobmanager_1 with leader id cadeae43-f183-4656-8a52-a759f5e313f3.
2020-02-26 22:20:02,455 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:822) - Receive slot request 92c9573f6b32ed5921fc4fc01bda507b for job a5562a7a9be7788645b2065f6272c4ee from resource manager with leader id b80c6526778a6e8fd103613414a8417e.
2020-02-26 22:20:02,456 [flink-akka.actor.default-dispatcher-3] INFO  (RetryingRegistration.java:155) - Resolved JobManager address, beginning registration
2020-02-26 22:20:02,458 [flink-akka.actor.default-dispatcher-3] INFO  (RetryingRegistration.java:204) - Registration at JobManager attempt 1 (timeout=100ms)
2020-02-26 22:20:02,457 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:834) - Allocated slot for 92c9573f6b32ed5921fc4fc01bda507b.
2020-02-26 22:20:02,458 [flink-akka.actor.default-dispatcher-5] INFO  (JobLeaderService.java:193) - Add job a5562a7a9be7788645b2065f6272c4ee for job leader monitoring.
2020-02-26 22:20:02,458 [mini-cluster-io-thread-3] INFO  (JobLeaderService.java:333) - Try to register at job manager akka://flink/user/jobmanager_1 with leader id cadeae43-f183-4656-8a52-a759f5e313f3.
2020-02-26 22:20:02,459 [flink-akka.actor.default-dispatcher-3] INFO  (RetryingRegistration.java:155) - Resolved JobManager address, beginning registration
2020-02-26 22:20:02,460 [flink-akka.actor.default-dispatcher-3] INFO  (RetryingRegistration.java:204) - Registration at JobManager attempt 1 (timeout=100ms)
2020-02-26 22:20:02,462 [flink-akka.actor.default-dispatcher-5] INFO  (JobLeaderService.java:382) - Successful registration at job manager akka://flink/user/jobmanager_1 for job a5562a7a9be7788645b2065f6272c4ee.
2020-02-26 22:20:02,464 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:1227) - Establish JobManager connection for job a5562a7a9be7788645b2065f6272c4ee.
2020-02-26 22:20:02,468 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:1128) - Offer reserved slots to the leader of job a5562a7a9be7788645b2065f6272c4ee.
2020-02-26 22:20:02,492 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Source: Custom Source (1/4) (4fd5504004c1d984ee36664503e3c51f) switched from SCHEDULED to DEPLOYING.
2020-02-26 22:20:02,493 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Source: Custom Source (1/4) (attempt #0) to bcc58e16-332e-42d1-86fb-5126dbc8df8c @ localhost (dataPort=-1)
2020-02-26 22:20:02,500 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Source: Custom Source (2/4) (1657b7adc1bf25ab532ca57f5cee45d6) switched from SCHEDULED to DEPLOYING.
2020-02-26 22:20:02,500 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Source: Custom Source (2/4) (attempt #0) to bcc58e16-332e-42d1-86fb-5126dbc8df8c @ localhost (dataPort=-1)
2020-02-26 22:20:02,500 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Source: Custom Source (3/4) (41592fd17203dc2c46352cc4e09cd562) switched from SCHEDULED to DEPLOYING.
2020-02-26 22:20:02,501 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Source: Custom Source (3/4) (attempt #0) to bcc58e16-332e-42d1-86fb-5126dbc8df8c @ localhost (dataPort=-1)
2020-02-26 22:20:02,501 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Source: Custom Source (4/4) (e93d17433cb33d68820fce905d44973a) switched from SCHEDULED to DEPLOYING.
2020-02-26 22:20:02,502 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Source: Custom Source (4/4) (attempt #0) to bcc58e16-332e-42d1-86fb-5126dbc8df8c @ localhost (dataPort=-1)
2020-02-26 22:20:02,502 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4) (50baf9c0c4861a12a546491958b6294c) switched from SCHEDULED to DEPLOYING.
2020-02-26 22:20:02,503 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4) (attempt #0) to bcc58e16-332e-42d1-86fb-5126dbc8df8c @ localhost (dataPort=-1)
2020-02-26 22:20:02,504 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4) (59a190ae874509b3e42c7ae06f7efe78) switched from SCHEDULED to DEPLOYING.
2020-02-26 22:20:02,504 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4) (attempt #0) to bcc58e16-332e-42d1-86fb-5126dbc8df8c @ localhost (dataPort=-1)
2020-02-26 22:20:02,505 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4) (41c9539174e2f1253202a728c80b8913) switched from SCHEDULED to DEPLOYING.
2020-02-26 22:20:02,505 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4) (attempt #0) to bcc58e16-332e-42d1-86fb-5126dbc8df8c @ localhost (dataPort=-1)
2020-02-26 22:20:02,505 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4) (08989892d3f1d9193d6bca79c6f43565) switched from SCHEDULED to DEPLOYING.
2020-02-26 22:20:02,506 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4) (attempt #0) to bcc58e16-332e-42d1-86fb-5126dbc8df8c @ localhost (dataPort=-1)
2020-02-26 22:20:02,506 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Sink: Print to Std. Out (1/4) (61c928a92feed1db7ab5e67fb614ce34) switched from SCHEDULED to DEPLOYING.
2020-02-26 22:20:02,507 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Sink: Print to Std. Out (1/4) (attempt #0) to bcc58e16-332e-42d1-86fb-5126dbc8df8c @ localhost (dataPort=-1)
2020-02-26 22:20:02,508 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Sink: Print to Std. Out (2/4) (c7bb4502c66c149130a9ff1ed0ff342b) switched from SCHEDULED to DEPLOYING.
2020-02-26 22:20:02,508 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Sink: Print to Std. Out (2/4) (attempt #0) to bcc58e16-332e-42d1-86fb-5126dbc8df8c @ localhost (dataPort=-1)
2020-02-26 22:20:02,508 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Sink: Print to Std. Out (3/4) (98b889bb5be6cb29ec87b7e28c346bee) switched from SCHEDULED to DEPLOYING.
2020-02-26 22:20:02,509 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Sink: Print to Std. Out (3/4) (attempt #0) to bcc58e16-332e-42d1-86fb-5126dbc8df8c @ localhost (dataPort=-1)
2020-02-26 22:20:02,509 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Sink: Print to Std. Out (4/4) (3bf00dd1670bb7660252f1a62ea11515) switched from SCHEDULED to DEPLOYING.
2020-02-26 22:20:02,509 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Sink: Print to Std. Out (4/4) (attempt #0) to bcc58e16-332e-42d1-86fb-5126dbc8df8c @ localhost (dataPort=-1)
2020-02-26 22:20:02,510 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (1/4) (a69f498976633da8e430c8ed67eee5df) switched from SCHEDULED to DEPLOYING.
2020-02-26 22:20:02,511 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (1/4) (attempt #0) to bcc58e16-332e-42d1-86fb-5126dbc8df8c @ localhost (dataPort=-1)
2020-02-26 22:20:02,511 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (2/4) (6b1a2f1c8705622b03cf5d1807adaf55) switched from SCHEDULED to DEPLOYING.
2020-02-26 22:20:02,512 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (2/4) (attempt #0) to bcc58e16-332e-42d1-86fb-5126dbc8df8c @ localhost (dataPort=-1)
2020-02-26 22:20:02,512 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (3/4) (98883c2cf60d487d73a97f2fc642884f) switched from SCHEDULED to DEPLOYING.
2020-02-26 22:20:02,512 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (3/4) (attempt #0) to bcc58e16-332e-42d1-86fb-5126dbc8df8c @ localhost (dataPort=-1)
2020-02-26 22:20:02,513 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (4/4) (a3df989a998a116af2a4547e7809e6e0) switched from SCHEDULED to DEPLOYING.
2020-02-26 22:20:02,513 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (4/4) (attempt #0) to bcc58e16-332e-42d1-86fb-5126dbc8df8c @ localhost (dataPort=-1)
2020-02-26 22:20:02,513 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (1/4) (bd79ab8827776d8b318642799c5a9de4) switched from SCHEDULED to DEPLOYING.
2020-02-26 22:20:02,514 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (1/4) (attempt #0) to bcc58e16-332e-42d1-86fb-5126dbc8df8c @ localhost (dataPort=-1)
2020-02-26 22:20:02,515 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (2/4) (9de42685a678ab01084ce68b22edf05e) switched from SCHEDULED to DEPLOYING.
2020-02-26 22:20:02,516 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (2/4) (attempt #0) to bcc58e16-332e-42d1-86fb-5126dbc8df8c @ localhost (dataPort=-1)
2020-02-26 22:20:02,517 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (3/4) (05202b94319913beb08f1f2d9c24b77c) switched from SCHEDULED to DEPLOYING.
2020-02-26 22:20:02,519 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (3/4) (attempt #0) to bcc58e16-332e-42d1-86fb-5126dbc8df8c @ localhost (dataPort=-1)
2020-02-26 22:20:02,520 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (4/4) (270a925248d1a08ceb99b31fe630c95d) switched from SCHEDULED to DEPLOYING.
2020-02-26 22:20:02,521 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (4/4) (attempt #0) to bcc58e16-332e-42d1-86fb-5126dbc8df8c @ localhost (dataPort=-1)
2020-02-26 22:20:02,522 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4) (ec11297c588f48bb897a213d5845afde) switched from SCHEDULED to DEPLOYING.
2020-02-26 22:20:02,523 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4) (attempt #0) to bcc58e16-332e-42d1-86fb-5126dbc8df8c @ localhost (dataPort=-1)
2020-02-26 22:20:02,526 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4) (b9577886fef87f86c24295e5cf942398) switched from SCHEDULED to DEPLOYING.
2020-02-26 22:20:02,526 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4) (attempt #0) to bcc58e16-332e-42d1-86fb-5126dbc8df8c @ localhost (dataPort=-1)
2020-02-26 22:20:02,527 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4) (f55881f4988792b64015bae668f76c00) switched from SCHEDULED to DEPLOYING.
2020-02-26 22:20:02,527 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4) (attempt #0) to bcc58e16-332e-42d1-86fb-5126dbc8df8c @ localhost (dataPort=-1)
2020-02-26 22:20:02,528 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4) (623f629c9aaaea9add303c45a96ae5b4) switched from SCHEDULED to DEPLOYING.
2020-02-26 22:20:02,528 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4) (attempt #0) to bcc58e16-332e-42d1-86fb-5126dbc8df8c @ localhost (dataPort=-1)
2020-02-26 22:20:02,529 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Flat Map (1/4) (b4907c89f885251b707847ce8963e5ab) switched from SCHEDULED to DEPLOYING.
2020-02-26 22:20:02,529 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Flat Map (1/4) (attempt #0) to bcc58e16-332e-42d1-86fb-5126dbc8df8c @ localhost (dataPort=-1)
2020-02-26 22:20:02,530 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Flat Map (2/4) (b67fec23112b4e0eea0700cbca0a1bae) switched from SCHEDULED to DEPLOYING.
2020-02-26 22:20:02,530 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Flat Map (2/4) (attempt #0) to bcc58e16-332e-42d1-86fb-5126dbc8df8c @ localhost (dataPort=-1)
2020-02-26 22:20:02,531 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Flat Map (3/4) (9457ab8b531dc8c93beeec14626f2806) switched from SCHEDULED to DEPLOYING.
2020-02-26 22:20:02,531 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Flat Map (3/4) (attempt #0) to bcc58e16-332e-42d1-86fb-5126dbc8df8c @ localhost (dataPort=-1)
2020-02-26 22:20:02,531 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Flat Map (4/4) (67920849e76dbef8de2e9845c7bd5876) switched from SCHEDULED to DEPLOYING.
2020-02-26 22:20:02,532 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:713) - Deploying Flat Map (4/4) (attempt #0) to bcc58e16-332e-42d1-86fb-5126dbc8df8c @ localhost (dataPort=-1)
2020-02-26 22:20:02,538 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source (1/4).
2020-02-26 22:20:02,539 [Source: Custom Source (1/4)] INFO  (Task.java:958) - Source: Custom Source (1/4) (4fd5504004c1d984ee36664503e3c51f) switched from CREATED to DEPLOYING.
2020-02-26 22:20:02,539 [Source: Custom Source (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source (1/4) (4fd5504004c1d984ee36664503e3c51f) [DEPLOYING]
2020-02-26 22:20:02,544 [Source: Custom Source (1/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source (1/4) (4fd5504004c1d984ee36664503e3c51f) [DEPLOYING].
2020-02-26 22:20:02,549 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source (3/4).
2020-02-26 22:20:02,553 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source (2/4).
2020-02-26 22:20:02,554 [Source: Custom Source (3/4)] INFO  (Task.java:958) - Source: Custom Source (3/4) (41592fd17203dc2c46352cc4e09cd562) switched from CREATED to DEPLOYING.
2020-02-26 22:20:02,558 [Source: Custom Source (1/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source (1/4) (4fd5504004c1d984ee36664503e3c51f) [DEPLOYING].
2020-02-26 22:20:02,558 [Source: Custom Source (2/4)] INFO  (Task.java:958) - Source: Custom Source (2/4) (1657b7adc1bf25ab532ca57f5cee45d6) switched from CREATED to DEPLOYING.
2020-02-26 22:20:02,558 [Source: Custom Source (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source (2/4) (1657b7adc1bf25ab532ca57f5cee45d6) [DEPLOYING]
2020-02-26 22:20:02,558 [Source: Custom Source (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source (3/4) (41592fd17203dc2c46352cc4e09cd562) [DEPLOYING]
2020-02-26 22:20:02,562 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source (4/4).
2020-02-26 22:20:02,559 [Source: Custom Source (2/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source (2/4) (1657b7adc1bf25ab532ca57f5cee45d6) [DEPLOYING].
2020-02-26 22:20:02,563 [Source: Custom Source (3/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source (3/4) (41592fd17203dc2c46352cc4e09cd562) [DEPLOYING].
2020-02-26 22:20:02,574 [Source: Custom Source (4/4)] INFO  (Task.java:958) - Source: Custom Source (4/4) (e93d17433cb33d68820fce905d44973a) switched from CREATED to DEPLOYING.
2020-02-26 22:20:02,575 [Source: Custom Source (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source (4/4) (e93d17433cb33d68820fce905d44973a) [DEPLOYING]
2020-02-26 22:20:02,575 [Source: Custom Source (4/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source (4/4) (e93d17433cb33d68820fce905d44973a) [DEPLOYING].
2020-02-26 22:20:02,576 [Source: Custom Source (2/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source (2/4) (1657b7adc1bf25ab532ca57f5cee45d6) [DEPLOYING].
2020-02-26 22:20:02,576 [Source: Custom Source (3/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source (3/4) (41592fd17203dc2c46352cc4e09cd562) [DEPLOYING].
2020-02-26 22:20:02,577 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4).
2020-02-26 22:20:02,577 [Source: Custom Source (4/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source (4/4) (e93d17433cb33d68820fce905d44973a) [DEPLOYING].
2020-02-26 22:20:02,585 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4).
2020-02-26 22:20:02,585 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4) (50baf9c0c4861a12a546491958b6294c) switched from CREATED to DEPLOYING.
2020-02-26 22:20:02,585 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4) (50baf9c0c4861a12a546491958b6294c) [DEPLOYING]
2020-02-26 22:20:02,586 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4) (50baf9c0c4861a12a546491958b6294c) [DEPLOYING].
2020-02-26 22:20:02,586 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4) (50baf9c0c4861a12a546491958b6294c) [DEPLOYING].
2020-02-26 22:20:02,595 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4) (59a190ae874509b3e42c7ae06f7efe78) switched from CREATED to DEPLOYING.
2020-02-26 22:20:02,595 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4) (59a190ae874509b3e42c7ae06f7efe78) [DEPLOYING]
2020-02-26 22:20:02,595 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4) (59a190ae874509b3e42c7ae06f7efe78) [DEPLOYING].
2020-02-26 22:20:02,596 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4) (59a190ae874509b3e42c7ae06f7efe78) [DEPLOYING].
2020-02-26 22:20:02,598 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4).
2020-02-26 22:20:02,606 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4) (41c9539174e2f1253202a728c80b8913) switched from CREATED to DEPLOYING.
2020-02-26 22:20:02,607 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4) (41c9539174e2f1253202a728c80b8913) [DEPLOYING]
2020-02-26 22:20:02,607 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4) (41c9539174e2f1253202a728c80b8913) [DEPLOYING].
2020-02-26 22:20:02,607 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4).
2020-02-26 22:20:02,608 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4) (41c9539174e2f1253202a728c80b8913) [DEPLOYING].
2020-02-26 22:20:02,611 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4) (08989892d3f1d9193d6bca79c6f43565) switched from CREATED to DEPLOYING.
2020-02-26 22:20:02,611 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4) (08989892d3f1d9193d6bca79c6f43565) [DEPLOYING]
2020-02-26 22:20:02,611 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (Task.java:593) - Loading JAR files for task Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4) (08989892d3f1d9193d6bca79c6f43565) [DEPLOYING].
2020-02-26 22:20:02,612 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (Task.java:619) - Registering task at network: Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4) (08989892d3f1d9193d6bca79c6f43565) [DEPLOYING].
2020-02-26 22:20:02,632 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Sink: Print to Std. Out (1/4).
2020-02-26 22:20:02,633 [Sink: Print to Std. Out (1/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (1/4) (61c928a92feed1db7ab5e67fb614ce34) switched from CREATED to DEPLOYING.
2020-02-26 22:20:02,634 [Source: Custom Source (1/4)] INFO  (Task.java:958) - Source: Custom Source (1/4) (4fd5504004c1d984ee36664503e3c51f) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,634 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4) (50baf9c0c4861a12a546491958b6294c) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,634 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4) (59a190ae874509b3e42c7ae06f7efe78) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,635 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source (1/4) (4fd5504004c1d984ee36664503e3c51f) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,634 [Sink: Print to Std. Out (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (1/4) (61c928a92feed1db7ab5e67fb614ce34) [DEPLOYING]
2020-02-26 22:20:02,634 [Source: Custom Source (2/4)] INFO  (Task.java:958) - Source: Custom Source (2/4) (1657b7adc1bf25ab532ca57f5cee45d6) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,638 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4) (50baf9c0c4861a12a546491958b6294c) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,639 [Source: Custom Source (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-26 22:20:02,639 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-26 22:20:02,638 [Source: Custom Source (4/4)] INFO  (Task.java:958) - Source: Custom Source (4/4) (e93d17433cb33d68820fce905d44973a) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,640 [Source: Custom Source (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-26 22:20:02,635 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4) (08989892d3f1d9193d6bca79c6f43565) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,635 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (Task.java:958) - Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4) (41c9539174e2f1253202a728c80b8913) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,634 [Source: Custom Source (3/4)] INFO  (Task.java:958) - Source: Custom Source (3/4) (41592fd17203dc2c46352cc4e09cd562) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,641 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-26 22:20:02,641 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-26 22:20:02,640 [Source: Custom Source (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-26 22:20:02,641 [Source: Custom Source (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-26 22:20:02,642 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4) (59a190ae874509b3e42c7ae06f7efe78) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,642 [Sink: Print to Std. Out (1/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Print to Std. Out (1/4) (61c928a92feed1db7ab5e67fb614ce34) [DEPLOYING].
2020-02-26 22:20:02,642 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-26 22:20:02,642 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source (2/4) (1657b7adc1bf25ab532ca57f5cee45d6) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,643 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source (4/4) (e93d17433cb33d68820fce905d44973a) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,643 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4) (08989892d3f1d9193d6bca79c6f43565) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,644 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4) (41c9539174e2f1253202a728c80b8913) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,645 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Source: Custom Source (3/4) (41592fd17203dc2c46352cc4e09cd562) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,649 [Sink: Print to Std. Out (1/4)] INFO  (Task.java:619) - Registering task at network: Sink: Print to Std. Out (1/4) (61c928a92feed1db7ab5e67fb614ce34) [DEPLOYING].
2020-02-26 22:20:02,662 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Sink: Print to Std. Out (2/4).
2020-02-26 22:20:02,671 [Sink: Print to Std. Out (2/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (2/4) (c7bb4502c66c149130a9ff1ed0ff342b) switched from CREATED to DEPLOYING.
2020-02-26 22:20:02,672 [Sink: Print to Std. Out (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (2/4) (c7bb4502c66c149130a9ff1ed0ff342b) [DEPLOYING]
2020-02-26 22:20:02,672 [Sink: Print to Std. Out (2/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Print to Std. Out (2/4) (c7bb4502c66c149130a9ff1ed0ff342b) [DEPLOYING].
2020-02-26 22:20:02,674 [Sink: Print to Std. Out (1/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (1/4) (61c928a92feed1db7ab5e67fb614ce34) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,675 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Sink: Print to Std. Out (3/4).
2020-02-26 22:20:02,675 [Sink: Print to Std. Out (2/4)] INFO  (Task.java:619) - Registering task at network: Sink: Print to Std. Out (2/4) (c7bb4502c66c149130a9ff1ed0ff342b) [DEPLOYING].
2020-02-26 22:20:02,676 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Sink: Print to Std. Out (1/4) (61c928a92feed1db7ab5e67fb614ce34) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,676 [Sink: Print to Std. Out (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-26 22:20:02,678 [Sink: Print to Std. Out (3/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (3/4) (98b889bb5be6cb29ec87b7e28c346bee) switched from CREATED to DEPLOYING.
2020-02-26 22:20:02,680 [Sink: Print to Std. Out (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (3/4) (98b889bb5be6cb29ec87b7e28c346bee) [DEPLOYING]
2020-02-26 22:20:02,681 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Sink: Print to Std. Out (4/4).
2020-02-26 22:20:02,686 [Sink: Print to Std. Out (3/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Print to Std. Out (3/4) (98b889bb5be6cb29ec87b7e28c346bee) [DEPLOYING].
2020-02-26 22:20:02,688 [Sink: Print to Std. Out (3/4)] INFO  (Task.java:619) - Registering task at network: Sink: Print to Std. Out (3/4) (98b889bb5be6cb29ec87b7e28c346bee) [DEPLOYING].
2020-02-26 22:20:02,690 [Sink: Print to Std. Out (2/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (2/4) (c7bb4502c66c149130a9ff1ed0ff342b) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,690 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (3/4).
2020-02-26 22:20:02,690 [Sink: Print to Std. Out (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-26 22:20:02,690 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Sink: Print to Std. Out (2/4) (c7bb4502c66c149130a9ff1ed0ff342b) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,690 [Sink: Print to Std. Out (4/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (4/4) (3bf00dd1670bb7660252f1a62ea11515) switched from CREATED to DEPLOYING.
2020-02-26 22:20:02,692 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (3/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (3/4) (98883c2cf60d487d73a97f2fc642884f) switched from CREATED to DEPLOYING.
2020-02-26 22:20:02,694 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (2/4).
2020-02-26 22:20:02,694 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (3/4) (98883c2cf60d487d73a97f2fc642884f) [DEPLOYING]
2020-02-26 22:20:02,694 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (3/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (3/4) (98883c2cf60d487d73a97f2fc642884f) [DEPLOYING].
2020-02-26 22:20:02,695 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (3/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (3/4) (98883c2cf60d487d73a97f2fc642884f) [DEPLOYING].
2020-02-26 22:20:02,692 [Sink: Print to Std. Out (3/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (3/4) (98b889bb5be6cb29ec87b7e28c346bee) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,699 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Sink: Print to Std. Out (3/4) (98b889bb5be6cb29ec87b7e28c346bee) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,700 [Sink: Print to Std. Out (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-26 22:20:02,699 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (2/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (2/4) (6b1a2f1c8705622b03cf5d1807adaf55) switched from CREATED to DEPLOYING.
2020-02-26 22:20:02,703 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (2/4) (6b1a2f1c8705622b03cf5d1807adaf55) [DEPLOYING]
2020-02-26 22:20:02,703 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (2/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (2/4) (6b1a2f1c8705622b03cf5d1807adaf55) [DEPLOYING].
2020-02-26 22:20:02,704 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (2/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (2/4) (6b1a2f1c8705622b03cf5d1807adaf55) [DEPLOYING].
2020-02-26 22:20:02,692 [Sink: Print to Std. Out (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Sink: Print to Std. Out (4/4) (3bf00dd1670bb7660252f1a62ea11515) [DEPLOYING]
2020-02-26 22:20:02,699 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (1/4).
2020-02-26 22:20:02,705 [Sink: Print to Std. Out (4/4)] INFO  (Task.java:593) - Loading JAR files for task Sink: Print to Std. Out (4/4) (3bf00dd1670bb7660252f1a62ea11515) [DEPLOYING].
2020-02-26 22:20:02,706 [Sink: Print to Std. Out (4/4)] INFO  (Task.java:619) - Registering task at network: Sink: Print to Std. Out (4/4) (3bf00dd1670bb7660252f1a62ea11515) [DEPLOYING].
2020-02-26 22:20:02,709 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (1/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (1/4) (a69f498976633da8e430c8ed67eee5df) switched from CREATED to DEPLOYING.
2020-02-26 22:20:02,710 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (1/4) (a69f498976633da8e430c8ed67eee5df) [DEPLOYING]
2020-02-26 22:20:02,710 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (1/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (1/4) (a69f498976633da8e430c8ed67eee5df) [DEPLOYING].
2020-02-26 22:20:02,711 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (1/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (1/4) (a69f498976633da8e430c8ed67eee5df) [DEPLOYING].
2020-02-26 22:20:02,712 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (4/4).
2020-02-26 22:20:02,713 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (4/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (4/4) (a3df989a998a116af2a4547e7809e6e0) switched from CREATED to DEPLOYING.
2020-02-26 22:20:02,713 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (4/4) (a3df989a998a116af2a4547e7809e6e0) [DEPLOYING]
2020-02-26 22:20:02,714 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (4/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (4/4) (a3df989a998a116af2a4547e7809e6e0) [DEPLOYING].
2020-02-26 22:20:02,715 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (4/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (4/4) (a3df989a998a116af2a4547e7809e6e0) [DEPLOYING].
2020-02-26 22:20:02,722 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (3/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (3/4) (98883c2cf60d487d73a97f2fc642884f) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,723 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (3/4) (98883c2cf60d487d73a97f2fc642884f) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,723 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-26 22:20:02,724 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (1/4).
2020-02-26 22:20:02,729 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (2/4).
2020-02-26 22:20:02,730 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (1/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (1/4) (bd79ab8827776d8b318642799c5a9de4) switched from CREATED to DEPLOYING.
2020-02-26 22:20:02,730 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (1/4) (bd79ab8827776d8b318642799c5a9de4) [DEPLOYING]
2020-02-26 22:20:02,730 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (1/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (1/4) (bd79ab8827776d8b318642799c5a9de4) [DEPLOYING].
2020-02-26 22:20:02,731 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (1/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (1/4) (bd79ab8827776d8b318642799c5a9de4) [DEPLOYING].
2020-02-26 22:20:02,732 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (2/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (2/4) (9de42685a678ab01084ce68b22edf05e) switched from CREATED to DEPLOYING.
2020-02-26 22:20:02,732 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (2/4) (9de42685a678ab01084ce68b22edf05e) [DEPLOYING]
2020-02-26 22:20:02,733 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (3/4).
2020-02-26 22:20:02,733 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (2/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (2/4) (9de42685a678ab01084ce68b22edf05e) [DEPLOYING].
2020-02-26 22:20:02,746 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (3/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (3/4) (05202b94319913beb08f1f2d9c24b77c) switched from CREATED to DEPLOYING.
2020-02-26 22:20:02,746 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (3/4) (05202b94319913beb08f1f2d9c24b77c) [DEPLOYING]
2020-02-26 22:20:02,746 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (3/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (3/4) (05202b94319913beb08f1f2d9c24b77c) [DEPLOYING].
2020-02-26 22:20:02,747 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (3/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (3/4) (05202b94319913beb08f1f2d9c24b77c) [DEPLOYING].
2020-02-26 22:20:02,747 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (4/4).
2020-02-26 22:20:02,749 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4).
2020-02-26 22:20:02,751 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (4/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (4/4) (270a925248d1a08ceb99b31fe630c95d) switched from CREATED to DEPLOYING.
2020-02-26 22:20:02,751 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (4/4) (270a925248d1a08ceb99b31fe630c95d) [DEPLOYING]
2020-02-26 22:20:02,753 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (4/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (4/4) (270a925248d1a08ceb99b31fe630c95d) [DEPLOYING].
2020-02-26 22:20:02,754 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (4/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (4/4) (270a925248d1a08ceb99b31fe630c95d) [DEPLOYING].
2020-02-26 22:20:02,755 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4) (ec11297c588f48bb897a213d5845afde) switched from CREATED to DEPLOYING.
2020-02-26 22:20:02,755 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4) (ec11297c588f48bb897a213d5845afde) [DEPLOYING]
2020-02-26 22:20:02,755 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (2/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (2/4) (9de42685a678ab01084ce68b22edf05e) [DEPLOYING].
2020-02-26 22:20:02,756 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4) (ec11297c588f48bb897a213d5845afde) [DEPLOYING].
2020-02-26 22:20:02,758 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4).
2020-02-26 22:20:02,759 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4) (ec11297c588f48bb897a213d5845afde) [DEPLOYING].
2020-02-26 22:20:02,775 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4).
2020-02-26 22:20:02,777 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] WARN  (FlinkKafkaProducer.java:998) - Using EXACTLY_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-02-26 22:20:02,778 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] WARN  (FlinkKafkaProducer.java:998) - Using EXACTLY_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-02-26 22:20:02,786 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4) (f55881f4988792b64015bae668f76c00) switched from CREATED to DEPLOYING.
2020-02-26 22:20:02,787 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4) (f55881f4988792b64015bae668f76c00) [DEPLOYING]
2020-02-26 22:20:02,787 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4) (f55881f4988792b64015bae668f76c00) [DEPLOYING].
2020-02-26 22:20:02,790 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4).
2020-02-26 22:20:02,794 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4) (f55881f4988792b64015bae668f76c00) [DEPLOYING].
2020-02-26 22:20:02,790 [Source: Custom Source (1/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-26 22:20:02,789 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] WARN  (FlinkKafkaProducer.java:998) - Using EXACTLY_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-02-26 22:20:02,789 [Source: Custom Source (4/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-26 22:20:02,795 [Source: Custom Source (4/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-26 22:20:02,789 [Source: Custom Source (2/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-26 22:20:02,789 [Source: Custom Source (3/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-26 22:20:02,796 [Source: Custom Source (3/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-26 22:20:02,788 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] WARN  (FlinkKafkaProducer.java:998) - Using EXACTLY_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-02-26 22:20:02,798 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (TwoPhaseCommitSinkFunction.java:366) - FlinkKafkaProducer 0/4 - no state to restore
2020-02-26 22:20:02,788 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (TwoPhaseCommitSinkFunction.java:366) - FlinkKafkaProducer 3/4 - no state to restore
2020-02-26 22:20:02,803 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4) (b9577886fef87f86c24295e5cf942398) switched from CREATED to DEPLOYING.
2020-02-26 22:20:02,788 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (TwoPhaseCommitSinkFunction.java:366) - FlinkKafkaProducer 2/4 - no state to restore
2020-02-26 22:20:02,803 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4) (623f629c9aaaea9add303c45a96ae5b4) switched from CREATED to DEPLOYING.
2020-02-26 22:20:02,796 [Source: Custom Source (2/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-26 22:20:02,795 [Source: Custom Source (1/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-26 22:20:02,795 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (TwoPhaseCommitSinkFunction.java:366) - FlinkKafkaProducer 1/4 - no state to restore
2020-02-26 22:20:02,808 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4) (623f629c9aaaea9add303c45a96ae5b4) [DEPLOYING]
2020-02-26 22:20:02,810 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4) (623f629c9aaaea9add303c45a96ae5b4) [DEPLOYING].
2020-02-26 22:20:02,811 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4) (623f629c9aaaea9add303c45a96ae5b4) [DEPLOYING].
2020-02-26 22:20:02,808 [Sink: Print to Std. Out (4/4)] INFO  (Task.java:958) - Sink: Print to Std. Out (4/4) (3bf00dd1670bb7660252f1a62ea11515) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,806 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4) (b9577886fef87f86c24295e5cf942398) [DEPLOYING]
2020-02-26 22:20:02,811 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4)] INFO  (Task.java:593) - Loading JAR files for task Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4) (b9577886fef87f86c24295e5cf942398) [DEPLOYING].
2020-02-26 22:20:02,811 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Sink: Print to Std. Out (4/4) (3bf00dd1670bb7660252f1a62ea11515) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,811 [Sink: Print to Std. Out (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-26 22:20:02,812 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4)] INFO  (Task.java:619) - Registering task at network: Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4) (b9577886fef87f86c24295e5cf942398) [DEPLOYING].
2020-02-26 22:20:02,830 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (1/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (1/4) (a69f498976633da8e430c8ed67eee5df) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,830 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-26 22:20:02,833 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (1/4) (a69f498976633da8e430c8ed67eee5df) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,842 [Source: Custom Source (2/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 1 has no restore state.
2020-02-26 22:20:02,853 [Source: Custom Source (1/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 0 has no restore state.
2020-02-26 22:20:02,845 [Source: Custom Source (4/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 3 has no restore state.
2020-02-26 22:20:02,845 [Source: Custom Source (3/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 2 has no restore state.
2020-02-26 22:20:02,843 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Flat Map (1/4).
2020-02-26 22:20:02,865 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4) (ec11297c588f48bb897a213d5845afde) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,865 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-26 22:20:02,868 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4) (f55881f4988792b64015bae668f76c00) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,869 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-26 22:20:02,870 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4) (623f629c9aaaea9add303c45a96ae5b4) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,870 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4) (b9577886fef87f86c24295e5cf942398) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,870 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4) (ec11297c588f48bb897a213d5845afde) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,870 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-26 22:20:02,871 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4) (f55881f4988792b64015bae668f76c00) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,871 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4) (b9577886fef87f86c24295e5cf942398) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,872 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-26 22:20:02,881 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (1/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (1/4) (bd79ab8827776d8b318642799c5a9de4) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,887 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-26 22:20:02,878 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (2/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (2/4) (6b1a2f1c8705622b03cf5d1807adaf55) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,889 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-26 22:20:02,876 [Flat Map (1/4)] INFO  (Task.java:958) - Flat Map (1/4) (b4907c89f885251b707847ce8963e5ab) switched from CREATED to DEPLOYING.
2020-02-26 22:20:02,896 [Flat Map (1/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Flat Map (1/4) (b4907c89f885251b707847ce8963e5ab) [DEPLOYING]
2020-02-26 22:20:02,896 [Flat Map (1/4)] INFO  (Task.java:593) - Loading JAR files for task Flat Map (1/4) (b4907c89f885251b707847ce8963e5ab) [DEPLOYING].
2020-02-26 22:20:02,896 [Flat Map (1/4)] INFO  (Task.java:619) - Registering task at network: Flat Map (1/4) (b4907c89f885251b707847ce8963e5ab) [DEPLOYING].
2020-02-26 22:20:02,897 [Flat Map (1/4)] INFO  (Task.java:958) - Flat Map (1/4) (b4907c89f885251b707847ce8963e5ab) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,897 [Flat Map (1/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-26 22:20:02,876 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (4/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (4/4) (270a925248d1a08ceb99b31fe630c95d) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,899 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-26 22:20:02,876 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Flat Map (2/4).
2020-02-26 22:20:02,875 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (2/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (2/4) (9de42685a678ab01084ce68b22edf05e) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,905 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-26 22:20:02,908 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (AbstractConfig.java:347) - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-02-26 22:20:02,875 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (3/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (3/4) (05202b94319913beb08f1f2d9c24b77c) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,910 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-26 22:20:02,872 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4) (623f629c9aaaea9add303c45a96ae5b4) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,932 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (4/4)] WARN  (TaskMetricGroup.java:143) - The operator name Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) exceeded the 80 characters length limit and was truncated.
2020-02-26 22:20:02,938 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (1/4) (bd79ab8827776d8b318642799c5a9de4) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,938 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (2/4) (6b1a2f1c8705622b03cf5d1807adaf55) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,938 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Flat Map (1/4) (b4907c89f885251b707847ce8963e5ab) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,939 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (4/4) (270a925248d1a08ceb99b31fe630c95d) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,939 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (2/4) (9de42685a678ab01084ce68b22edf05e) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,931 [Flat Map (2/4)] INFO  (Task.java:958) - Flat Map (2/4) (b67fec23112b4e0eea0700cbca0a1bae) switched from CREATED to DEPLOYING.
2020-02-26 22:20:02,909 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (AbstractConfig.java:347) - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-02-26 22:20:02,908 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (AbstractConfig.java:347) - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-02-26 22:20:02,908 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (2/4)] WARN  (TaskMetricGroup.java:143) - The operator name Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) exceeded the 80 characters length limit and was truncated.
2020-02-26 22:20:02,894 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (4/4)] INFO  (Task.java:958) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (4/4) (a3df989a998a116af2a4547e7809e6e0) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,894 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (1/4)] WARN  (TaskMetricGroup.java:143) - The operator name Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) exceeded the 80 characters length limit and was truncated.
2020-02-26 22:20:02,946 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (1/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-26 22:20:02,946 [Source: Custom Source (2/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-26 22:20:02,946 [Flat Map (1/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-26 22:20:02,946 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (2/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-26 22:20:02,956 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (1/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-26 22:20:02,946 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (3/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-26 22:20:02,944 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (3/4) (05202b94319913beb08f1f2d9c24b77c) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,957 [flink-akka.actor.default-dispatcher-3] INFO  (Execution.java:1509) - Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (4/4) (a3df989a998a116af2a4547e7809e6e0) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:02,943 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (3/4)] WARN  (TaskMetricGroup.java:143) - The operator name Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) exceeded the 80 characters length limit and was truncated.
2020-02-26 22:20:02,964 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (3/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-26 22:20:02,943 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (4/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-26 22:20:02,968 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4)] WARN  (FlinkKafkaProducer.java:998) - Using EXACTLY_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-02-26 22:20:02,969 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4)] INFO  (TwoPhaseCommitSinkFunction.java:366) - FlinkKafkaProducer 1/4 - no state to restore
2020-02-26 22:20:02,970 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4)] INFO  (AbstractConfig.java:347) - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-02-26 22:20:02,942 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (AbstractConfig.java:347) - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-02-26 22:20:02,940 [Source: Custom Source (4/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-26 22:20:02,940 [Source: Custom Source (1/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-26 22:20:02,939 [Source: Custom Source (3/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-26 22:20:02,938 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Flat Map (3/4).
2020-02-26 22:20:02,974 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4)] WARN  (FlinkKafkaProducer.java:998) - Using EXACTLY_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-02-26 22:20:02,974 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4)] WARN  (FlinkKafkaProducer.java:998) - Using EXACTLY_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-02-26 22:20:02,969 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4)] WARN  (FlinkKafkaProducer.java:998) - Using EXACTLY_ONCE semantic, but checkpointing is not enabled. Switching to NONE semantic.
2020-02-26 22:20:02,960 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Map (2/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-26 22:20:02,990 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4)] INFO  (TwoPhaseCommitSinkFunction.java:366) - FlinkKafkaProducer 0/4 - no state to restore
2020-02-26 22:20:02,990 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4)] INFO  (AbstractConfig.java:347) - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-02-26 22:20:02,992 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4)] INFO  (TwoPhaseCommitSinkFunction.java:366) - FlinkKafkaProducer 2/4 - no state to restore
2020-02-26 22:20:02,992 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4)] INFO  (AbstractConfig.java:347) - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-02-26 22:20:02,955 [Flat Map (2/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Flat Map (2/4) (b67fec23112b4e0eea0700cbca0a1bae) [DEPLOYING]
2020-02-26 22:20:02,954 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-26 22:20:03,007 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, initAggrWindow) -> (Flat Map, Map) (4/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-26 22:20:03,002 [Flat Map (2/4)] INFO  (Task.java:593) - Loading JAR files for task Flat Map (2/4) (b67fec23112b4e0eea0700cbca0a1bae) [DEPLOYING].
2020-02-26 22:20:02,988 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4)] INFO  (TwoPhaseCommitSinkFunction.java:366) - FlinkKafkaProducer 3/4 - no state to restore
2020-02-26 22:20:02,978 [flink-akka.actor.default-dispatcher-5] INFO  (TaskExecutor.java:592) - Received task Flat Map (4/4).
2020-02-26 22:20:02,977 [Flat Map (3/4)] INFO  (Task.java:958) - Flat Map (3/4) (9457ab8b531dc8c93beeec14626f2806) switched from CREATED to DEPLOYING.
2020-02-26 22:20:03,010 [Flat Map (3/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Flat Map (3/4) (9457ab8b531dc8c93beeec14626f2806) [DEPLOYING]
2020-02-26 22:20:03,010 [Flat Map (2/4)] INFO  (Task.java:619) - Registering task at network: Flat Map (2/4) (b67fec23112b4e0eea0700cbca0a1bae) [DEPLOYING].
2020-02-26 22:20:03,011 [Flat Map (3/4)] INFO  (Task.java:593) - Loading JAR files for task Flat Map (3/4) (9457ab8b531dc8c93beeec14626f2806) [DEPLOYING].
2020-02-26 22:20:03,011 [Flat Map (2/4)] INFO  (Task.java:958) - Flat Map (2/4) (b67fec23112b4e0eea0700cbca0a1bae) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:03,011 [Flat Map (3/4)] INFO  (Task.java:619) - Registering task at network: Flat Map (3/4) (9457ab8b531dc8c93beeec14626f2806) [DEPLOYING].
2020-02-26 22:20:03,011 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Flat Map (2/4) (b67fec23112b4e0eea0700cbca0a1bae) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:03,012 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4)] INFO  (AbstractConfig.java:347) - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 3600000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2020-02-26 22:20:03,011 [Flat Map (3/4)] INFO  (Task.java:958) - Flat Map (3/4) (9457ab8b531dc8c93beeec14626f2806) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:03,012 [Flat Map (2/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-26 22:20:03,020 [flink-akka.actor.default-dispatcher-5] INFO  (TaskSlotTable.java:242) - Activate slot 92c9573f6b32ed5921fc4fc01bda507b.
2020-02-26 22:20:03,025 [flink-akka.actor.default-dispatcher-5] INFO  (TaskSlotTable.java:242) - Activate slot 9c7ac154ef8e1ca94ab905087932f898.
2020-02-26 22:20:03,025 [flink-akka.actor.default-dispatcher-5] INFO  (TaskSlotTable.java:242) - Activate slot ffd61c9714979d83b51d2cfd7e216d3a.
2020-02-26 22:20:03,025 [flink-akka.actor.default-dispatcher-5] INFO  (TaskSlotTable.java:242) - Activate slot e7539bb0c69d945fe422d653d01fd560.
2020-02-26 22:20:03,014 [Flat Map (3/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-26 22:20:03,014 [flink-akka.actor.default-dispatcher-2] INFO  (Execution.java:1509) - Flat Map (3/4) (9457ab8b531dc8c93beeec14626f2806) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:03,029 [Flat Map (2/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-26 22:20:03,032 [Flat Map (3/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-26 22:20:03,035 [Flat Map (4/4)] INFO  (Task.java:958) - Flat Map (4/4) (67920849e76dbef8de2e9845c7bd5876) switched from CREATED to DEPLOYING.
2020-02-26 22:20:03,035 [Flat Map (4/4)] INFO  (Task.java:586) - Creating FileSystem stream leak safety net for task Flat Map (4/4) (67920849e76dbef8de2e9845c7bd5876) [DEPLOYING]
2020-02-26 22:20:03,035 [Flat Map (4/4)] INFO  (Task.java:593) - Loading JAR files for task Flat Map (4/4) (67920849e76dbef8de2e9845c7bd5876) [DEPLOYING].
2020-02-26 22:20:03,036 [Flat Map (4/4)] INFO  (Task.java:619) - Registering task at network: Flat Map (4/4) (67920849e76dbef8de2e9845c7bd5876) [DEPLOYING].
2020-02-26 22:20:03,037 [Flat Map (4/4)] INFO  (Task.java:958) - Flat Map (4/4) (67920849e76dbef8de2e9845c7bd5876) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:03,037 [flink-akka.actor.default-dispatcher-4] INFO  (Execution.java:1509) - Flat Map (4/4) (67920849e76dbef8de2e9845c7bd5876) switched from DEPLOYING to RUNNING.
2020-02-26 22:20:03,039 [Flat Map (4/4)] INFO  (StateBackendLoader.java:227) - No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
2020-02-26 22:20:03,041 [Flat Map (4/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-26 22:20:03,142 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-26 22:20:03,142 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-26 22:20:03,142 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582748403140
2020-02-26 22:20:03,144 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4)] INFO  (FlinkKafkaProducer.java:1158) - Starting FlinkKafkaInternalProducer (3/4) to produce into default topic output-topic-job1
2020-02-26 22:20:03,154 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (3/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-26 22:20:03,157 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-26 22:20:03,181 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-26 22:20:03,182 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582748403157
2020-02-26 22:20:03,219 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (FlinkKafkaProducer.java:1158) - Starting FlinkKafkaInternalProducer (2/4) to produce into default topic _input-topic-job1
2020-02-26 22:20:03,220 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-26 22:20:03,221 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-26 22:20:03,221 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 1 has no restore state.
2020-02-26 22:20:03,222 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-26 22:20:03,222 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-26 22:20:03,222 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-26 22:20:03,222 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582748403157
2020-02-26 22:20:03,223 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4)] INFO  (FlinkKafkaProducer.java:1158) - Starting FlinkKafkaInternalProducer (2/4) to produce into default topic output-topic-job1
2020-02-26 22:20:03,224 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (2/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-26 22:20:03,225 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-26 22:20:03,232 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-26 22:20:03,233 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582748403153
2020-02-26 22:20:03,234 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (FlinkKafkaProducer.java:1158) - Starting FlinkKafkaInternalProducer (4/4) to produce into default topic _input-topic-job1
2020-02-26 22:20:03,236 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-26 22:20:03,237 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-26 22:20:03,238 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582748403162
2020-02-26 22:20:03,238 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (FlinkKafkaProducer.java:1158) - Starting FlinkKafkaInternalProducer (3/4) to produce into default topic _input-topic-job1
2020-02-26 22:20:03,239 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-26 22:20:03,239 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-26 22:20:03,239 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582748403147
2020-02-26 22:20:03,239 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4)] INFO  (FlinkKafkaProducer.java:1158) - Starting FlinkKafkaInternalProducer (4/4) to produce into default topic output-topic-job1
2020-02-26 22:20:03,239 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-26 22:20:03,240 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-26 22:20:03,239 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-26 22:20:03,240 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-26 22:20:03,240 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582748403178
2020-02-26 22:20:03,240 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4)] INFO  (FlinkKafkaProducer.java:1158) - Starting FlinkKafkaInternalProducer (1/4) to produce into default topic output-topic-job1
2020-02-26 22:20:03,241 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (1/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-26 22:20:03,240 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 2 has no restore state.
2020-02-26 22:20:03,241 [Window(TumblingEventTimeWindows(30000), EventTimeTrigger, CoGroupWindowFunction) -> Sink: Unnamed (4/4)] INFO  (HeapKeyedStateBackend.java:140) - Initializing heap keyed state backend with stream factory.
2020-02-26 22:20:03,241 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-26 22:20:03,242 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-26 22:20:03,240 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-26 22:20:03,243 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-26 22:20:03,243 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 3 has no restore state.
2020-02-26 22:20:03,243 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582748403174
2020-02-26 22:20:03,243 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (FlinkKafkaProducer.java:1158) - Starting FlinkKafkaInternalProducer (1/4) to produce into default topic _input-topic-job1
2020-02-26 22:20:03,243 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-26 22:20:03,243 [Source: Custom Source (2/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-26 22:20:03,244 [Source: Custom Source (2/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-26 22:20:03,244 [Source: Custom Source (2/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582748403171
2020-02-26 22:20:03,244 [Source: Custom Source (1/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-26 22:20:03,245 [Source: Custom Source (1/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-26 22:20:03,245 [Source: Custom Source (1/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582748403171
2020-02-26 22:20:03,245 [Source: Custom Source (4/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-26 22:20:03,246 [Source: Custom Source (4/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-26 22:20:03,246 [Source: Custom Source (4/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582748403170
2020-02-26 22:20:03,246 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-26 22:20:03,247 [Source: Custom Source (3/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-26 22:20:03,247 [Source: Custom Source (3/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-26 22:20:03,247 [Source: Custom Source (3/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582748403170
2020-02-26 22:20:03,245 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (TypeExtractor.java:1818) - class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
2020-02-26 22:20:03,249 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (TypeExtractor.java:1857) - Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
2020-02-26 22:20:03,250 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (FlinkKafkaConsumerBase.java:886) - Consumer subtask 0 has no restore state.
2020-02-26 22:20:03,250 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-26 22:20:03,253 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-26 22:20:03,253 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-26 22:20:03,253 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582748403242
2020-02-26 22:20:03,261 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-26 22:20:03,272 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-26 22:20:03,272 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582748403261
2020-02-26 22:20:03,273 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-26 22:20:03,273 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-26 22:20:03,273 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582748403261
2020-02-26 22:20:03,276 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-26 22:20:03,276 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-26 22:20:03,276 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582748403275
2020-02-26 22:20:03,716 [Source: Custom Source (3/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-4, groupId=KafkaCsvProducer] Cluster ID: wKv-B2cXSB6W9rbaNsnecA
2020-02-26 22:20:03,716 [Source: Custom Source (4/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-2, groupId=KafkaCsvProducer] Cluster ID: wKv-B2cXSB6W9rbaNsnecA
2020-02-26 22:20:03,716 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-8, groupId=KafkaCsvProducer] Cluster ID: wKv-B2cXSB6W9rbaNsnecA
2020-02-26 22:20:03,718 [kafka-producer-network-thread | producer-4] INFO  (Metadata.java:261) - [Producer clientId=producer-4] Cluster ID: wKv-B2cXSB6W9rbaNsnecA
2020-02-26 22:20:03,718 [kafka-producer-network-thread | producer-1] INFO  (Metadata.java:261) - [Producer clientId=producer-1] Cluster ID: wKv-B2cXSB6W9rbaNsnecA
2020-02-26 22:20:03,718 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-6, groupId=KafkaCsvProducer] Cluster ID: wKv-B2cXSB6W9rbaNsnecA
2020-02-26 22:20:03,720 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-7, groupId=KafkaCsvProducer] Cluster ID: wKv-B2cXSB6W9rbaNsnecA
2020-02-26 22:20:03,720 [Source: Custom Source (4/4)] INFO  (FlinkKafkaConsumerBase.java:604) - Consumer subtask 3 will start reading the following 1 partitions from the earliest offsets: [KafkaTopicPartition{topic='input-topic-job1', partition=0}]
2020-02-26 22:20:03,720 [Source: Custom Source (1/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-3, groupId=KafkaCsvProducer] Cluster ID: wKv-B2cXSB6W9rbaNsnecA
2020-02-26 22:20:03,720 [Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (FlinkKafkaConsumerBase.java:604) - Consumer subtask 3 will start reading the following 1 partitions from the earliest offsets: [KafkaTopicPartition{topic='input-topic-job1', partition=0}]
2020-02-26 22:20:03,720 [Source: Custom Source (3/4)] INFO  (FlinkKafkaConsumerBase.java:651) - Consumer subtask 2 initially has no partitions to read from.
2020-02-26 22:20:03,720 [Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (FlinkKafkaConsumerBase.java:651) - Consumer subtask 2 initially has no partitions to read from.
2020-02-26 22:20:03,721 [kafka-producer-network-thread | producer-8] INFO  (Metadata.java:261) - [Producer clientId=producer-8] Cluster ID: wKv-B2cXSB6W9rbaNsnecA
2020-02-26 22:20:03,721 [kafka-producer-network-thread | producer-2] INFO  (Metadata.java:261) - [Producer clientId=producer-2] Cluster ID: wKv-B2cXSB6W9rbaNsnecA
2020-02-26 22:20:03,721 [Source: Custom Source (1/4)] INFO  (FlinkKafkaConsumerBase.java:651) - Consumer subtask 0 initially has no partitions to read from.
2020-02-26 22:20:03,722 [kafka-producer-network-thread | producer-6] INFO  (Metadata.java:261) - [Producer clientId=producer-6] Cluster ID: wKv-B2cXSB6W9rbaNsnecA
2020-02-26 22:20:03,722 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-5, groupId=KafkaCsvProducer] Cluster ID: wKv-B2cXSB6W9rbaNsnecA
2020-02-26 22:20:03,722 [kafka-producer-network-thread | producer-3] INFO  (Metadata.java:261) - [Producer clientId=producer-3] Cluster ID: wKv-B2cXSB6W9rbaNsnecA
2020-02-26 22:20:03,723 [Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (FlinkKafkaConsumerBase.java:651) - Consumer subtask 1 initially has no partitions to read from.
2020-02-26 22:20:03,723 [kafka-producer-network-thread | producer-7] INFO  (Metadata.java:261) - [Producer clientId=producer-7] Cluster ID: wKv-B2cXSB6W9rbaNsnecA
2020-02-26 22:20:03,724 [Source: Custom Source (2/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-1, groupId=KafkaCsvProducer] Cluster ID: wKv-B2cXSB6W9rbaNsnecA
2020-02-26 22:20:03,724 [Source: Custom Source (2/4)] INFO  (FlinkKafkaConsumerBase.java:651) - Consumer subtask 1 initially has no partitions to read from.
2020-02-26 22:20:03,725 [kafka-producer-network-thread | producer-5] INFO  (Metadata.java:261) - [Producer clientId=producer-5] Cluster ID: wKv-B2cXSB6W9rbaNsnecA
2020-02-26 22:20:03,725 [Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (FlinkKafkaConsumerBase.java:651) - Consumer subtask 0 initially has no partitions to read from.
2020-02-26 22:20:03,752 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 3 creating fetcher with offsets {KafkaTopicPartition{topic='input-topic-job1', partition=0}=-915623761775}.
2020-02-26 22:20:03,755 [Legacy Source Thread - Source: Custom Source (4/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 3 creating fetcher with offsets {KafkaTopicPartition{topic='input-topic-job1', partition=0}=-915623761775}.
2020-02-26 22:20:03,765 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 0 creating fetcher with offsets {}.
2020-02-26 22:20:03,767 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 2 creating fetcher with offsets {}.
2020-02-26 22:20:03,767 [Legacy Source Thread - Source: Custom Source (1/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 0 creating fetcher with offsets {}.
2020-02-26 22:20:03,766 [Legacy Source Thread - Source: Custom Source (2/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 1 creating fetcher with offsets {}.
2020-02-26 22:20:03,766 [Legacy Source Thread - Source: Custom Source (3/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 2 creating fetcher with offsets {}.
2020-02-26 22:20:03,766 [Legacy Source Thread - Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (FlinkKafkaConsumerBase.java:688) - Consumer subtask 1 creating fetcher with offsets {}.
2020-02-26 22:20:03,774 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-26 22:20:03,776 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-26 22:20:03,780 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-26 22:20:03,783 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-26 22:20:03,796 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-26 22:20:03,796 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (1/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582748403783
2020-02-26 22:20:03,794 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-26 22:20:03,802 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-26 22:20:03,790 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-26 22:20:03,786 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-26 22:20:03,799 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (AbstractConfig.java:347) - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = KafkaCsvProducer
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2020-02-26 22:20:03,796 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-26 22:20:03,806 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-26 22:20:03,806 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582748403789
2020-02-26 22:20:03,806 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-26 22:20:03,810 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-26 22:20:03,810 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582748403784
2020-02-26 22:20:03,810 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (KafkaConsumer.java:1123) - [Consumer clientId=consumer-KafkaCsvProducer-11, groupId=KafkaCsvProducer] Subscribed to partition(s): input-topic-job1-0
2020-02-26 22:20:03,823 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (KafkaConsumer.java:1123) - [Consumer clientId=consumer-KafkaCsvProducer-9, groupId=KafkaCsvProducer] Subscribed to partition(s): input-topic-job1-0
2020-02-26 22:20:03,823 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-11, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition input-topic-job1-0
2020-02-26 22:20:03,823 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (SubscriptionState.java:568) - [Consumer clientId=consumer-KafkaCsvProducer-9, groupId=KafkaCsvProducer] Seeking to EARLIEST offset of partition input-topic-job1-0
2020-02-26 22:20:03,828 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-26 22:20:03,828 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-26 22:20:03,828 [Kafka Fetcher for Source: Custom Source (3/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582748403828
2020-02-26 22:20:03,832 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-26 22:20:03,832 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-26 22:20:03,832 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (2/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582748403832
2020-02-26 22:20:03,834 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-26 22:20:03,840 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-26 22:20:03,840 [Kafka Fetcher for Source: Custom Source (2/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582748403834
2020-02-26 22:20:03,842 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-26 22:20:03,842 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-26 22:20:03,842 [Kafka Fetcher for Source: Custom Source (1/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582748403842
2020-02-26 22:20:03,844 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (AppInfoParser.java:117) - Kafka version: 2.4.0
2020-02-26 22:20:03,844 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (AppInfoParser.java:118) - Kafka commitId: 77a89fcf8d7fa018
2020-02-26 22:20:03,845 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (3/4)] INFO  (AppInfoParser.java:119) - Kafka startTimeMs: 1582748403844
2020-02-26 22:20:03,866 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-9, groupId=KafkaCsvProducer] Cluster ID: wKv-B2cXSB6W9rbaNsnecA
2020-02-26 22:20:03,867 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (Metadata.java:261) - [Consumer clientId=consumer-KafkaCsvProducer-11, groupId=KafkaCsvProducer] Cluster ID: wKv-B2cXSB6W9rbaNsnecA
2020-02-26 22:20:03,882 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-9, groupId=KafkaCsvProducer] Resetting offset for partition input-topic-job1-0 to offset 0.
2020-02-26 22:20:03,882 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (SubscriptionState.java:385) - [Consumer clientId=consumer-KafkaCsvProducer-11, groupId=KafkaCsvProducer] Resetting offset for partition input-topic-job1-0 to offset 0.
2020-02-26 22:20:08,977 [Kafka Fetcher for Source: Custom Source (4/4)] INFO  (AbstractCoordinator.java:756) - [Consumer clientId=consumer-KafkaCsvProducer-11, groupId=KafkaCsvProducer] Discovered group coordinator skl:9092 (id: 2147483647 rack: null)
2020-02-26 22:20:08,993 [Kafka Fetcher for Source: Custom Source -> Flat Map -> Sink: Unnamed (4/4)] INFO  (AbstractCoordinator.java:756) - [Consumer clientId=consumer-KafkaCsvProducer-9, groupId=KafkaCsvProducer] Discovered group coordinator skl:9092 (id: 2147483647 rack: null)
